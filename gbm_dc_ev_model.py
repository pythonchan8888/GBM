# -*- coding: utf-8 -*-
"""GBM DC EV Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gtzOsuXdJTfa1RZSka6QBaHKtvRYbKuH

Section 1: Data Fetching (with Type/Tier preparation)
"""

import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta # Ensure timedelta is imported
import os
import logging
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
# PerformanceWarning is pandas-specific, so filter after pandas import
warnings.filterwarnings("ignore", category=pd.errors.PerformanceWarning)

api_key = os.environ.get('FOOTYSTATS_API_KEY')
if not api_key:
    raise ValueError("FOOTYSTATS_API_KEY environment variable not set. Please set it before running.")

logging.basicConfig(level=logging.INFO, filename='recommendations_log.txt', filemode='w', format='%(asctime)s - %(message)s')

print("\n--- Section 1 (Revised): Unified Data Fetching & Flagging ---")

# --- Configuration ---
API_KEY = os.environ.get('FOOTYSTATS_API_KEY', '')
PAST_SEASONS_TO_FETCH = 5
RUN_ID = datetime.utcnow().strftime('%Y%m%d_%H%M%S')

# --- Helper Functions (Your existing, robust versions) ---
def get_season_ids_for_league(api_key, league_name_to_match, past_seasons=None):
    url = f"https://api.football-data-api.com/league-list?key={api_key}"
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        data = response.json()
        if not data or 'data' not in data:
            print(f"  Warning: No data returned from football-data-api.com for league-list. League: {league_name_to_match}")
            return []
    except requests.exceptions.RequestException as e:
        print(f"  Error fetching season IDs for '{league_name_to_match}': {e}")
        return []
    except ValueError as e:
        print(f"  Error decoding JSON for '{league_name_to_match}': {e}")
        return []

    df = pd.json_normalize(data['data'])
    if df.empty or 'season' not in df.columns or 'name' not in df.columns:
        print(f"  Warning: football-data-api.com league-list response not in expected format or empty for league: {league_name_to_match}.")
        return []

    df_exploded = df.explode('season')
    df_exploded['name_processed'] = df_exploded['name'].astype(str).str.strip().str.lower()
    league_name_processed_to_match = league_name_to_match.strip().lower()
    league_df = df_exploded[df_exploded['name_processed'] == league_name_processed_to_match]

    if league_df.empty or league_df['season'].isnull().all():
        print(f"  Warning: League '{league_name_to_match}' (processed: '{league_name_processed_to_match}') not found in football-data-api.com list or no seasons available.")
        return []

    valid_seasons_mask = league_df['season'].apply(lambda x: isinstance(x, dict))
    if not valid_seasons_mask.any():
        print(f"  Warning: No valid season data (dict type) to normalize for league '{league_name_to_match}'.")
        return []

    season_df = pd.json_normalize(league_df.loc[valid_seasons_mask, 'season'].tolist())
    if 'year' not in season_df.columns or 'id' not in season_df.columns:
        print(f"  Warning: 'year' or 'id' column missing in season data for league '{league_name_to_match}'.")
        return []

    season_df = season_df.sort_values('year', ascending=False)
    if past_seasons is not None:
        season_df = season_df.head(past_seasons)
    season_ids = season_df['id'].tolist()
    if not season_ids: print(f"  No season IDs found for '{league_name_to_match}' after filtering.")
    return season_ids

def get_league_match_data(api_key, season_id_from_api, league_name_for_df):
    # Using the URL without /v1/ as you found it works
    # Always try to include stats; missing stats for future games will be handled by normalization
    url = f"https://api.footystats.org/league-matches?key={api_key}&season_id={season_id_from_api}&include=stats"
    print(f"    Fetching from URL: {url.split('?')[0]}?season_id={season_id_from_api}...") # Mask key
    try:
        response = requests.get(url, timeout=15)
        response.raise_for_status()
        data = response.json()
        if not data or 'data' not in data or not data['data']:
            print(f"    Warning: No match data returned from FootyStats for season_id: {season_id_from_api}. League: {league_name_for_df}")
            return pd.DataFrame()
    except requests.exceptions.RequestException as e:
        print(f"    Error fetching match data for season_id {season_id_from_api} ({league_name_for_df}): {e}")
        return pd.DataFrame()
    except ValueError as e:
        print(f"    Error decoding JSON for match data, season_id {season_id_from_api} ({league_name_for_df}): {e}")
        return pd.DataFrame()

    df = pd.json_normalize(data['data'])
    if df.empty: return pd.DataFrame()

    df['season_id_fetched'] = season_id_from_api
    df['league'] = league_name_for_df

    if 'stats' in df.columns and not df['stats'].isnull().all():
        valid_stats_mask = df['stats'].apply(lambda x: isinstance(x, dict))
        if valid_stats_mask.any():
            stats_list = df.loc[valid_stats_mask, 'stats'].tolist()
            if stats_list:
                df_stats = pd.json_normalize(stats_list)
                if not df_stats.empty:
                    df_stats.index = df.loc[valid_stats_mask].index
                    df = pd.concat([df.drop('stats', axis=1), df_stats], axis=1)
                else: df = df.drop(columns=['stats'], errors='ignore')
            else: df = df.drop(columns=['stats'], errors='ignore')
        else: df = df.drop(columns=['stats'], errors='ignore')
    elif 'stats' in df.columns: df = df.drop(columns=['stats'], errors='ignore')
    return df

# --- Your Expanded LEAGUES_TO_FETCH list ---
LEAGUES_TO_FETCH = [
    'England Premier League', 'Italy Serie A', 'Spain La Liga', 'Germany Bundesliga', 'France Ligue 1',
    'Europe UEFA Champions League', 'Europe UEFA Europa League', 'Japan J1 League',
    'South Korea K League 1', 'Brazil Serie A', 'Argentina Primera División', 'Australia A-League',
    'USA MLS', 'Netherlands Eredivisie', 'Portugal Liga NOS', 'Belgium Pro League',
    'England FA Cup', 'Germany DFB Pokal', 'Italy Coppa Italia', 'Spain Copa del Rey',
    'France Coupe de France', 'Brazil Copa do Brasil', 'Argentina Copa Argentina',
    'Asia AFC Champions League', 'Austria Bundesliga', 'China Chinese Super League',
    'Denmark Superliga', 'England League Cup', 'England Championship',
    'Europe UEFA Europa Conference League', 'Israel Israeli Premier League', 'Japan Emperor Cup',
    'Malaysia Super League', 'Netherlands KNVB Cup', 'Saudi Arabia Professional League',
    'Scotland Premiership', 'South Korea Korean FA Cup', 'Turkey Süper Lig', 'Turkey Turkish Cup',
    'International FIFA Club World Cup'
]
import os as _os
if _os.environ.get('GBM_QUICK', '').strip() == '1':
    print("Quick mode ON: limiting leagues for smoke run.")
    LEAGUES_TO_FETCH = ['England Premier League', 'Italy Serie A', 'Spain La Liga', 'Germany Bundesliga', 'France Ligue 1', 'Japan J1 League', 'Portugal Liga NOS', 'Netherlands Eredivisie', 'England Championship', 'Scotland Premiership', 'Denmark Superliga', 'Saudi Arabia Professional League', 'Europe UEFA Champions League']

# --- Mappings for Competition Type and Tier (ensure these are complete for LEAGUES_TO_FETCH) ---
COMPETITION_TYPES = {
    'England Premier League': 'league', 'Italy Serie A': 'league', 'Spain La Liga': 'league',
    'Germany Bundesliga': 'league', 'France Ligue 1': 'league',
    'Europe UEFA Champions League': 'cup', 'Europe UEFA Europa League': 'cup',
    'Japan J1 League': 'league', 'South Korea K League 1': 'league', 'Brazil Serie A': 'league',
    'Argentina Primera División': 'league', 'Australia A-League': 'league', 'USA MLS': 'league',
    'Netherlands Eredivisie': 'league', 'Portugal Liga NOS': 'league',
    'Belgium Pro League': 'league', 'England FA Cup': 'cup', 'Germany DFB Pokal': 'cup',
    'Italy Coppa Italia': 'cup', 'Spain Copa del Rey': 'cup', 'France Coupe de France': 'cup',
    'Brazil Copa do Brasil': 'cup', 'Argentina Copa Argentina': 'cup', 'Asia AFC Champions League': 'cup',
    'Austria Bundesliga': 'league', 'China Chinese Super League': 'league', 'Denmark Superliga': 'league',
    'England League Cup': 'cup', 'England Championship': 'league', 'Europe UEFA Europa Conference League': 'cup',
    'Israel Israeli Premier League': 'league', 'Japan Emperor Cup': 'cup', 'Malaysia Super League': 'league',
    'Netherlands KNVB Cup': 'cup', 'Saudi Arabia Professional League': 'league', 'Scotland Premiership': 'league',
    'South Korea Korean FA Cup': 'cup', 'Turkey Süper Lig': 'league', 'Turkey Turkish Cup': 'cup',
    'International FIFA Club World Cup': 'cup'
}
DEFAULT_COMPETITION_TYPE = 'league'
LEAGUE_TIERS = {
    'England Premier League': 1, 'Spain La Liga': 1, 'Germany Bundesliga': 1, 'Italy Serie A': 1, 'France Ligue 1': 1,
    'Europe UEFA Champions League': 1, 'England FA Cup': 1,
    'Europe UEFA Europa League': 2, 'Portugal Liga NOS': 2, 'Netherlands Eredivisie': 2,
    'Brazil Serie A': 2, 'Argentina Primera División': 2, 'England Championship': 2,
    'Belgium Pro League': 2, 'Turkey Süper Lig': 2, 'Austria Bundesliga': 2,
    'Italy Coppa Italia': 2, 'Spain Copa del Rey': 2, 'Germany DFB Pokal': 2, 'France Coupe de France': 2,
    'Europe UEFA Europa Conference League': 2, 'Asia AFC Champions League': 2, 'England League Cup': 2,
    'Japan J1 League': 3, 'South Korea K League 1': 3, 'Australia A-League': 3, 'USA MLS': 3,
    'China Chinese Super League': 3, 'Denmark Superliga': 3, 'Israel Israeli Premier League': 3,
    'Malaysia Super League': 3, 'Saudi Arabia Professional League': 3, 'Scotland Premiership': 3,
    'Brazil Copa do Brasil': 3, 'Argentina Copa Argentina': 3, 'Japan Emperor Cup': 3,
    'South Korea Korean FA Cup': 3, 'Netherlands KNVB Cup': 3, 'Turkey Turkish Cup': 3,
    'International FIFA Club World Cup': 1
}
DEFAULT_TIER = 3

# --- Main Data Fetching Loop ---
all_data_list = []
print("--- Fetching Historical & Current Season Match Data (including potential future fixtures) ---")
for league_name_in_list in LEAGUES_TO_FETCH:
    print(f"\nProcessing league: {league_name_in_list}...")
    season_ids = get_season_ids_for_league(API_KEY, league_name_in_list, past_seasons=PAST_SEASONS_TO_FETCH)
    if not season_ids:
        print(f"  No season IDs obtained for '{league_name_in_list}'. Skipping.")
        continue
    for s_id in season_ids:
        # print(f"  Fetching matches for season_id: {s_id} (League: {league_name_in_list})") # Already printed in function
        season_match_data = get_league_match_data(API_KEY, s_id, league_name_in_list)
        if not season_match_data.empty:
            all_data_list.append(season_match_data)

# --- Consolidate All Fetched Data ---
all_data = pd.DataFrame() # Initialize an empty DataFrame
if all_data_list:
    all_data = pd.concat(all_data_list, ignore_index=True)
    print(f"\nTotal raw match entries fetched: {len(all_data)}")
else:
    print("No data fetched. Check LEAGUES_TO_FETCH names and API connectivity.")

# --- Initial Processing & Adding 'is_future', 'competition_type', 'league_tier' ---
if not all_data.empty:
    print("\nPerforming initial processing on all_data...")

    # Datetime conversion
    if 'date_unix' in all_data.columns:
        all_data['datetime'] = pd.to_datetime(all_data['date_unix'], unit='s')
        all_data['datetime_gmt8'] = all_data['datetime'] + pd.Timedelta(hours=8)
        print("Datetime columns created.")
    else:
        print("Warning: 'date_unix' column not found. Cannot create datetime columns accurately.")
        # Create dummy datetime_gmt8 if essential for later steps, though it will be incorrect
        if 'datetime_gmt8' not in all_data.columns: all_data['datetime_gmt8'] = pd.NaT

    # Define 'now' for 'is_future' flag - current time in GMT+8
    # This needs to be set based on the timezone of your 'datetime_gmt8' column.
    # Assuming 'datetime_gmt8' is naive but represents GMT+8.
    # Get current time. If running in Colab, it's UTC. Add 8 hours for GMT+8.
    now_utc = pd.Timestamp.now(tz='UTC')
    now_gmt8_for_comparison = now_utc.tz_convert('Asia/Singapore').tz_localize(None) # GMT+8 naive
    # Or, if your system time is already GMT+8 and you want naive comparison:
    # now_gmt8_for_comparison = pd.Timestamp(datetime.now())
    print(f"Current reference time for 'is_future' flag (GMT+8): {now_gmt8_for_comparison}")

    # Statuses that mean a game is definitely historical or unbettable as a future game
    TERMINAL_STATUSES = ['COMPLETE', 'CANCELED', 'CANCELLED',
                         'SUSPENDED', 'AWARDED', 'ABANDONED', 'POSTPONED', 'FT',
                         'AET', 'PEN']
                         # Note: 'INCOMPLETE' for a *past* game also fits here.

    def determine_is_future(row, current_time_gmt8):
        match_status_upper = str(row.get('status', '')).upper().strip()
        match_time = row['datetime_gmt8'] # Assumed to be pd.Timestamp (naive GMT+8)

        if pd.isna(match_time): return False

        # If status indicates it's definitely over or problematic
        if match_status_upper in TERMINAL_STATUSES:
            return False

        # Based on your data: 'incomplete' AND future_date indicates a future match
        if match_status_upper == 'INCOMPLETE':
            return match_time > current_time_gmt8

        # Add other known future statuses from API if they exist (e.g., 'TIMED', 'SCHEDULED', 'NS')
        # Example:
        # KNOWN_FUTURE_STATUSES = ['TIMED', 'SCHEDULED', 'NS', 'NOT STARTED']
        # if match_status_upper in KNOWN_FUTURE_STATUSES and match_time > current_time_gmt8:
        #     return True

        # If status is unknown/empty but date is in future, cautiously treat as future
        # This helps if API returns upcoming fixtures with no specific "future" status yet
        if not match_status_upper and match_time > current_time_gmt8:
            return True

        return False # Default to not future

    if 'status' in all_data.columns and 'datetime_gmt8' in all_data.columns:
        all_data['is_future'] = all_data.apply(
            lambda row: determine_is_future(row, now_gmt8_for_comparison), axis=1
        )
        print(f"\n'is_future' flag created. Future matches identified: {all_data['is_future'].sum()}")
    else:
        print("Warning: 'status' or 'datetime_gmt8' column not found. Cannot create 'is_future' flag accurately.")
        all_data['is_future'] = False # Default

    # Add Competition Type and League Tier
    if 'league' in all_data.columns:
        all_data['competition_type'] = all_data['league'].map(COMPETITION_TYPES).fillna(DEFAULT_COMPETITION_TYPE)
        all_data['league_tier'] = all_data['league'].map(LEAGUE_TIERS).fillna(DEFAULT_TIER)
        print("Added 'competition_type' and 'league_tier' columns.")
    else:
        print("Warning: 'league' column not found. Cannot map type/tier.")
        if 'competition_type' not in all_data.columns: all_data['competition_type'] = DEFAULT_COMPETITION_TYPE
        if 'league_tier' not in all_data.columns: all_data['league_tier'] = DEFAULT_TIER

    # Final sort for consistency
    all_data.sort_values(by=['datetime_gmt8', 'id'], inplace=True, na_position='first') # Put NaT dates first
    all_data.reset_index(drop=True, inplace=True)
    print("Final sorting of 'all_data' complete.")

    print("\nSample of 'all_data' (tail, to check for future games if any were fetched):")
    display_cols_final_s1 = ['datetime_gmt8', 'league', 'home_name', 'away_name', 'status', 'is_future', 'competition_type', 'league_tier']
    display_cols_final_s1 = [col for col in display_cols_final_s1 if col in all_data.columns]
    if display_cols_final_s1:
        print(all_data[display_cols_final_s1].tail(20)) # Show more rows in tail
        print("\nValue counts for 'is_future':")
        print(all_data['is_future'].value_counts(dropna=False))
        print("\nValue counts for 'competition_type':")
        print(all_data['competition_type'].value_counts(dropna=False))
        print("\nValue counts for 'league_tier':")
        print(all_data['league_tier'].value_counts(dropna=False))
    else:
        print("Key columns for display are missing from all_data.")

else:
    print("No data in 'all_data' to process further.")

# Rename all_data to all_data_unified for clarity in subsequent sections
if 'all_data' in locals() and not all_data.empty:
    all_data_unified = all_data.copy()
    print(f"\n'all_data_unified' DataFrame created with {len(all_data_unified)} total entries, ready for feature engineering.")
    # del all_data # Optional: delete original all_data if memory is a concern
else:
    all_data_unified = pd.DataFrame() # Ensure it exists even if empty
    print("Warning: 'all_data_unified' is empty as no data was fetched/processed.")

print("\n--- End of Section 1 (Revised): Unified Data Fetching & Flagging ---")

import pandas as pd

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
pd.set_option('display.width', None)  # Or a large number

all_data_unified.tail(10)

if 'all_data' in locals() and not all_data.empty and 'status' in all_data.columns:
    print(all_data['status'].unique())
else:
    print("'all_data' or 'status' column not found. Please run Section 1 first.")

"""Section 2: Feature Engineering (xGA and Actual Outcome)"""

import pandas as pd
import numpy as np

print("\n--- Section 2: Feature Engineering (xGA and Actual Outcome) on all_data_unified ---")

# This section now assumes 'all_data_unified' is the input DataFrame from Section 1.
# It should contain 'homeID', 'awayID', 'datetime_gmt8',
# 'team_a_xg', 'team_b_xg', 'homeGoalCount', 'awayGoalCount'.

if 'all_data_unified' not in locals() or all_data_unified.empty:
    print("Error: 'all_data_unified' DataFrame not found or is empty. Please run Section 1 (Revised) first.")
    # exit() # Or raise an error to stop execution
else:
    print(f"Input DataFrame 'all_data_unified' has {len(all_data_unified)} rows.")

    def calculate_xga_for_team(team_id, current_match_date, matches_data_for_lookup, decay_factor=0.9, max_matches=10):
        """
        Calculates the time-decayed weighted average of Expected Goals Conceded (xGA) for a team
        based on their past 'max_matches' games before the 'current_match_date'.
        Uses 'matches_data_for_lookup' (which will be all_data_unified) for historical data.
        """
        # Ensure datetime_gmt8 in the lookup DataFrame is datetime (should be from Section 1)
        if not pd.api.types.is_datetime64_any_dtype(matches_data_for_lookup['datetime_gmt8']):
            # This should not happen if Section 1 ran correctly, but as a safeguard:
            matches_data_for_lookup = matches_data_for_lookup.copy() # Avoid SettingWithCopyWarning
            matches_data_for_lookup['datetime_gmt8'] = pd.to_datetime(matches_data_for_lookup['datetime_gmt8'], errors='coerce')

        # Ensure current_match_date is datetime
        if not pd.api.types.is_datetime64_any_dtype(current_match_date):
            current_match_date = pd.to_datetime(current_match_date, errors='coerce')

        if pd.isna(current_match_date): # If current match date is invalid, cannot proceed
            return np.nan

        previous_matches_df = matches_data_for_lookup[
            (matches_data_for_lookup['datetime_gmt8'] < current_match_date) &
            ((matches_data_for_lookup['homeID'] == team_id) | (matches_data_for_lookup['awayID'] == team_id))
        ].copy()

        previous_matches_df.sort_values(by='datetime_gmt8', ascending=True, inplace=True)
        previous_matches_df = previous_matches_df.tail(max_matches)

        if previous_matches_df.empty:
            return np.nan

        xga_components = []
        actual_weights = []
        for i, (_, row) in enumerate(previous_matches_df.iterrows()):
            opponent_xg = np.nan
            if row['homeID'] == team_id:
                opponent_xg = pd.to_numeric(row.get('team_b_xg'), errors='coerce')
            else:
                opponent_xg = pd.to_numeric(row.get('team_a_xg'), errors='coerce')

            if pd.notna(opponent_xg):
                weight = decay_factor ** (len(previous_matches_df) - 1 - i)
                xga_components.append(opponent_xg * weight)
                actual_weights.append(weight)

        if not actual_weights or sum(actual_weights) == 0:
            return np.nan

        return sum(xga_components) / sum(actual_weights)

    MAX_MATCHES_FOR_XGA = 10
    DECAY_FACTOR_XGA = 0.9

    print(f"\nCalculating team_a_xga (using last {MAX_MATCHES_FOR_XGA} matches, decay {DECAY_FACTOR_XGA})...")
    all_data_unified['team_a_xga'] = all_data_unified.apply(
        lambda row: calculate_xga_for_team(
            row['homeID'], row['datetime_gmt8'],
            all_data_unified, # Pass the full unified DataFrame for historical lookup
            decay_factor=DECAY_FACTOR_XGA, max_matches=MAX_MATCHES_FOR_XGA
        ), axis=1
    )

    print(f"Calculating team_b_xga (using last {MAX_MATCHES_FOR_XGA} matches, decay {DECAY_FACTOR_XGA})...")
    all_data_unified['team_b_xga'] = all_data_unified.apply(
        lambda row: calculate_xga_for_team(
            row['awayID'], row['datetime_gmt8'],
            all_data_unified, # Pass the full unified DataFrame for historical lookup
            decay_factor=DECAY_FACTOR_XGA, max_matches=MAX_MATCHES_FOR_XGA
        ), axis=1
    )
    print("xGA calculations complete.")

    # --- Calculate Actual Outcome ---
    def get_actual_outcome(row):
        home_goals = pd.to_numeric(row.get('homeGoalCount'), errors='coerce')
        away_goals = pd.to_numeric(row.get('awayGoalCount'), errors='coerce')

        # For future matches, homeGoalCount/awayGoalCount might be NaN or 0.
        # We only want to set actual_outcome if the game is not future AND goals are valid.
        if row.get('is_future', True): # If 'is_future' column exists and is True, or if column doesn't exist (safer to assume future)
            return None # No actual outcome for future games

        if pd.isna(home_goals) or pd.isna(away_goals):
            return None

        if home_goals > away_goals: return 'home_win'
        elif home_goals < away_goals: return 'away_win'
        else: return 'draw'

    print("\nCalculating actual match outcomes (for non-future matches)...")
    all_data_unified['actual_outcome'] = all_data_unified.apply(get_actual_outcome, axis=1)
    print("Actual outcome calculation complete.")

    # --- Display a sample of the DataFrame with new features ---
    print("\n--- Sample of DataFrame with new xGA and Actual Outcome columns ---")
    columns_to_show_s2 = [
        'datetime_gmt8', 'is_future', 'status', 'home_name', 'away_name',
        'homeGoalCount', 'awayGoalCount', 'actual_outcome',
        'team_a_xg', 'team_b_xg', 'team_a_xga', 'team_b_xga',
        'league', 'competition_type', 'league_tier'
    ]
    columns_to_show_s2 = [col for col in columns_to_show_s2 if col in all_data_unified.columns]

    if not all_data_unified.empty and columns_to_show_s2:
        print("\nSample Head (likely historical):")
        print(all_data_unified[columns_to_show_s2].head())
        print("\nSample Tail (to see if future matches are processed):")
        print(all_data_unified[columns_to_show_s2].tail())

        print("\nChecking for NaNs in new xGA columns (first 5 rows of the entire dataset):")
        xga_cols_to_check = [col for col in ['team_a_xga', 'team_b_xga'] if col in all_data_unified.columns]
        if xga_cols_to_check:
            print(all_data_unified[xga_cols_to_check].head())
        else:
            print("xGA columns not found.")

        print("\nValue counts for 'actual_outcome':")
        if 'actual_outcome' in all_data_unified.columns:
            print(all_data_unified['actual_outcome'].value_counts(dropna=False)) # dropna=False to see NaNs
        else:
            print("'actual_outcome' column not found.")
    else:
        print("DataFrame 'all_data_unified' is empty or key columns for display are missing.")

print("\n--- End of Section 2: Feature Engineering (xGA and Actual Outcome) ---")
# 'all_data_unified' is now updated with team_a_xga, team_b_xga, and actual_outcome (for non-future games)
# This 'all_data_unified' will be the input to Section 3.

"""Section 3: Rolling Features, Team Form, and Fixture Congestion"""

import pandas as pd
import numpy as np

print("\n--- Section 3 (Refactored): Rolling Features, Team Form, and Fixture Congestion on all_data_unified ---")

# This section assumes 'all_data_unified' is the input DataFrame from Section 1 (Revised)
# It should contain 'is_future', 'competition_type', 'league_tier', 'homeID', 'awayID',
# 'datetime_gmt8', 'team_a_xg', 'team_b_xg', 'team_a_xga', 'team_b_xga',
# 'homeGoalCount', 'awayGoalCount', 'actual_outcome' (NaN for future).

if 'all_data_unified' not in locals() or all_data_unified.empty:
    print("Error: 'all_data_unified' DataFrame not found or is empty. Please run Section 1 (Revised) first.")
    # exit() # Or raise an error
else:
    print(f"Input 'all_data_unified' has {len(all_data_unified)} rows.")
    # Create a working copy to avoid modifying the original from Section 1 if it's re-run
    current_data_df = all_data_unified.copy()

    ROLLING_WINDOW_SIZE = 5

    # --- 1. Define calculate_points function ---
    def calculate_points(row, team_name_to_check):
        if pd.isna(row['actual_outcome']): return 0 # No points if outcome is NaN (e.g., future games)
        if row['actual_outcome'] == 'home_win':
            return 3 if row['home_name'] == team_name_to_check else 0
        elif row['actual_outcome'] == 'away_win':
            return 3 if row['away_name'] == team_name_to_check else 0
        elif row['actual_outcome'] == 'draw':
            if row['home_name'] == team_name_to_check or row['away_name'] == team_name_to_check:
                return 1
        return 0

    # --- 2. Prepare Team-Specific Stats DataFrame (team_game_stats) ---
    # This will be used to calculate historical form and days_since_last_match.
    # We should only use historical matches (is_future == False) to build up these stats,
    # especially for things like 'points_earned'.
    print("Preparing team_game_stats DataFrame from historical data...")

    historical_matches_for_form = current_data_df[current_data_df['is_future'] == False].copy()
    print(f"Using {len(historical_matches_for_form)} historical matches for team_game_stats.")

    temp_match_list = []
    if not historical_matches_for_form.empty:
        for i, row in historical_matches_for_form.iterrows():
            temp_match_list.append({
                'match_id': row['id'], 'team_id': row['homeID'], 'team_name': row['home_name'],
                'datetime_gmt8': row['datetime_gmt8'],
                'goals_scored': pd.to_numeric(row.get('homeGoalCount'), errors='coerce'),
                'goals_conceded': pd.to_numeric(row.get('awayGoalCount'), errors='coerce'),
                'xg_for': pd.to_numeric(row.get('team_a_xg'), errors='coerce'),
                'xga_against': pd.to_numeric(row.get('team_a_xga'), errors='coerce'), # From Section 2
                'actual_outcome_original': row['actual_outcome'] # From Section 2
            })
            temp_match_list.append({
                'match_id': row['id'], 'team_id': row['awayID'], 'team_name': row['away_name'],
                'datetime_gmt8': row['datetime_gmt8'],
                'goals_scored': pd.to_numeric(row.get('awayGoalCount'), errors='coerce'),
                'goals_conceded': pd.to_numeric(row.get('homeGoalCount'), errors='coerce'),
                'xg_for': pd.to_numeric(row.get('team_b_xg'), errors='coerce'),
                'xga_against': pd.to_numeric(row.get('team_b_xga'), errors='coerce'), # From Section 2
                'actual_outcome_original': row['actual_outcome']
            })
        team_game_stats = pd.DataFrame(temp_match_list)
        team_game_stats.sort_values(by=['team_id', 'datetime_gmt8'], inplace=True)
        print(f"team_game_stats (from historical) prepared with {len(team_game_stats)} team-match entries.")

        # Calculate points earned (only on historical_matches_for_form for lookup)
        match_details_lookup = historical_matches_for_form.set_index('id')
        def get_points_for_team_in_match(team_game_row):
            try: # Handle potential KeyError if a match_id in team_game_stats isn't in lookup (should not happen)
                original_match_row = match_details_lookup.loc[team_game_row['match_id']]
                return calculate_points(original_match_row, team_game_row['team_name'])
            except KeyError:
                return 0
        team_game_stats['points_earned'] = team_game_stats.apply(get_points_for_team_in_match, axis=1)
    else:
        team_game_stats = pd.DataFrame() # Empty if no historical data
        print("Warning: No historical matches found to build team_game_stats for form calculation.")


    # --- 3. Calculate Fixture Congestion (Days Since Last Match) on team_game_stats ---
    # This uses the historically derived team_game_stats.
    if not team_game_stats.empty:
        print("\nCalculating 'days_since_last_match' for each team (based on historical context)...")
        team_game_stats['days_since_last_match'] = team_game_stats.groupby('team_id')['datetime_gmt8'].diff().dt.days
    else:
        # If team_game_stats is empty, these columns won't be created on it.
        # The merge step later will handle missing columns gracefully if it tries to merge them.
        pass

    # --- 4. Calculate Rolling Form Metrics on team_game_stats ---
    if not team_game_stats.empty:
        print(f"Calculating rolling team form metrics (overall form over last {ROLLING_WINDOW_SIZE} games)...")
        form_metrics_to_roll = ['goals_scored', 'goals_conceded', 'points_earned', 'xg_for', 'xga_against']
        for metric in form_metrics_to_roll:
            if metric in team_game_stats.columns:
                team_game_stats[f'rolling_{metric}_form'] = team_game_stats.groupby('team_id')[metric].transform(
                    lambda x: x.shift(1).rolling(window=ROLLING_WINDOW_SIZE, min_periods=1).mean())
            else:
                print(f"Warning: Metric '{metric}' not found in team_game_stats for rolling calculation.")
        if 'rolling_points_form' in team_game_stats.columns:
            team_game_stats['ppg_form'] = team_game_stats['rolling_points_form']
    else:
        pass # No team_game_stats to calculate rolling form on

    # --- 5. Merge Form & Congestion Metrics back to 'current_data_df' (which is all_data_unified) ---
    print("\nMerging team form and 'days_since_last_match' back to the main DataFrame...")
    # These metrics in team_game_stats are based on historical data.
    # When merged to current_data_df, for future matches, they will represent the form *leading up to* that future match.

    cols_to_merge = ['match_id', 'team_id', 'days_since_last_match'] + \
                    [f'rolling_{m}_form' for m in form_metrics_to_roll if f'rolling_{m}_form' in team_game_stats.columns]
    if 'ppg_form' in team_game_stats.columns: cols_to_merge.append('ppg_form')

    # Ensure only existing columns are selected from team_game_stats for merging
    cols_to_merge = [col for col in cols_to_merge if col in team_game_stats.columns]

    if not team_game_stats.empty and len(cols_to_merge) > 2: # if there's something to merge
        team_game_stats_to_merge = team_game_stats[cols_to_merge].copy()

        # Merge for Home Team perspective
        home_perspective_stats = team_game_stats_to_merge.rename(
            columns={col: col + '_home' for col in cols_to_merge if col not in ['match_id', 'team_id']}
        )
        home_perspective_stats = home_perspective_stats.rename(columns={'match_id': 'match_id_h_ref', 'team_id': 'team_id_h_ref'})
        current_data_df = pd.merge(current_data_df, home_perspective_stats,
                                   left_on=['id', 'homeID'], right_on=['match_id_h_ref', 'team_id_h_ref'],
                                   how='left').drop(columns=['match_id_h_ref', 'team_id_h_ref'], errors='ignore')

        # Merge for Away Team perspective
        away_perspective_stats = team_game_stats_to_merge.rename(
            columns={col: col + '_away' for col in cols_to_merge if col not in ['match_id', 'team_id']}
        )
        away_perspective_stats = away_perspective_stats.rename(columns={'match_id': 'match_id_a_ref', 'team_id': 'team_id_a_ref'})
        current_data_df = pd.merge(current_data_df, away_perspective_stats,
                                   left_on=['id', 'awayID'], right_on=['match_id_a_ref', 'team_id_a_ref'],
                                   how='left').drop(columns=['match_id_a_ref', 'team_id_a_ref'], errors='ignore')
        print("Team form and 'days_since_last_match' metrics merged.")
    else:
        print("No form or days_since_last_match metrics to merge from team_game_stats (it might be empty or lack columns).")


    # --- 6. Calculate Fixture Congestion (Matches in Last N Days) directly on current_data_df ---
    # This uses the full current_data_df (all_data_unified) for lookups, which is correct.
    print("\nCalculating matches in last N days (this can be slow)...")
    def calculate_matches_in_prior_n_days(current_match_row, team_id_to_check, all_matches_history_df, N_days):
        # Filter for matches of the specific team from the *complete historical part of all_matches_history_df*
        # AND matches of this team in the future part that are *before* the current_match_row's date.
        # This ensures we only count actual past matches.

        team_matches = all_matches_history_df[
            ((all_matches_history_df['homeID'] == team_id_to_check) | (all_matches_history_df['awayID'] == team_id_to_check)) &
            (all_matches_history_df['datetime_gmt8'] < current_match_row['datetime_gmt8']) # Strictly past
        ]

        window_end = current_match_row['datetime_gmt8'] - pd.Timedelta(days=1)
        window_start = current_match_row['datetime_gmt8'] - pd.Timedelta(days=N_days)

        count = team_matches[
            (team_matches['datetime_gmt8'] >= window_start) &
            (team_matches['datetime_gmt8'] <= window_end)
        ].shape[0]
        return count

    # Apply for home team
    current_data_df['home_matches_last_7d'] = current_data_df.apply(
        lambda row: calculate_matches_in_prior_n_days(row, row['homeID'], current_data_df, 7), axis=1)
    current_data_df['home_matches_last_14d'] = current_data_df.apply(
        lambda row: calculate_matches_in_prior_n_days(row, row['homeID'], current_data_df, 14), axis=1)
    # Apply for away team
    current_data_df['away_matches_last_7d'] = current_data_df.apply(
        lambda row: calculate_matches_in_prior_n_days(row, row['awayID'], current_data_df, 7), axis=1)
    current_data_df['away_matches_last_14d'] = current_data_df.apply(
        lambda row: calculate_matches_in_prior_n_days(row, row['awayID'], current_data_df, 14), axis=1)
    print("Matches in last N days calculated.")

    # --- 7. Calculate Role-Specific Rolling Stats directly on current_data_df ---
    # These also use the full current_data_df but .shift(1) ensures only past data is used for each row.
    print(f"\nCalculating rolling metrics for home/away specific performance (last {ROLLING_WINDOW_SIZE} games in that role)...")
    # Convert base columns to numeric first for safety, coercing errors
    base_rolling_cols = ['team_a_xg', 'team_a_xga', 'homeGoalCount', 'awayGoalCount', 'team_b_xg', 'team_b_xga']
    for col in base_rolling_cols:
        if col in current_data_df.columns:
            current_data_df[col] = pd.to_numeric(current_data_df[col], errors='coerce')

    current_data_df['home_rolling_xg_as_home'] = current_data_df.groupby('homeID')['team_a_xg'].transform(
        lambda x: x.shift(1).rolling(window=ROLLING_WINDOW_SIZE, min_periods=1).mean())
    current_data_df['home_rolling_xga_as_home'] = current_data_df.groupby('homeID')['team_a_xga'].transform(
        lambda x: x.shift(1).rolling(window=ROLLING_WINDOW_SIZE, min_periods=1).mean())
    current_data_df['home_rolling_goals_scored_as_home'] = current_data_df.groupby('homeID')['homeGoalCount'].transform(
        lambda x: x.shift(1).rolling(window=ROLLING_WINDOW_SIZE, min_periods=1).mean())
    current_data_df['home_rolling_goals_conceded_as_home'] = current_data_df.groupby('homeID')['awayGoalCount'].transform(
        lambda x: x.shift(1).rolling(window=ROLLING_WINDOW_SIZE, min_periods=1).mean())
    current_data_df['away_rolling_xg_as_away'] = current_data_df.groupby('awayID')['team_b_xg'].transform(
        lambda x: x.shift(1).rolling(window=ROLLING_WINDOW_SIZE, min_periods=1).mean())
    current_data_df['away_rolling_xga_as_away'] = current_data_df.groupby('awayID')['team_b_xga'].transform(
        lambda x: x.shift(1).rolling(window=ROLLING_WINDOW_SIZE, min_periods=1).mean())
    current_data_df['away_rolling_goals_scored_as_away'] = current_data_df.groupby('awayID')['awayGoalCount'].transform(
        lambda x: x.shift(1).rolling(window=ROLLING_WINDOW_SIZE, min_periods=1).mean())
    current_data_df['away_rolling_goals_conceded_as_away'] = current_data_df.groupby('awayID')['homeGoalCount'].transform(
        lambda x: x.shift(1).rolling(window=ROLLING_WINDOW_SIZE, min_periods=1).mean())
    print("Home/Away specific rolling metrics calculated.")

    # --- 8. Final Check for Duplicate Columns ---
    cols = pd.Series(current_data_df.columns)
    duplicate_cols = cols[cols.duplicated()].unique()
    if len(duplicate_cols) > 0:
        print(f"Warning: Found duplicate column names after all operations: {list(duplicate_cols)}")
    else:
        print("No duplicate column names found in current_data_df. Excellent.")

    # --- 9. Assign to df_model_input (standard name for output of feature engineering stages) ---
    df_model_input = current_data_df.copy() # Use df_model_input as the consistent output name

    # --- 10. Display Sample Output ---
    print("\n--- Sample of df_model_input with Rolling Features & Congestion ---")
    # Use the final column names created by your renaming logic in step 5
    # Example if direct renames like 'ppg_form_home' worked:
    columns_to_show_s3 = [
        'datetime_gmt8', 'is_future', 'home_name', 'away_name', 'actual_outcome',
        'competition_type', 'league_tier',
        'ppg_form_home', 'ppg_form_away', # These were created in step 5
        'days_since_last_match_home', 'days_since_last_match_away', # These were created in step 5
        'home_matches_last_7d', 'away_matches_last_7d', # From step 6
        'home_rolling_xg_as_home', 'away_rolling_xg_as_away' # From step 7
    ]
    columns_to_show_s3_existing = [col for col in columns_to_show_s3 if col in df_model_input.columns]
    if columns_to_show_s3_existing:
        print(df_model_input[columns_to_show_s3_existing].tail(10)) # Show tail for future games
    else:
        print("Key columns for display are missing from df_model_input.")

print("\n--- End of Section 3 (Refactored): Rolling Features, Team Form, and Fixture Congestion ---")
# df_model_input is now ready for Section 3.5 (Advanced Granular Stats)

"""Section 3.5: Advanced Feature Engineering - Granular Stats & Additional Odds"""

import pandas as pd
import numpy as np

print("\n--- Section 3.5 (Corrected): Advanced Feature Engineering - Granular Stats & Additional Odds ---")

# df_model_input is the DataFrame from the end of your completed Section 3.
# all_data is the DataFrame from Section 1.

print(f"Input df_model_input to Section 3.5 has {df_model_input.shape[0]} rows and {df_model_input.shape[1]} columns.")

# Safety check for required raw columns (as you had)
required_raw_cols_for_s3_5 = [
    'id', 'team_a_possession', 'team_b_possession', 'team_a_shots', 'team_b_shots',
    'team_a_shotsOnTarget', 'team_b_shotsOnTarget', 'team_a_corners', 'team_b_corners',
    'team_a_fouls', 'team_b_fouls', 'team_a_dangerous_attacks', 'team_b_dangerous_attacks',
    'team_a_xga', 'team_b_xga', # Needed for 'match_team_xga' for Section 3.7
    'odds_btts_yes', 'odds_ft_over25', 'odds_ft_under25'
]
cols_to_get_from_all_data = [col for col in required_raw_cols_for_s3_5 if col in all_data.columns]
if 'id' not in cols_to_get_from_all_data and 'id' in required_raw_cols_for_s3_5:
    cols_to_get_from_all_data.append('id')

if not set(cols_to_get_from_all_data).issubset(set(df_model_input.columns)):
    print("Merging required raw columns from all_data into df_model_input for Section 3.5...")
    # Preserve original df_model_input columns if merge introduces _raw_dup for already existing ones
    existing_cols = df_model_input.columns.tolist()
    df_model_input = pd.merge(
        df_model_input,
        all_data[cols_to_get_from_all_data].drop_duplicates(subset=['id']), # Avoid duplicating rows if all_data had issues
        on='id',
        how='left',
        suffixes=('_existing', '') # Suffix new columns if originals exist
    )
    # Prioritize existing columns if merge created duplicates with suffix
    for col_base in required_raw_cols_for_s3_5:
        if col_base + '_existing' in df_model_input.columns and col_base in df_model_input.columns:
             # If the original column (no suffix) exists from the merge, and _existing also exists,
             # assume the one without suffix is the latest/correct one from all_data
             df_model_input.drop(columns=[col_base + '_existing'], inplace=True)
    print("Required raw columns ensured in df_model_input.")


# --- Part 1: Rolling Averages for Granular Stats ---
print("\nPreparing team_game_stats_granular (comprehensively for Sections 3.5 & 3.7)...")
temp_match_list_granular = []
for i, row in df_model_input.iterrows():
    temp_match_list_granular.append({
        'match_id': row['id'], 'team_id': row['homeID'], 'datetime_gmt8': row['datetime_gmt8'],
        'possession': row.get('team_a_possession'), 'shots_for': row.get('team_a_shots'),
        'shots_against': row.get('team_b_shots'), 'sot_for': row.get('team_a_shotsOnTarget'),
        'sot_against': row.get('team_b_shotsOnTarget'), 'corners_for': row.get('team_a_corners'),
        'corners_against': row.get('team_b_corners'), 'fouls_for': row.get('team_a_fouls'),
        'fouls_against': row.get('team_b_fouls'), 'da_for': row.get('team_a_dangerous_attacks'),
        'da_against': row.get('team_b_dangerous_attacks'),
        'match_team_xga': row.get('team_a_xga') # Home team's xGA for this match
    })
    temp_match_list_granular.append({
        'match_id': row['id'], 'team_id': row['awayID'], 'datetime_gmt8': row['datetime_gmt8'],
        'possession': row.get('team_b_possession'), 'shots_for': row.get('team_b_shots'),
        'shots_against': row.get('team_a_shots'), 'sot_for': row.get('team_b_shotsOnTarget'),
        'sot_against': row.get('team_a_shotsOnTarget'), 'corners_for': row.get('team_b_corners'),
        'corners_against': row.get('team_a_corners'), 'fouls_for': row.get('team_b_fouls'),
        'fouls_against': row.get('team_a_fouls'), 'da_for': row.get('team_b_dangerous_attacks'),
        'da_against': row.get('team_a_dangerous_attacks'),
        'match_team_xga': row.get('team_b_xga') # Away team's xGA for this match
    })
team_game_stats_granular = pd.DataFrame(temp_match_list_granular)
team_game_stats_granular.sort_values(by=['team_id', 'datetime_gmt8'], inplace=True)

cols_to_numeric_granular = [
    'possession', 'shots_for', 'shots_against', 'sot_for', 'sot_against',
    'corners_for', 'corners_against', 'fouls_for', 'fouls_against',
    'da_for', 'da_against', 'match_team_xga'
]
for col in cols_to_numeric_granular:
    if col in team_game_stats_granular.columns:
        team_game_stats_granular[col] = pd.to_numeric(team_game_stats_granular[col], errors='coerce')
print(f"team_game_stats_granular prepared with {len(team_game_stats_granular)} entries and 'match_team_xga'.")

# --- DEFINE granular_metrics_to_roll HERE ---
granular_metrics_to_roll = [ # These are the base names from team_game_stats_granular
    'possession', 'shots_for', 'shots_against',
    'sot_for', 'sot_against', 'corners_for', 'corners_against',
    'fouls_for', 'fouls_against', 'da_for', 'da_against'
    # 'match_team_xga' is a raw value per match for the team, usually not rolled itself
    # unless you want rolling average of team's own xGA, but we have that as rolling_xga_against_form
]
# ROLLING_WINDOW_GRANULAR can be same as ROLLING_WINDOW_SIZE or different
ROLLING_WINDOW_GRANULAR = 5

print(f"\nCalculating rolling averages for granular stats (last {ROLLING_WINDOW_GRANULAR} games)...")
for metric in granular_metrics_to_roll:
    if metric in team_game_stats_granular.columns:
        col_name = f'rolling_{metric}_form' # e.g., rolling_possession_form
        team_game_stats_granular[col_name] = team_game_stats_granular.groupby('team_id')[metric].transform(
            lambda x: x.shift(1).rolling(window=ROLLING_WINDOW_GRANULAR, min_periods=1).mean()
        )
    else:
        print(f"Warning: Granular metric column '{metric}' not found in team_game_stats_granular for rolling average.")

# Merge these new rolling granular stats back to df_model_input
cols_to_merge_granular = ['match_id', 'team_id'] + \
                         [f'rolling_{m}_form' for m in granular_metrics_to_roll
                          if f'rolling_{m}_form' in team_game_stats_granular.columns]
# Ensure cols_to_merge_granular only contains existing columns
cols_to_merge_granular = [col for col in cols_to_merge_granular if col in team_game_stats_granular.columns]


if len(cols_to_merge_granular) > 2: # Check if there are actual rolling features to merge
    team_game_stats_granular_to_merge = team_game_stats_granular[cols_to_merge_granular].copy()

    home_granular_stats = team_game_stats_granular_to_merge.rename(
        columns={col: col + '_home' for col in team_game_stats_granular_to_merge.columns if col not in ['match_id', 'team_id']}
    )
    home_granular_stats = home_granular_stats.rename(columns={'match_id': 'match_id_h_granular', 'team_id': 'team_id_h_granular'})
    df_model_input = pd.merge(df_model_input, home_granular_stats,
                              left_on=['id', 'homeID'], right_on=['match_id_h_granular', 'team_id_h_granular'],
                              how='left').drop(columns=['match_id_h_granular', 'team_id_h_granular'], errors='ignore')

    away_granular_stats = team_game_stats_granular_to_merge.rename(
        columns={col: col + '_away' for col in team_game_stats_granular_to_merge.columns if col not in ['match_id', 'team_id']}
    )
    away_granular_stats = away_granular_stats.rename(columns={'match_id': 'match_id_a_granular', 'team_id': 'team_id_a_granular'})
    df_model_input = pd.merge(df_model_input, away_granular_stats,
                              left_on=['id', 'awayID'], right_on=['match_id_a_granular', 'team_id_a_granular'],
                              how='left').drop(columns=['match_id_a_granular', 'team_id_a_granular'], errors='ignore')
    print("Rolling granular stats merged into df_model_input.")
else:
    print("No rolling granular stats were created or selected to merge.")


# --- Part 2: Implied Probabilities from Other Odds Markets ---
# (This part of your code was fine)
print("\nCalculating implied probabilities from other odds markets...")
def safe_inv_odds(odds_series):
    odds_numeric = pd.to_numeric(odds_series, errors='coerce')
    return np.where(odds_numeric.notna() & (odds_numeric > 0), 1 / odds_numeric, np.nan)

if 'odds_btts_yes' in df_model_input.columns:
    df_model_input['market_prob_btts_yes'] = safe_inv_odds(df_model_input['odds_btts_yes'])
else: print("Warning: 'odds_btts_yes' column not found.")
if 'odds_ft_over25' in df_model_input.columns:
    df_model_input['market_prob_o25'] = safe_inv_odds(df_model_input['odds_ft_over25'])
else: print("Warning: 'odds_ft_over25' column not found.")
if 'odds_ft_under25' in df_model_input.columns:
    df_model_input['market_prob_u25'] = safe_inv_odds(df_model_input['odds_ft_under25'])
else: print("Warning: 'odds_ft_under25' column not found.")
print("Implied market probabilities calculated.")

# --- Display a sample of the DataFrame with new advanced features ---
print("\n--- Sample of df_model_input with new Advanced Features (first 5 rows) ---")
new_adv_cols_to_show = [
    'home_name', 'away_name',
    'rolling_possession_form_home', 'rolling_possession_form_away',
    'rolling_sot_for_form_home', 'rolling_sot_for_form_away',
    'rolling_da_for_form_home', 'rolling_da_against_form_away', # Example with DA
    'market_prob_btts_yes', 'market_prob_o25', 'market_prob_u25'
]
new_adv_cols_to_show = [col for col in new_adv_cols_to_show if col in df_model_input.columns]

if not df_model_input.empty and new_adv_cols_to_show:
    print(df_model_input[new_adv_cols_to_show].head())
    print("\nChecking for NaNs in new advanced feature columns (first 5 rows sample):")
    # Ensure columns for isnull check actually exist to prevent KeyError
    existing_cols_for_nan_check = [col for col in new_adv_cols_to_show if col in df_model_input.columns and col not in ['home_name', 'away_name']]
    if existing_cols_for_nan_check:
        print(df_model_input[existing_cols_for_nan_check].head().isnull().sum())
    else:
        print("No new advanced feature columns (other than names) were found to check for NaNs.")
else:
    print("DataFrame 'df_model_input' is empty or key columns for new feature display are missing.")

print("\n--- End of Section 3.5 (Corrected): Advanced Feature Engineering ---")

print(df_model_input.columns.tolist())
print(f"Are there any truly duplicated column names? {df_model_input.columns.has_duplicates}")

"""Section 3.6 (NEW): Synthetic Feature Engineering"""

import pandas as pd
import numpy as np

print("\n--- Section 3.6 (Corrected): Synthetic Feature Engineering ---")

# df_model_input is the DataFrame from the end of your Section 3.5
# It should contain raw xG, goals, shots, SOT, possession, corners, fouls etc. for each match.

# --- 1. Prepare team_game_stats_for_synthetics with all necessary raw metrics ---
print("\nPreparing team_game_stats for synthetic feature calculation...")
temp_match_list_for_synthetics = []

# Define all raw stat columns we'll need from df_model_input for synthetic features
# These are the per-match stats for team_a (home) and team_b (away)
raw_stat_cols_map = {
    'goals_scored_home': 'homeGoalCount', 'goals_scored_away': 'awayGoalCount',
    'xg_for_home': 'team_a_xg', 'xg_for_away': 'team_b_xg',
    'shots_for_home': 'team_a_shots', 'shots_for_away': 'team_b_shots',
    'sot_for_home': 'team_a_shotsOnTarget', 'sot_for_away': 'team_b_shotsOnTarget',
    # Add any other stats you might want for more synthetic features later
    # e.g., 'possession_home': 'team_a_possession', 'possession_away': 'team_b_possession'
}

for i, row in df_model_input.iterrows():
    # Home team's perspective
    home_stats = {
        'match_id': row['id'], 'team_id': row['homeID'], 'datetime_gmt8': row['datetime_gmt8'],
        'goals_scored': row.get(raw_stat_cols_map['goals_scored_home']),
        'xg_for': row.get(raw_stat_cols_map['xg_for_home']),
        'shots_for': row.get(raw_stat_cols_map['shots_for_home']),
        'sot_for': row.get(raw_stat_cols_map['sot_for_home'])
    }
    temp_match_list_for_synthetics.append(home_stats)

    # Away team's perspective
    away_stats = {
        'match_id': row['id'], 'team_id': row['awayID'], 'datetime_gmt8': row['datetime_gmt8'],
        'goals_scored': row.get(raw_stat_cols_map['goals_scored_away']),
        'xg_for': row.get(raw_stat_cols_map['xg_for_away']),
        'shots_for': row.get(raw_stat_cols_map['shots_for_away']),
        'sot_for': row.get(raw_stat_cols_map['sot_for_away'])
    }
    temp_match_list_for_synthetics.append(away_stats)

team_game_stats_for_synthetics = pd.DataFrame(temp_match_list_for_synthetics)
team_game_stats_for_synthetics.sort_values(by=['team_id', 'datetime_gmt8'], inplace=True)

# Convert relevant columns to numeric, coercing errors to NaN
cols_to_numeric_synth = ['goals_scored', 'xg_for', 'shots_for', 'sot_for']
for col in cols_to_numeric_synth:
    if col in team_game_stats_for_synthetics.columns:
        team_game_stats_for_synthetics[col] = pd.to_numeric(team_game_stats_for_synthetics[col], errors='coerce')

print(f"team_game_stats_for_synthetics prepared with {len(team_game_stats_for_synthetics)} entries.")
# print("Sample of team_game_stats_for_synthetics with base metrics:")
# print(team_game_stats_for_synthetics.head())
# print(team_game_stats_for_synthetics.isnull().sum())


# --- 2. Calculate Match-Specific Raw Synthetic Features ---
print("\nCalculating raw synthetic features per team-match...")
epsilon = 1e-6 # For safe division

# a) Goal Over/Underperformance vs. xG
if 'goals_scored' in team_game_stats_for_synthetics.columns and 'xg_for' in team_game_stats_for_synthetics.columns:
    team_game_stats_for_synthetics['synth_goals_minus_xg'] = (
        team_game_stats_for_synthetics['goals_scored'] - team_game_stats_for_synthetics['xg_for']
    )
    team_game_stats_for_synthetics['synth_goals_per_xg_ratio'] = np.where(
        (team_game_stats_for_synthetics['xg_for'].notna()) & (abs(team_game_stats_for_synthetics['xg_for']) > epsilon),
        team_game_stats_for_synthetics['goals_scored'] / (team_game_stats_for_synthetics['xg_for']), # No need for epsilon if xg_for > epsilon
        np.nan
    )
    # Handle xG = 0, Goals > 0 or xG > 0, Goals = 0 specifically if desired, e.g. large/small number for ratio
    # For xG=0, Goals=0, ratio could be 1 (met expectation) or NaN. Current logic gives NaN.
else:
    print("Warning: Cannot calculate xG-related synthetic features; 'goals_scored' or 'xg_for' missing or not numeric.")
# b) Shooting Efficiency / Accuracy
if 'goals_scored' in team_game_stats_for_synthetics.columns and \
   'shots_for' in team_game_stats_for_synthetics.columns and \
   'sot_for' in team_game_stats_for_synthetics.columns:

    team_game_stats_for_synthetics['synth_goals_per_shot'] = np.where(
        (team_game_stats_for_synthetics['shots_for'].notna()) & (team_game_stats_for_synthetics['shots_for'] > 0),
        team_game_stats_for_synthetics['goals_scored'] / team_game_stats_for_synthetics['shots_for'],
        np.nan
    )
    team_game_stats_for_synthetics['synth_goals_per_sot'] = np.where(
        (team_game_stats_for_synthetics['sot_for'].notna()) & (team_game_stats_for_synthetics['sot_for'] > 0),
        team_game_stats_for_synthetics['goals_scored'] / team_game_stats_for_synthetics['sot_for'],
        np.nan
    )
    team_game_stats_for_synthetics['synth_sot_per_shot_ratio'] = np.where(
        (team_game_stats_for_synthetics['shots_for'].notna()) & (team_game_stats_for_synthetics['shots_for'] > 0),
        team_game_stats_for_synthetics['sot_for'] / team_game_stats_for_synthetics['shots_for'],
        np.nan
    )
else:
    print("Warning: Cannot calculate shot-related synthetic features; key shot/goal columns missing or not numeric.")


# --- 3. Calculate Rolling Averages of these Synthetic Features ---
synthetic_metrics_to_roll = [
    'synth_goals_minus_xg', 'synth_goals_per_xg_ratio',
    'synth_goals_per_shot', 'synth_goals_per_sot', 'synth_sot_per_shot_ratio'
]
ROLLING_WINDOW_SYNTHETIC = 5

print(f"\nCalculating rolling averages for synthetic features (last {ROLLING_WINDOW_SYNTHETIC} games)...")
for metric in synthetic_metrics_to_roll:
    if metric in team_game_stats_for_synthetics.columns:
        col_name = f'rolling_{metric}_form'
        team_game_stats_for_synthetics[col_name] = team_game_stats_for_synthetics.groupby('team_id')[metric].transform(
            lambda x: x.shift(1).rolling(window=ROLLING_WINDOW_SYNTHETIC, min_periods=1).mean()
        )
    else: # This warning should now be less frequent if raw features are properly created
        print(f"Warning: Raw synthetic metric '{metric}' not found in team_game_stats_for_synthetics. Cannot create rolling average for it.")

# --- 4. Merge Rolling Synthetic Features back to df_model_input ---
# Ensure df_model_input is used as the base for merging
# If df_model_input was modified (e.g. rows dropped) after team_game_stats_for_synthetics was created, align them first.
# However, df_model_input is the source for team_game_stats_for_synthetics via match_id ('id')

cols_to_merge_synthetic = ['match_id', 'team_id'] + \
                          [f'rolling_{m}_form' for m in synthetic_metrics_to_roll
                           if f'rolling_{m}_form' in team_game_stats_for_synthetics.columns]

# Filter to only existing columns to avoid errors if some synthetic features failed
cols_to_merge_synthetic = [col for col in cols_to_merge_synthetic if col in team_game_stats_for_synthetics.columns]
team_game_stats_synthetic_to_merge = team_game_stats_for_synthetics[cols_to_merge_synthetic].copy()


# Merge for Home Team perspective
home_synthetic_stats = team_game_stats_synthetic_to_merge.rename(
    columns={col: col + '_home' for col in team_game_stats_synthetic_to_merge.columns if col not in ['match_id', 'team_id']}
)
home_synthetic_stats = home_synthetic_stats.rename(columns={'match_id': 'match_id_h_synth', 'team_id': 'team_id_h_synth'})
df_model_input = pd.merge(df_model_input, home_synthetic_stats,
                          left_on=['id', 'homeID'], right_on=['match_id_h_synth', 'team_id_h_synth'],
                          how='left').drop(columns=['match_id_h_synth', 'team_id_h_synth'], errors='ignore')

# Merge for Away Team perspective
away_synthetic_stats = team_game_stats_synthetic_to_merge.rename(
    columns={col: col + '_away' for col in team_game_stats_synthetic_to_merge.columns if col not in ['match_id', 'team_id']}
)
away_synthetic_stats = away_synthetic_stats.rename(columns={'match_id': 'match_id_a_synth', 'team_id': 'team_id_a_synth'})
df_model_input = pd.merge(df_model_input, away_synthetic_stats,
                          left_on=['id', 'awayID'], right_on=['match_id_a_synth', 'team_id_a_synth'],
                          how='left').drop(columns=['match_id_a_synth', 'team_id_a_synth'], errors='ignore')

print("Rolling synthetic features merged into df_model_input.")

# --- Display a sample of the DataFrame with new synthetic features ---
print("\n--- Sample of df_model_input with new Rolling Synthetic Features (first 15 rows to see some non-NaNs) ---")
new_synth_cols_to_show = [
    'home_name', 'away_name',
    'rolling_synth_goals_minus_xg_form_home', 'rolling_synth_goals_per_xg_ratio_form_home',
    'rolling_synth_goals_per_shot_form_home', 'rolling_synth_goals_per_sot_form_home',
    'rolling_synth_sot_per_shot_ratio_form_home',
    'rolling_synth_goals_minus_xg_form_away', 'rolling_synth_goals_per_xg_ratio_form_away'
]
new_synth_cols_to_show = [col for col in new_synth_cols_to_show if col in df_model_input.columns]

if not df_model_input.empty and new_synth_cols_to_show:
    print(df_model_input[new_synth_cols_to_show].head(15))
    print("\nChecking for NaNs in new rolling synthetic feature columns (first 15 rows sample):")
    # Ensure all columns in new_synth_cols_to_show actually exist before trying to access them
    existing_cols_for_nan_check = [col for col in new_synth_cols_to_show if col in df_model_input.columns and col not in ['home_name', 'away_name']]
    if existing_cols_for_nan_check:
        print(df_model_input[existing_cols_for_nan_check].head(15).isnull().sum())
    else:
        print("No new synthetic columns were found to check for NaNs in the sample.")
else:
    print("DataFrame 'df_model_input' is empty or key columns for new synthetic feature display are missing.")

# --- Add back the granular stats & odds-derived features from original Section 3.5 if they were on df_model_input ---
# This part is if you also want the rolling granulars (possession etc) and market probs in the final df_model_input
# If they were already calculated on df_model_input in your actual Section 3.5, they are still there.
# If team_game_stats_granular from 3.5 was the one with those and wasn't merged fully, this is where you'd merge them.
# My code for 3.5 already merged them into df_model_input.

print("\n--- End of Section 3.6 (Corrected): Synthetic Feature Engineering ---")

"""Section 3.7 (NEW): Advanced Defensive Synthetic Features"""

import pandas as pd
import numpy as np

print("\n--- Section 3.7 (Corrected to use 'match_team_xga'): Advanced Defensive Synthetic Features ---")

if 'team_game_stats_granular' not in locals() or team_game_stats_granular.empty:
    print("Error: 'team_game_stats_granular' DataFrame from Section 3.5 is not available or empty.")
else:
    print(f"Using 'team_game_stats_granular' with {len(team_game_stats_granular)} entries.")

    # --- 1. Calculate Match-Specific Raw Defensive Synthetic Features ---
    print("\nCalculating raw defensive synthetic features per team-match...")
    epsilon = 1e-6

    # Ensure necessary columns are numeric (should have been done in 3.5, but good check)
    # The key input from team_game_stats_granular for xGA conceded is 'match_team_xga'
    # The shots/SOT conceded by the team are 'shots_against' and 'sot_against' in team_game_stats_granular

    defensive_base_cols_needed = {
        'xga_conceded_this_match': 'match_team_xga', # This is the team's own xGA for the match
        'shots_faced_this_match': 'shots_against',    # These are opponent's shots
        'sot_faced_this_match': 'sot_against'      # These are opponent's SOT
    }

    all_base_cols_present = True
    for internal_name, actual_col_name in defensive_base_cols_needed.items():
        if actual_col_name not in team_game_stats_granular.columns:
            print(f"Warning: Base column '{actual_col_name}' (for {internal_name}) not found in team_game_stats_granular.")
            team_game_stats_granular[actual_col_name] = np.nan # Create as NaN to avoid key errors
            all_base_cols_present = False
        else:
            # Ensure numeric
            team_game_stats_granular[actual_col_name] = pd.to_numeric(team_game_stats_granular[actual_col_name], errors='coerce')

    if all_base_cols_present:
        team_game_stats_granular['synth_xga_per_shot_conceded'] = np.where(
            (team_game_stats_granular[defensive_base_cols_needed['shots_faced_this_match']].notna()) & \
            (team_game_stats_granular[defensive_base_cols_needed['shots_faced_this_match']] > 0),
            team_game_stats_granular[defensive_base_cols_needed['xga_conceded_this_match']] / \
            team_game_stats_granular[defensive_base_cols_needed['shots_faced_this_match']],
            np.nan
        )

        team_game_stats_granular['synth_xga_per_sot_conceded'] = np.where(
            (team_game_stats_granular[defensive_base_cols_needed['sot_faced_this_match']].notna()) & \
            (team_game_stats_granular[defensive_base_cols_needed['sot_faced_this_match']] > 0),
            team_game_stats_granular[defensive_base_cols_needed['xga_conceded_this_match']] / \
            team_game_stats_granular[defensive_base_cols_needed['sot_faced_this_match']],
            np.nan
        )
    else:
        print("Cannot calculate defensive synthetic features due to missing base columns.")
        team_game_stats_granular['synth_xga_per_shot_conceded'] = np.nan
        team_game_stats_granular['synth_xga_per_sot_conceded'] = np.nan


    # --- 2. Calculate Rolling Averages ---
    defensive_synthetic_metrics_to_roll = [
        'synth_xga_per_shot_conceded',
        'synth_xga_per_sot_conceded'
    ]
    ROLLING_WINDOW_DEF_SYNTHETIC = 5

    print(f"\nCalculating rolling averages for defensive synthetic features (last {ROLLING_WINDOW_DEF_SYNTHETIC} games)...")
    for metric in defensive_synthetic_metrics_to_roll:
        if metric in team_game_stats_granular.columns and team_game_stats_granular[metric].notna().any():
            col_name = f'rolling_{metric}_form'
            team_game_stats_granular[col_name] = team_game_stats_granular.groupby('team_id')[metric].transform(
                lambda x: x.shift(1).rolling(window=ROLLING_WINDOW_DEF_SYNTHETIC, min_periods=1).mean()
            )
        else:
            print(f"Warning: Raw defensive synthetic metric '{metric}' is all NaN or not found. Cannot create rolling average.")
            team_game_stats_granular[f'rolling_{metric}_form'] = np.nan # Ensure column exists for merging

    # --- 3. Merge Rolling Defensive Synthetic Features back to df_model_input ---
    cols_to_merge_def_synthetic = ['match_id', 'team_id'] + \
                                  [f'rolling_{m}_form' for m in defensive_synthetic_metrics_to_roll
                                   if f'rolling_{m}_form' in team_game_stats_granular.columns]
    cols_to_merge_def_synthetic = [col for col in cols_to_merge_def_synthetic if col in team_game_stats_granular.columns]

    if len(cols_to_merge_def_synthetic) > 2:
        team_game_stats_def_synthetic_to_merge = team_game_stats_granular[cols_to_merge_def_synthetic].copy()

        home_def_synthetic_stats = team_game_stats_def_synthetic_to_merge.rename(
            columns={col: col + '_home' for col in team_game_stats_def_synthetic_to_merge.columns if col not in ['match_id', 'team_id']}
        )
        home_def_synthetic_stats = home_def_synthetic_stats.rename(columns={'match_id': 'match_id_h_def_synth', 'team_id': 'team_id_h_def_synth'})
        df_model_input = pd.merge(df_model_input, home_def_synthetic_stats,
                                  left_on=['id', 'homeID'], right_on=['match_id_h_def_synth', 'team_id_h_def_synth'],
                                  how='left').drop(columns=['match_id_h_def_synth', 'team_id_h_def_synth'], errors='ignore')

        away_def_synthetic_stats = team_game_stats_def_synthetic_to_merge.rename(
            columns={col: col + '_away' for col in team_game_stats_def_synthetic_to_merge.columns if col not in ['match_id', 'team_id']}
        )
        away_def_synthetic_stats = away_def_synthetic_stats.rename(columns={'match_id': 'match_id_a_def_synth', 'team_id': 'team_id_a_def_synth'})
        df_model_input = pd.merge(df_model_input, away_def_synthetic_stats,
                                  left_on=['id', 'awayID'], right_on=['match_id_a_def_synth', 'team_id_a_def_synth'],
                                  how='left').drop(columns=['match_id_a_def_synth', 'team_id_a_def_synth'], errors='ignore')
        print("Rolling defensive synthetic features merged into df_model_input.")
    else:
        print("No new rolling defensive synthetic features were created/merged (likely due to missing base columns or all-NaN raw metrics).")

    # --- Display a sample ---
    print("\n--- Sample of df_model_input with new Rolling Defensive Synthetic Features (first 15 rows) ---")
    new_def_synth_cols_to_show = [
        'home_name', 'away_name',
        'rolling_synth_xga_per_shot_conceded_form_home',
        'rolling_synth_xga_per_sot_conceded_form_home',
        'rolling_synth_xga_per_shot_conceded_form_away',
        'rolling_synth_xga_per_sot_conceded_form_away'
    ]
    new_def_synth_cols_to_show = [col for col in new_def_synth_cols_to_show if col in df_model_input.columns]

    if not df_model_input.empty and new_def_synth_cols_to_show:
        print(df_model_input[new_def_synth_cols_to_show].head(15))
    else:
        print("DataFrame 'df_model_input' is empty or key columns for new defensive synthetic feature display are missing.")

print("\n--- End of Section 3.7 (Corrected): Advanced Defensive Synthetic Features ---")

# Run this after all feature engineering is done, just before Section 4
final_feature_engineered_columns = df_model_input.columns.tolist()
print(final_feature_engineered_columns)

"""Section 3.8 (NEW): Elo Rating Calculation"""

import numpy as np
import pandas as pd

print("\n--- Section 3.8 (NEW): Elo Rating Calculation ---")

# Elo configuration
K_FACTOR = 25
HFA_ELO = 65
STARTING_ELO = 1500

def _elo_expected_score(elo_a: float, elo_b: float, hfa: float) -> float:
    dr = elo_a - elo_b + hfa
    return 1.0 / (1.0 + 10.0 ** (-dr / 400.0))

def _elo_update(elo_a: float, elo_b: float, goals_a: float, goals_b: float, k_factor: float, hfa: float):
    expected_a = _elo_expected_score(elo_a, elo_b, hfa)
    if goals_a > goals_b:
        actual_a = 1.0
    elif goals_a < goals_b:
        actual_a = 0.0
    else:
        actual_a = 0.5
    goal_diff = abs(float(goals_a) - float(goals_b))
    if goal_diff <= 1:
        multiplier = 1.0
    elif goal_diff == 2:
        multiplier = 1.5
    else:
        multiplier = (11.0 + goal_diff) / 8.0
    elo_change = k_factor * multiplier * (actual_a - expected_a)
    return elo_a + elo_change, elo_b - elo_change

# Ensure chronological order
df_model_input = df_model_input.sort_values(by='datetime_gmt8')

elo_ratings = {}
elo_rows = []
for _, r in df_model_input.iterrows():
    match_id = r['id']
    hid, aid = r['homeID'], r['awayID']
    elo_h = elo_ratings.get(hid, STARTING_ELO)
    elo_a = elo_ratings.get(aid, STARTING_ELO)
    elo_rows.append({'id': match_id, 'pre_match_home_elo': elo_h, 'pre_match_away_elo': elo_a})
    if r['is_future'] is False and pd.notna(r['homeGoalCount']) and pd.notna(r['awayGoalCount']):
        new_h, new_a = _elo_update(elo_h, elo_a, r['homeGoalCount'], r['awayGoalCount'], K_FACTOR, HFA_ELO)
        elo_ratings[hid] = new_h
        elo_ratings[aid] = new_a

df_match_elos = pd.DataFrame(elo_rows)
df_model_input = df_model_input.drop(columns=['pre_match_home_elo', 'pre_match_away_elo'], errors='ignore')
df_model_input = pd.merge(df_model_input, df_match_elos, on='id', how='left')

df_model_input['elo_diff'] = df_model_input['pre_match_home_elo'] - df_model_input['pre_match_away_elo']
df_model_input['elo_prob_home_win'] = df_model_input.apply(
    lambda row: _elo_expected_score(row['pre_match_home_elo'], row['pre_match_away_elo'], HFA_ELO), axis=1
)

print("Elo ratings calculated and merged.")

"""Section 3.9 (NEW): Dynamic League Quality Tiers"""

print("\n--- Section 3.9 (NEW): Dynamic League Quality Tiers (10 Levels) ---")

# Average of pre-match Elos used to characterize league quality
try:
    league_quality_series = df_model_input.groupby('league').apply(
        lambda x: (x['pre_match_home_elo'].mean() + x['pre_match_away_elo'].mean()) / 2.0
    )
except Exception:
    league_quality_series = pd.Series(dtype=float)

NUM_TIERS = 10
df_model_input['dynamic_league_quality'] = df_model_input['league'].map(league_quality_series)
df_model_input['dynamic_league_quality'] = df_model_input['dynamic_league_quality'].fillna(STARTING_ELO)

try:
    df_model_input['dynamic_league_tier'] = pd.qcut(
        df_model_input['dynamic_league_quality'], NUM_TIERS, labels=False, duplicates='drop'
    )
except Exception as e:
    print(f"Warning: Could not create {NUM_TIERS} dynamic tiers. Falling back to static 'league_tier'. Reason: {e}")
    df_model_input['dynamic_league_tier'] = df_model_input.get('league_tier')

print("Dynamic league tiers calculated based on average team Elo ratings.")

"""Section 3.10 (REVISED & ROBUST): EWM-based Refactor for Rolling Features"""

import pandas as pd
import numpy as np

print("\n--- Section 3.10 (REVISED & ROBUST): EWM-based Rolling Features (overwrite prior rollings) ---")

try:
    required_cols_for_ewm = ['id','datetime_gmt8','homeID','awayID','homeGoalCount','awayGoalCount','team_a_xg','team_b_xg','team_a_xga','team_b_xga']
    if not all(c in df_model_input.columns for c in required_cols_for_ewm):
        raise ValueError("Required columns missing for EWM calculation")

    df_tmp = df_model_input[required_cols_for_ewm].copy()
    # Ensure numeric types
    for c in ['homeGoalCount','awayGoalCount','team_a_xg','team_b_xg','team_a_xga','team_b_xga']:
        df_tmp[c] = pd.to_numeric(df_tmp[c], errors='coerce')
    df_tmp = df_tmp.sort_values('datetime_gmt8')

    # Build long format (team-match perspective)
    home_part = pd.DataFrame({
        'id': df_tmp['id'],
        'datetime_gmt8': df_tmp['datetime_gmt8'],
        'team_id': df_tmp['homeID'],
        'goals_for': df_tmp['homeGoalCount'],
        'goals_against': df_tmp['awayGoalCount'],
        'xg_for': df_tmp['team_a_xg'],
        'xg_against': df_tmp['team_b_xg'],
        'xga_against': df_tmp['team_a_xga'],  # team's own xGA in match
        'is_home': True
    })
    away_part = pd.DataFrame({
        'id': df_tmp['id'],
        'datetime_gmt8': df_tmp['datetime_gmt8'],
        'team_id': df_tmp['awayID'],
        'goals_for': df_tmp['awayGoalCount'],
        'goals_against': df_tmp['homeGoalCount'],
        'xg_for': df_tmp['team_b_xg'],
        'xg_against': df_tmp['team_a_xg'],
        'xga_against': df_tmp['team_b_xga'],
        'is_home': False
    })
    long_df = pd.concat([home_part, away_part], ignore_index=True)
    long_df = long_df.sort_values(['team_id','datetime_gmt8'])

    # Compute EWM stats per team (shift to avoid leakage)
    def ewm_shift_mean(series: pd.Series, span: int = 6) -> pd.Series:
        return series.shift(1).ewm(span=span, min_periods=1, adjust=False).mean()

    for metric in ['goals_for','goals_against','xg_for','xg_against','xga_against']:
        long_df[f'ewm_{metric}'] = long_df.groupby('team_id')[metric].transform(lambda s: ewm_shift_mean(s, span=6))

    # Columns to replace with EWM-derived values
    cols_to_replace_home = {
        'ewm_goals_for':'rolling_goals_scored_form_home',
        'ewm_goals_against':'rolling_goals_conceded_form_home',
        'ewm_xg_for':'rolling_xg_for_form_home',
        'ewm_xg_against':'rolling_xga_against_form_home'
    }
    cols_to_replace_away = {
        'ewm_goals_for':'rolling_goals_scored_form_away',
        'ewm_goals_against':'rolling_goals_conceded_form_away',
        'ewm_xg_for':'rolling_xg_for_form_away',
        'ewm_xg_against':'rolling_xga_against_form_away'
    }

    # Drop old rolling columns before merging to avoid conflicts
    df_model_input = df_model_input.drop(columns=list(cols_to_replace_home.values()) + list(cols_to_replace_away.values()), errors='ignore')

    # Merge back to match level for home/away contexts
    ewm_home = long_df[long_df['is_home']].copy()
    ewm_away = long_df[~long_df['is_home']].copy()

    # Home features overwrite
    df_model_input = df_model_input.merge(
        ewm_home[['id','team_id','ewm_goals_for','ewm_goals_against','ewm_xg_for','ewm_xg_against','ewm_xga_against']]
               .rename(columns={
                   'team_id':'homeID',
                   'ewm_goals_for':'rolling_goals_scored_form_home',
                   'ewm_goals_against':'rolling_goals_conceded_form_home',
                   'ewm_xg_for':'rolling_xg_for_form_home',
                    'ewm_xg_against':'rolling_xga_against_form_home'
               }),
        on=['id','homeID'], how='left'
    )

    # Away features overwrite
    df_model_input = df_model_input.merge(
        ewm_away[['id','team_id','ewm_goals_for','ewm_goals_against','ewm_xg_for','ewm_xg_against','ewm_xga_against']]
               .rename(columns={
                   'team_id':'awayID',
                   'ewm_goals_for':'rolling_goals_scored_form_away',
                   'ewm_goals_against':'rolling_goals_conceded_form_away',
                   'ewm_xg_for':'rolling_xg_for_form_away',
                    'ewm_xg_against':'rolling_xga_against_form_away'
               }),
        on=['id','awayID'], how='left'
    )

    # Role-specific home/away rolling
    df_model_input['home_rolling_xg_as_home'] = df_model_input['rolling_xg_for_form_home']
    df_model_input['home_rolling_xga_as_home'] = df_model_input['rolling_xga_against_form_home']
    df_model_input['home_rolling_goals_scored_as_home'] = df_model_input['rolling_goals_scored_form_home']
    df_model_input['home_rolling_goals_conceded_as_home'] = df_model_input['rolling_goals_conceded_form_home']

    df_model_input['away_rolling_xg_as_away'] = df_model_input['rolling_xg_for_form_away']
    df_model_input['away_rolling_xga_as_away'] = df_model_input['rolling_xga_against_form_away']
    df_model_input['away_rolling_goals_scored_as_away'] = df_model_input['rolling_goals_scored_form_away']
    df_model_input['away_rolling_goals_conceded_as_away'] = df_model_input['rolling_goals_conceded_form_away']

    print("EWM-based rolling features computed and merged.")
except Exception as e:
    print(f"Warning: EWM-based rolling features failed. Error: {e}")

"""Section 4: Data Preparation for Modeling"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

print("\n--- Section 4: Data Preparation for Modeling (Incorporating All Engineered Features) ---")

# df_model_input is the DataFrame from the end of your Section 3.7

# --- 1. Define the Prediction Target (y) & Split Historical from Future ---
# Ensure essential columns for target and identification are present and not null
df_model_input.dropna(subset=['homeGoalCount', 'awayGoalCount', 'datetime_gmt8', 'id', 'homeID', 'awayID', 'is_future'], inplace=True)

# Separate historical data for training/testing the model, and future data for predictions
df_for_training_and_testing = df_model_input[df_model_input['is_future'] == False].copy()
df_to_predict_future = df_model_input[df_model_input['is_future'] == True].copy()

print(f"Historical matches for model training/testing: {len(df_for_training_and_testing)}")
print(f"Future matches for generating recommendations: {len(df_to_predict_future)}")

if df_for_training_and_testing.empty:
    print("Error: No historical data available for training/testing after NA drop. Check data fetching and 'is_future' flag.")
    # exit() # Or handle error appropriately
else:
    target_home_goals = df_for_training_and_testing['homeGoalCount'].astype(float)
    target_away_goals = df_for_training_and_testing['awayGoalCount'].astype(float)
    print(f"Target variables defined for {len(df_for_training_and_testing)} historical matches.")

    # --- 2. Feature Selection (X) ---
    categorical_features = [
        'competition_type',
        # 'league_tier',  # replaced by dynamic tiers
        'dynamic_league_tier'
    ]
    # Ensure categorical features are treated as 'category' dtype IN THE TRAINING/TESTING DATAFRAME
    for col in categorical_features:
        if col in df_for_training_and_testing.columns:
            df_for_training_and_testing[col] = df_for_training_and_testing[col].astype('category')
            if not df_to_predict_future.empty and col in df_to_predict_future.columns: # Also for future data
                 df_to_predict_future[col] = df_to_predict_future[col].astype('category')
        else:
            print(f"Warning: Categorical feature '{col}' expected but not found. It will be excluded.")
            if col in categorical_features: categorical_features.remove(col)

    # Construct numerical_features list based on your df_model_input.columns.tolist()
    numerical_features = [
        'team_a_xg', 'team_b_xg', 'team_a_xga', 'team_b_xga',
        'odds_ft_1', 'odds_ft_x', 'odds_ft_2',

        # Overall Form & Congestion (from your list, names confirmed)
        'rolling_goals_scored_form_home', 'rolling_goals_conceded_form_home',
        'rolling_points_earned_form_home', # Using this based on your column list
        'rolling_xg_for_form_home', 'rolling_xga_against_form_home',
        'days_since_last_match_home',
        'rolling_goals_scored_form_away', 'rolling_goals_conceded_form_away',
        'rolling_points_earned_form_away', # Using this based on your column list
        'rolling_xg_for_form_away', 'rolling_xga_against_form_away',
        'days_since_last_match_away',
        'home_matches_last_7d', 'home_matches_last_14d',
        'away_matches_last_7d', 'away_matches_last_14d',

        # Role-Specific Rolling Features
        'home_rolling_xg_as_home', 'home_rolling_xga_as_home',
        'home_rolling_goals_scored_as_home', 'home_rolling_goals_conceded_as_home',
        'away_rolling_xg_as_away', 'away_rolling_xga_as_away',
        'away_rolling_goals_scored_as_away', 'away_rolling_goals_conceded_as_away',

        # Granular Rolling Stats (from Section 3.5)
        'rolling_possession_form_home', 'rolling_shots_for_form_home',
        'rolling_shots_against_form_home', 'rolling_sot_for_form_home',
        'rolling_sot_against_form_home', 'rolling_corners_for_form_home',
        'rolling_corners_against_form_home', 'rolling_fouls_for_form_home',
        'rolling_fouls_against_form_home',
        'rolling_da_for_form_home', 'rolling_da_against_form_home',

        'rolling_possession_form_away', 'rolling_shots_for_form_away',
        'rolling_shots_against_form_away', 'rolling_sot_for_form_away',
        'rolling_sot_against_form_away', 'rolling_corners_for_form_away',
        'rolling_corners_against_form_away', 'rolling_fouls_for_form_away',
        'rolling_fouls_against_form_away',
        'rolling_da_for_form_away', 'rolling_da_against_form_away',

        # Odds-Derived Probabilities (from Section 3.5)
        'market_prob_btts_yes', 'market_prob_o25', 'market_prob_u25',

        # Synthetic Attacking Rolling Features (from Section 3.6)
        'rolling_synth_goals_minus_xg_form_home', 'rolling_synth_goals_per_xg_ratio_form_home',
        'rolling_synth_goals_per_shot_form_home', 'rolling_synth_goals_per_sot_form_home',
        'rolling_synth_sot_per_shot_ratio_form_home',
        'rolling_synth_goals_minus_xg_form_away', 'rolling_synth_goals_per_xg_ratio_form_away',
        'rolling_synth_goals_per_shot_form_away', 'rolling_synth_goals_per_sot_form_away',
        'rolling_synth_sot_per_shot_ratio_form_away',

        # Synthetic Defensive Rolling Features (from Section 3.7)
        'rolling_synth_xga_per_shot_conceded_form_home', 'rolling_synth_xga_per_sot_conceded_form_home',
        'rolling_synth_xga_per_shot_conceded_form_away', 'rolling_synth_xga_per_sot_conceded_form_away',

        # Elo-based features
        'pre_match_home_elo', 'pre_match_away_elo', 'elo_diff', 'elo_prob_home_win',
        'dynamic_league_quality'
    ]

    # Clean up the feature lists by keeping only columns that actually exist
    numerical_features = [col for col in numerical_features if col in df_for_training_and_testing.columns]
    categorical_features = [col for col in categorical_features if col in df_for_training_and_testing.columns and df_for_training_and_testing[col].dtype.name == 'category']

    print(f"\nSelected {len(numerical_features)} final numerical features for modeling.")
    print(f"Selected {len(categorical_features)} final categorical features for OHE: {categorical_features}")

    all_feature_columns = numerical_features + categorical_features
    if not all_feature_columns:
        print("CRITICAL ERROR: No features selected for modeling. Stopping.")
        # exit()
    else:
        X_historical_raw = df_for_training_and_testing[all_feature_columns].copy()

    # --- 3. Data Splitting (Chronological Train/Test Split for Historical Data) ---
    if not X_historical_raw.empty:
        # Ensure df_for_training_and_testing is sorted (already done by all_data_unified)
        # X_historical_raw index will align with df_for_training_and_testing

        split_percentage = 0.80
        if len(X_historical_raw) < 10:
            print(f"Error: Very few historical data points ({len(X_historical_raw)}) available for train/test split.")

        split_index = int(len(X_historical_raw) * split_percentage)
        X_train_raw = X_historical_raw.iloc[:split_index]
        X_test_raw = X_historical_raw.iloc[split_index:]

        y_train_home_goals = target_home_goals.iloc[:split_index]
        y_test_home_goals = target_home_goals.iloc[split_index:]
        y_train_away_goals = target_away_goals.iloc[:split_index]
        y_test_away_goals = target_away_goals.iloc[split_index:]

        print(f"\nHistorical data split into training and testing sets:")
        print(f"X_train_raw shape: {X_train_raw.shape}, X_test_raw shape: {X_test_raw.shape}")

        # --- 4. Preprocessing Pipeline (NaN Imputation, Encoding, Scaling) ---
        numerical_pipeline = Pipeline([
            ('imputer_num', SimpleImputer(strategy='median')),
            ('scaler', StandardScaler())
        ])
        categorical_pipeline = Pipeline([
            ('imputer_cat', SimpleImputer(strategy='most_frequent')),
            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
        ])

        transformers_list = []
        if numerical_features:
            transformers_list.append(('num', numerical_pipeline, numerical_features))
        if categorical_features:
            transformers_list.append(('cat', categorical_pipeline, categorical_features))

        if not transformers_list:
            print("Error: No features available for preprocessing pipeline.")
        else:
            preprocessor = ColumnTransformer(transformers=transformers_list, remainder='drop') # Drop other columns

            print("\nApplying preprocessing (NaN imputation, OneHotEncoding, Scaling) to historical data...")
            # Fit preprocessor ONLY on X_train_raw
            X_train_processed_array = preprocessor.fit_transform(X_train_raw)
            X_test_processed_array = preprocessor.transform(X_test_raw)

            # Get feature names after OHE
            processed_feature_names = []
            try:
                if numerical_features:
                    processed_feature_names.extend(numerical_features)
                if categorical_features and 'cat' in preprocessor.named_transformers_:
                    ohe_feature_names = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)
                    processed_feature_names.extend(ohe_feature_names.tolist())
            except Exception as e:
                print(f"Warning: Could not automatically determine all OHE feature names due to error: {e}.")

            print("Preprocessing of historical data complete.")
            print(f"Shape of processed X_train: {X_train_processed_array.shape}")
            print(f"Shape of processed X_test: {X_test_processed_array.shape}")

            if processed_feature_names and X_train_processed_array.shape[1] == len(processed_feature_names):
                print(f"Total features after OHE: {len(processed_feature_names)}")
                X_train_processed_df = pd.DataFrame(X_train_processed_array, columns=processed_feature_names, index=X_train_raw.index)
                X_test_processed_df = pd.DataFrame(X_test_processed_array, columns=processed_feature_names, index=X_test_raw.index)
            else:
                X_train_processed_df = pd.DataFrame(X_train_processed_array, index=X_train_raw.index)
                X_test_processed_df = pd.DataFrame(X_test_processed_array, index=X_test_raw.index)
                print(f"Warning: Processed DataFrames for historical data created without explicit column names or mismatch.")

            print("\nSample of processed and scaled training data (X_train_processed_df first 5 rows):")
            print(X_train_processed_df.head())

            # Now, also preprocess the future data using the FITTED preprocessor
            if not df_to_predict_future.empty and all_feature_columns:
                X_future_raw = df_to_predict_future[all_feature_columns].copy()
                # Ensure categorical features in future data are also 'category' dtype
                for col in categorical_features:
                    if col in X_future_raw.columns:
                        X_future_raw[col] = X_future_raw[col].astype('category')

                print(f"\nPreprocessing future data ({len(X_future_raw)} matches)...")
                X_future_processed_array = preprocessor.transform(X_future_raw) # Use transform ONLY

                if processed_feature_names and X_future_processed_array.shape[1] == len(processed_feature_names):
                    X_future_processed_df = pd.DataFrame(X_future_processed_array, columns=processed_feature_names, index=X_future_raw.index)
                else:
                    X_future_processed_df = pd.DataFrame(X_future_processed_array, index=X_future_raw.index)

                print(f"Shape of processed X_future_processed_df: {X_future_processed_df.shape}")
                # print("\nSample of processed future data (first 5 rows):")
                # print(X_future_processed_df.head())
            else:
                print("\nNo future matches to preprocess or no features selected.")
                X_future_processed_df = pd.DataFrame() # Ensure it exists

    else: # This else corresponds to 'if not X_historical_raw.empty:'
        print("X_historical_raw is empty, skipping train/test split and preprocessing.")
        X_train_processed_df = pd.DataFrame()
        X_test_processed_df = pd.DataFrame()
        X_future_processed_df = pd.DataFrame()

print("\n--- End of Section 4: Data Preparation for Modeling ---")
# Outputs from this section:
# X_train_processed_df, X_test_processed_df (for model training and evaluation)
# y_train_home_goals, y_test_home_goals, y_train_away_goals, y_test_away_goals
# X_future_processed_df (for generating future recommendations)
# preprocessor (the fitted ColumnTransformer, needed for future data)

print("\nSample of processed and scaled training data (last 5 rows):")
print(X_train_processed_df.tail())

"""Section 5: Model Training (LightGBM for Goal Prediction)"""

import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.isotonic import IsotonicRegression
import matplotlib.pyplot as plt
import seaborn as sns

print("\n--- Section 5: Model Training (LightGBM for Goal Prediction) ---")

# X_train_processed_df, X_test_processed_df,
# y_train_home_goals, y_test_home_goals, y_train_away_goals, y_test_away_goals
# should be available from Section 4

# --- 1. Train a LightGBM model for Home Goals ---
print("\nTraining LightGBM model for Home Goals...")
params_home = {
    'objective': 'poisson', 'metric': 'poisson', 'boosting_type': 'gbdt',
    'num_leaves': 31, 'learning_rate': 0.05, 'feature_fraction': 0.8,
    'bagging_fraction': 0.8, 'bagging_freq': 5, 'verbose': -1,
    'n_estimators': 2000, 'seed': 42, 'n_jobs': -1
}

model_home_goals = lgb.LGBMRegressor(**params_home)
model_home_goals.fit(
    X_train_processed_df, y_train_home_goals,
    eval_set=[(X_test_processed_df, y_test_home_goals)],
    eval_metric='poisson',
    callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=True)]
)
print("Home Goals model training complete.")
pred_home_goals_test = model_home_goals.predict(X_test_processed_df)
pred_home_goals_test[pred_home_goals_test < 0] = 0

# --- 2. Train a LightGBM model for Away Goals ---
print("\nTraining LightGBM model for Away Goals...")
params_away = {
    'objective': 'poisson', 'metric': 'poisson', 'boosting_type': 'gbdt',
    'num_leaves': 31, 'learning_rate': 0.05, 'feature_fraction': 0.8,
    'bagging_fraction': 0.8, 'bagging_freq': 5, 'verbose': -1,
    'n_estimators': 2000, 'seed': 123, 'n_jobs': -1
}
model_away_goals = lgb.LGBMRegressor(**params_away)
model_away_goals.fit(
    X_train_processed_df, y_train_away_goals,
    eval_set=[(X_test_processed_df, y_test_away_goals)],
    eval_metric='poisson',
    callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=True)]
)
print("Away Goals model training complete.")
pred_away_goals_test = model_away_goals.predict(X_test_processed_df)
pred_away_goals_test[pred_away_goals_test < 0] = 0

# --- 3. Basic Evaluation of Goal Predictions ---
print("\n--- Model Evaluation (Goal Predictions on Test Set) ---")
mse_home = mean_squared_error(y_test_home_goals, pred_home_goals_test)
rmse_home = np.sqrt(mse_home)
mae_home = mean_absolute_error(y_test_home_goals, pred_home_goals_test)
print(f"Home Goals Model - Test Poisson Deviance (from training): {model_home_goals.best_score_['valid_0']['poisson']:.4f}")
print(f"Home Goals Model - Test RMSE: {rmse_home:.4f}, Test MAE: {mae_home:.4f}")

mse_away = mean_squared_error(y_test_away_goals, pred_away_goals_test)
rmse_away = np.sqrt(mse_away)
mae_away = mean_absolute_error(y_test_away_goals, pred_away_goals_test)
print(f"Away Goals Model - Test Poisson Deviance (from training): {model_away_goals.best_score_['valid_0']['poisson']:.4f}")
print(f"Away Goals Model - Test RMSE: {rmse_away:.4f}, Test MAE: {mae_away:.4f}")

# Store predictions in the test part of df_model_input for later use
test_indices = X_test_processed_df.index

# Initialize or ensure prediction columns are float and non-test rows are np.nan
if 'pred_home_goals' not in df_model_input.columns:
    df_model_input['pred_home_goals'] = np.nan
else:
    df_model_input['pred_home_goals'] = pd.to_numeric(df_model_input['pred_home_goals'], errors='coerce') # Coerce to float
    df_model_input.loc[~df_model_input.index.isin(test_indices), 'pred_home_goals'] = np.nan

if 'pred_away_goals' not in df_model_input.columns:
    df_model_input['pred_away_goals'] = np.nan
else:
    df_model_input['pred_away_goals'] = pd.to_numeric(df_model_input['pred_away_goals'], errors='coerce') # Coerce to float
    df_model_input.loc[~df_model_input.index.isin(test_indices), 'pred_away_goals'] = np.nan
# Now assign the test set predictions (which are already float arrays)
df_model_input.loc[test_indices, 'pred_home_goals'] = pred_home_goals_test
df_model_input.loc[test_indices, 'pred_away_goals'] = pred_away_goals_test
print("Predictions stored in df_model_input for the test set.")
# --- 4. Feature Importance ---
def plot_feature_importance(model, feature_names, model_name="Model"):
    if hasattr(model, 'feature_importances_') and feature_names is not None and not feature_names.empty:
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': model.feature_importances_
        }).sort_values(by='importance', ascending=False)
        num_to_plot = min(20, len(importance_df))
        if num_to_plot > 0:
            plt.figure(figsize=(12, max(6, num_to_plot // 1.5)))
            sns.barplot(x='importance', y='feature', data=importance_df.head(num_to_plot), palette="viridis")
            plt.title(f'Top {num_to_plot} Feature Importances - {model_name}')
            plt.tight_layout()
            plt.show()
        else:
            print(f"No features with importance > 0 to plot for {model_name}")
    else:
        print(f"Feature importances not available, feature names missing, or feature_names empty for {model_name}")

print("\nPlotting feature importances...")
if isinstance(X_train_processed_df, pd.DataFrame):
    plot_feature_importance(model_home_goals, X_train_processed_df.columns, "Home Goals Model")
    plot_feature_importance(model_away_goals, X_train_processed_df.columns, "Away Goals Model")
else:
    print("X_train_processed_df is not a DataFrame, cannot get column names for feature importance plot.")

print("\n--- End of Section 5: Model Training (LightGBM for Goal Prediction) ---")

"""Section 5.1: Hyperparameter Tuning for LightGBM Goal Models"""

# Ensure Optuna is available without using notebook magics
try:
    import optuna  # For hyperparameter optimization
except ImportError:  # pragma: no cover
    optuna = None
    print("Warning: 'optuna' is not installed. Please install it with: pip install optuna")

from sklearn.model_selection import KFold  # Kept for reference
from sklearn.model_selection import TimeSeriesSplit  # Robust CV for time series
from sklearn.metrics import mean_poisson_deviance # A good metric for Poisson objectives
from sklearn.isotonic import IsotonicRegression
import lightgbm as lgb
import numpy as np
import pandas as pd

print("\n--- Section 5.1: Hyperparameter Tuning for LightGBM Goal Models ---")

# Assuming X_train_processed_df, y_train_home_goals, y_train_away_goals are available
# For true time-series validation in tuning, TimeSeriesSplit is better.
# For simplicity here, using KFold, but be mindful of potential leakage if features have strong time trends not captured by shift(1).
# A proper setup would involve splitting the training data further into sub-train/sub-val for tuning.

def objective_lgbm(trial, X_train, y_train, target_name="goals", N_SPLITS: int = 5):
    """TimeSeriesSplit-based objective for robust hyperparameter tuning."""
    params = {
        'objective': 'poisson',
        'metric': 'poisson',
        'verbosity': -1,
        'boosting_type': 'gbdt',
        'n_estimators': trial.suggest_int('n_estimators', 400, 3000, step=100),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),
        'num_leaves': trial.suggest_int('num_leaves', 31, 255),
        'max_depth': trial.suggest_int('max_depth', 3, 14),
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 120),
        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),
        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),
        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),
        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),
        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),
        'seed': 42,
        'n_jobs': -1,
    }

    tscv = TimeSeriesSplit(n_splits=N_SPLITS)
    cv_scores = []
    best_iterations = []

    # Ensure DataFrame/Series for iloc
    X_train_df = X_train if isinstance(X_train, pd.DataFrame) else pd.DataFrame(X_train)
    y_train_sr = y_train if isinstance(y_train, pd.Series) else pd.Series(y_train)

    for train_idx, val_idx in tscv.split(X_train_df):
        X_tune_train, X_tune_val = X_train_df.iloc[train_idx], X_train_df.iloc[val_idx]
        y_tune_train, y_tune_val = y_train_sr.iloc[train_idx], y_train_sr.iloc[val_idx]

        model = lgb.LGBMRegressor(**params)
        model.fit(
            X_tune_train,
            y_tune_train,
            eval_set=[(X_tune_val, y_tune_val)],
            eval_metric='poisson',
            callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)],
        )

        if hasattr(model, 'best_score_') and 'valid_0' in model.best_score_ and 'poisson' in model.best_score_['valid_0']:
            cv_scores.append(model.best_score_['valid_0']['poisson'])
        if getattr(model, 'best_iteration_', None) is not None:
            best_iterations.append(model.best_iteration_)

    if not cv_scores:
        return float('inf')

    # Optionally record average best iteration for later use
    if best_iterations:
        trial.set_user_attr('best_iteration', int(np.mean(best_iterations)))

    return float(np.mean(cv_scores))


# --- Tune Home Goals Model ---
print("\nTuning Home Goals Model with Optuna...")
# Ensure X_train_processed_df and y_train_home_goals are correctly defined from Section 4
if optuna is None:
    print("Optuna not available. Skip tuning or install with: pip install optuna")
else:
    study_home = optuna.create_study(direction='minimize', study_name='LGBM Home Goals')
    study_home.optimize(lambda trial: objective_lgbm(trial, X_train_processed_df, y_train_home_goals, "Home Goals"),
                        n_trials=30) # Adjust n_trials as needed (e.g., 50-100 for better search)

    best_params_home = study_home.best_params
    print("Best hyperparameters for Home Goals Model:", best_params_home)

# --- Tune Away Goals Model ---
print("\nTuning Away Goals Model with Optuna...")
if optuna is None:
    print("Optuna not available. Skip tuning or install with: pip install optuna")
else:
    study_away = optuna.create_study(direction='minimize', study_name='LGBM Away Goals')
    study_away.optimize(lambda trial: objective_lgbm(trial, X_train_processed_df, y_train_away_goals, "Away Goals"),
                        n_trials=30) # Adjust n_trials

    best_params_away = study_away.best_params
    print("Best hyperparameters for Away Goals Model:", best_params_away)

# OPTIONAL but recommended: also store the best iteration if n_estimators was tuned with early stopping
# This assumes you added trial.set_user_attr('best_iteration', model.best_iteration_) in your objective
if optuna is not None:
    if 'best_iteration' in study_home.best_trial.user_attrs:
        best_iteration_home = study_home.best_trial.user_attrs['best_iteration']
        best_params_home['n_estimators'] = best_iteration_home
        print(f"Adjusted n_estimators for Home Model to best_iteration: {best_iteration_home}")

    if 'best_iteration' in study_away.best_trial.user_attrs:
        best_iteration_away = study_away.best_trial.user_attrs['best_iteration']
        best_params_away['n_estimators'] = best_iteration_away
        print(f"Adjusted n_estimators for Away Model to best_iteration: {best_iteration_away}")

print("\n--- End of Section 5 Addendum: Hyperparameter Tuning ---")
# Next: Re-train models in Section 5 using these best_params, then proceed to Section 6 (Dixon-Coles layer).

"""Section 5.2: Training Final Models with Optimal Hyperparameters"""

import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns

print("\n--- Section 5.2: Training Final Models with Optimal Hyperparameters ---")

# This section expects 'best_params_home' and 'best_params_away'
# (and potentially adjusted 'n_estimators' within them)
# to be defined from the successful execution of
# 'Section 5.1: Hyperparameter Tuning for LightGBM Models'.

# Check if the variables exist; if not, the user needs to run Section 5.1
if 'best_params_home' not in locals() or 'best_params_away' not in locals():
    print("ERROR: `best_params_home` or `best_params_away` not found in the current session.")
    print("Please ensure you have successfully run 'Section 5.1: Hyperparameter Tuning' first.")
    print("Stopping execution of Section 5.2.")
    # exit() # Or raise an error to halt the notebook if preferred
    # For now, if they are not defined, subsequent code will raise a NameError.
else:
    print("Using optimal parameters found by Optuna (Section 5.1) for tiered model training.")
    
    # --- NEW: Per-Tier Model Training ---
    print("\n--- Training Tier-Specific Models ---")
    
    # Get league tiers for training data
    train_tiers = df_model_input.loc[X_train_processed_df.index, 'league_tier'].fillna(5)
    test_tiers = df_model_input.loc[X_test_processed_df.index, 'league_tier'].fillna(5)
    
    # Train models for each tier (1-3, with tier 4+ as fallback)
    tier_models_home = {}
    tier_models_away = {}
    tier_calibrators_home = {}
    tier_calibrators_away = {}
    
    for tier in [1, 2, 3]:
        print(f"\n  Training models for Tier {tier}...")
        
        # Filter training data for this tier
        tier_train_mask = (train_tiers == tier)
        tier_test_mask = (test_tiers == tier)
        
        if tier_train_mask.sum() < 50:  # Need minimum data
            print(f"    Insufficient data for Tier {tier} ({tier_train_mask.sum()} samples), skipping...")
            continue
            
        X_train_tier = X_train_processed_df[tier_train_mask]
        y_train_home_tier = y_train_home_goals[tier_train_mask]
        y_train_away_tier = y_train_away_goals[tier_train_mask]
        
        X_test_tier = X_test_processed_df[tier_test_mask] if tier_test_mask.sum() > 0 else X_test_processed_df[:10]
        y_test_home_tier = y_test_home_goals[tier_test_mask] if tier_test_mask.sum() > 0 else y_test_home_goals[:10]
        y_test_away_tier = y_test_away_goals[tier_test_mask] if tier_test_mask.sum() > 0 else y_test_away_goals[:10]
        
        print(f"    Tier {tier}: {len(X_train_tier)} train, {len(X_test_tier)} test samples")
        
        # Train Home model for this tier
        model_home_tier = lgb.LGBMRegressor(**best_params_home)
        model_home_tier.fit(
            X_train_tier, y_train_home_tier,
            eval_set=[(X_test_tier, y_test_home_tier)],
            eval_metric='poisson',
            callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]
        )
        
        # Train Away model for this tier
        model_away_tier = lgb.LGBMRegressor(**best_params_away)
        model_away_tier.fit(
            X_train_tier, y_train_away_tier,
            eval_set=[(X_test_tier, y_test_away_tier)],
            eval_metric='poisson',
            callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]
        )
        
        tier_models_home[tier] = model_home_tier
        tier_models_away[tier] = model_away_tier
        
        # Fit tier-specific calibrators on test data
        if tier_test_mask.sum() > 10:  # Need minimum test data
            pred_home_tier = model_home_tier.predict(X_test_tier)
            pred_away_tier = model_away_tier.predict(X_test_tier)
            
            calib_home_tier = IsotonicRegression(out_of_bounds='clip')
            calib_away_tier = IsotonicRegression(out_of_bounds='clip')
            
            calib_home_tier.fit(pred_home_tier.reshape(-1, 1), y_test_home_tier)
            calib_away_tier.fit(pred_away_tier.reshape(-1, 1), y_test_away_tier)
            
            tier_calibrators_home[tier] = calib_home_tier
            tier_calibrators_away[tier] = calib_away_tier
            
            print(f"    Tier {tier} models and calibrators trained successfully")
    
    # Fallback: Train general models for all tiers (as before)
    print("\n  Training fallback models for all data...")
    final_model_home_goals = lgb.LGBMRegressor(**best_params_home)
    final_model_home_goals.fit(
        X_train_processed_df, y_train_home_goals,
        eval_set=[(X_test_processed_df, y_test_home_goals)],
        eval_metric='poisson',
        callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]
    )

    final_model_away_goals = lgb.LGBMRegressor(**best_params_away)
    final_model_away_goals.fit(
        X_train_processed_df, y_train_away_goals,
        eval_set=[(X_test_processed_df, y_test_away_goals)],
        eval_metric='poisson',
        callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]
    )
    
    print("Tier-specific and fallback models training complete.")

    # Generate tier-aware predictions for test set
    pred_home_goals_test_tuned = np.zeros(len(X_test_processed_df))
    pred_away_goals_test_tuned = np.zeros(len(X_test_processed_df))

    for i, tier in enumerate(test_tiers):
        tier_int = int(tier) if not pd.isna(tier) else 5
        
        if tier_int in tier_models_home and tier_int in tier_models_away:
            # Use tier-specific model
            pred_home_goals_test_tuned[i] = tier_models_home[tier_int].predict(X_test_processed_df.iloc[[i]])[0]
            pred_away_goals_test_tuned[i] = tier_models_away[tier_int].predict(X_test_processed_df.iloc[[i]])[0]
        else:
            # Use fallback model
            pred_home_goals_test_tuned[i] = final_model_home_goals.predict(X_test_processed_df.iloc[[i]])[0]
            pred_away_goals_test_tuned[i] = final_model_away_goals.predict(X_test_processed_df.iloc[[i]])[0]

    pred_home_goals_test_tuned[pred_home_goals_test_tuned < 0] = 0
    pred_away_goals_test_tuned[pred_away_goals_test_tuned < 0] = 0

# --- 3. Evaluation of Tuned Goal Predictions ---
print("\n--- Tuned Model Evaluation (Goal Predictions on Test Set) ---")
mse_home_tuned = mean_squared_error(y_test_home_goals, pred_home_goals_test_tuned)
rmse_home_tuned = np.sqrt(mse_home_tuned)
mae_home_tuned = mean_absolute_error(y_test_home_goals, pred_home_goals_test_tuned)
print(f"TUNED Home Goals Model - Test Poisson Deviance (from training): {final_model_home_goals.best_score_['valid_0']['poisson']:.4f}")
print(f"TUNED Home Goals Model - Test RMSE: {rmse_home_tuned:.4f}, Test MAE: {mae_home_tuned:.4f}")

mse_away_tuned = mean_squared_error(y_test_away_goals, pred_away_goals_test_tuned)
rmse_away_tuned = np.sqrt(mse_away_tuned)
mae_away_tuned = mean_absolute_error(y_test_away_goals, pred_away_goals_test_tuned)
print(f"TUNED Away Goals Model - Test Poisson Deviance (from training): {final_model_away_goals.best_score_['valid_0']['poisson']:.4f}")
print(f"TUNED Away Goals Model - Test RMSE: {rmse_away_tuned:.4f}, Test MAE: {mae_away_tuned:.4f}")


import joblib

# Fit isotonic calibration for home and away goal predictions (lambdas)
calib_home = IsotonicRegression(out_of_bounds='clip')
calib_home.fit(pred_home_goals_test_tuned.reshape(-1, 1), y_test_home_goals)

calib_away = IsotonicRegression(out_of_bounds='clip')
calib_away.fit(pred_away_goals_test_tuned.reshape(-1, 1), y_test_away_goals)

# Apply to test predictions
calibrated_home_test = calib_home.predict(pred_home_goals_test_tuned.reshape(-1, 1))
calibrated_away_test = calib_away.predict(pred_away_goals_test_tuned.reshape(-1, 1))

# Save calibrators - ensure artifact dirs exist
from pathlib import Path
if 'artifacts_dir' not in locals():
    timestamp_str = pd.Timestamp.utcnow().strftime('%Y%m%d_%H%M%S')
    artifacts_dir = Path(f"artifacts/{timestamp_str}")
    artifacts_dir.mkdir(parents=True, exist_ok=True)
if 'latest_dir' not in locals():
    latest_dir = Path("artifacts/latest")
    latest_dir.mkdir(parents=True, exist_ok=True)

joblib.dump(calib_home, artifacts_dir / 'calib_home_goals.joblib')
joblib.dump(calib_away, artifacts_dir / 'calib_away_goals.joblib')

import shutil
shutil.copy(artifacts_dir / 'calib_home_goals.joblib', latest_dir / 'calib_home_goals.joblib')
shutil.copy(artifacts_dir / 'calib_away_goals.joblib', latest_dir / 'calib_away_goals.joblib')

print("Isotonic calibrators for goal predictions fitted and saved.")

df_model_input.loc[test_indices, 'pred_home_goals'] = calibrated_home_test
df_model_input.loc[test_indices, 'pred_away_goals'] = calibrated_away_test
print("TUNED and CALIBRATED predictions stored in df_model_input for the test set.")

# Note: Calibrated predictions already stored above, no need to overwrite

# --- 4. Feature Importance of Tuned Models ---
# (Using the same plot_feature_importance function as defined in your original Section 5)
def plot_feature_importance(model, feature_names, model_name="Model"):
    if hasattr(model, 'feature_importances_') and feature_names is not None and not feature_names.empty:
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': model.feature_importances_
        }).sort_values(by='importance', ascending=False)
        num_to_plot = min(20, len(importance_df))
        if num_to_plot > 0:
            plt.figure(figsize=(12, max(6, num_to_plot // 1.5)))
            sns.barplot(x='importance', y='feature', data=importance_df.head(num_to_plot), palette="viridis")
            plt.title(f'Top {num_to_plot} Feature Importances - {model_name} (Tuned)')
            plt.tight_layout()
            plt.show()
        else: print(f"No features with importance > 0 to plot for {model_name}")
    else: print(f"Feature importances not available or names missing for {model_name}")

print("\nPlotting feature importances for TUNED models...")
if isinstance(X_train_processed_df, pd.DataFrame):
    plot_feature_importance(final_model_home_goals, X_train_processed_df.columns, "Home Goals Model (Tuned)")
    plot_feature_importance(final_model_away_goals, X_train_processed_df.columns, "Away Goals Model (Tuned)")
else:
    print("X_train_processed_df is not a DataFrame, cannot get column names for feature importance plot.")

print("\n--- End of Section 5.2: Training Final Models with Optimal Hyperparameters ---")

"""Section 5.4 (NEW): Model Artifact Persistence"""

import json
from pathlib import Path
import joblib

print("\n--- Section 5.4 (NEW): Model Artifact Persistence ---")
try:
    timestamp_str = pd.Timestamp.utcnow().strftime('%Y%m%d_%H%M%S')
    artifacts_dir = Path(f"artifacts/{timestamp_str}")
    artifacts_dir.mkdir(parents=True, exist_ok=True)
    latest_dir = Path("artifacts/latest")
    if latest_dir.exists():
        import shutil as _shutil
        _shutil.rmtree(latest_dir)
    latest_dir.mkdir(parents=True, exist_ok=True)

    # Save tuned model boosters if available; otherwise fall back to final models
    try:
        (final_model_home_goals.booster_ if hasattr(final_model_home_goals, 'booster_') else final_model_home_goals).save_model(str(artifacts_dir/"lgb_home.txt"))
        (final_model_away_goals.booster_ if hasattr(final_model_away_goals, 'booster_') else final_model_away_goals).save_model(str(artifacts_dir/"lgb_away.txt"))
        _shutil.copy(artifacts_dir/"lgb_home.txt", latest_dir/"lgb_home.txt")
        _shutil.copy(artifacts_dir/"lgb_away.txt", latest_dir/"lgb_away.txt")
        
        # Save tier-specific models
        if 'tier_models_home' in locals():
            for tier, model in tier_models_home.items():
                (model.booster_ if hasattr(model, 'booster_') else model).save_model(str(artifacts_dir/f"lgb_home_tier{tier}.txt"))
                _shutil.copy(artifacts_dir/f"lgb_home_tier{tier}.txt", latest_dir/f"lgb_home_tier{tier}.txt")
        
        if 'tier_models_away' in locals():
            for tier, model in tier_models_away.items():
                (model.booster_ if hasattr(model, 'booster_') else model).save_model(str(artifacts_dir/f"lgb_away_tier{tier}.txt"))
                _shutil.copy(artifacts_dir/f"lgb_away_tier{tier}.txt", latest_dir/f"lgb_away_tier{tier}.txt")
        
        # Save tier-specific calibrators
        if 'tier_calibrators_home' in locals():
            for tier, calib in tier_calibrators_home.items():
                joblib.dump(calib, artifacts_dir/f"calib_home_tier{tier}.joblib")
                _shutil.copy(artifacts_dir/f"calib_home_tier{tier}.joblib", latest_dir/f"calib_home_tier{tier}.joblib")
        
        if 'tier_calibrators_away' in locals():
            for tier, calib in tier_calibrators_away.items():
                joblib.dump(calib, artifacts_dir/f"calib_away_tier{tier}.joblib")
                _shutil.copy(artifacts_dir/f"calib_away_tier{tier}.joblib", latest_dir/f"calib_away_tier{tier}.joblib")
        
        print("Models and tier-specific artifacts saved.")
    except Exception as e:
        print(f"Model save skipped: {e}")

    try:
        joblib.dump(preprocessor, artifacts_dir/"preprocessor.joblib")
        import shutil as _shutil
        _shutil.copy(artifacts_dir/"preprocessor.joblib", latest_dir/"preprocessor.joblib")
        print("Preprocessor saved.")
    except Exception as e:
        print(f"Preprocessor save skipped: {e}")

    # Save BVP phi params if defined later; we will append/update in Section 6 when available
    (artifacts_dir/"bvp.json").write_text(json.dumps({}, indent=2))
    import shutil as _shutil
    _shutil.copy(artifacts_dir/"bvp.json", latest_dir/"bvp.json")
    print("Initialized BVP params file.")
except Exception as e:
    print(f"Artifact persistence error: {e}")

"""Section 6: Deriving Probabilities and Calculating EV"""

import pandas as pd
import numpy as np
from scipy.stats import poisson # For individual Poisson terms if needed, or comparison
from scipy.optimize import minimize
from math import factorial, exp, pow, lgamma # Using lgamma for log(factorial) can be more stable

print("\n--- Section 6: Deriving Scoreline Probabilities (Bivariate Poisson Layer) ---")

# Ensure necessary variables from previous sections are available:
# df_model_input (with original odds for test set)
# X_train_processed_df, X_test_processed_df (for predictions)
# final_model_home_goals, final_model_away_goals (tuned LightGBM models from Sec 5.2)
# y_train_home_goals, y_train_away_goals (actual scores for training set from Sec 4)
# test_matches_df (created in your previous attempt at Sec 6, or we can recreate the slice)

# --- 1. Get LightGBM Mean Goal Predictions for the TRAINING SET ---
print("Generating LightGBM mean goal predictions for the TRAINING set...")
# Ensure X_train_processed_df is defined from Section 4
if 'X_train_processed_df' not in locals():
    print("Error: X_train_processed_df is not defined. Please run Section 4.")
    # exit() # Or raise error
else:
    pred_home_goals_train = final_model_home_goals.predict(X_train_processed_df)
    pred_away_goals_train = final_model_away_goals.predict(X_train_processed_df)
    pred_home_goals_train[pred_home_goals_train < 0] = 1e-6 # Floor at a tiny positive value
    pred_away_goals_train[pred_away_goals_train < 0] = 1e-6 # Floor at a tiny positive value

# --- 2. Define Bivariate Poisson Probability Mass Function (Karlis & Ntzoufras, 2003 type) ---
# P(X=x, Y=y | lambda1, lambda2, phi) where phi=Cov(X,Y)
# Constraint: 0 <= phi <= min(lambda1, lambda2)
def biv_poisson_pmf(x, y, lambda1, lambda2, phi, max_k_sum=20):
    x = int(x) # Ensure integer scores
    y = int(y)

    if pd.isna(lambda1) or pd.isna(lambda2) or pd.isna(phi) or \
       lambda1 <= 0 or lambda2 <= 0: # Lambdas must be positive for this PMF form
        return 1e-100 # Effectively zero if lambdas are invalid

    # Ensure phi is valid for given lambdas for this specific calculation
    # The optimizer will handle global bounds, but PMF needs valid inputs.
    current_phi = max(0, min(phi, lambda1 - 1e-7, lambda2 - 1e-7)) # Ensure lambda_i - phi >= 0

    try:
        if (lambda1 + lambda2 - current_phi) < 0 : # Should not happen if current_phi is constrained
             return 1e-100

        log_exp_term = -(lambda1 + lambda2 - current_phi)

        log_prob_sum_terms = []
        for k in range(min(x, y, max_k_sum) + 1):
            # Using log gamma for log(factorial) for better numerical stability
            log_fact_xk = lgamma(x - k + 1)
            log_fact_yk = lgamma(y - k + 1)
            log_fact_k = lgamma(k + 1)

            # Calculate log of terms to sum later using log-sum-exp if needed, or sum directly if values are small
            # log( (lambda1-phi)^(x-k) ) = (x-k) * log(lambda1-phi)

            val_lambda1_minus_phi = lambda1 - current_phi
            val_lambda2_minus_phi = lambda2 - current_phi

            if val_lambda1_minus_phi < 0 or val_lambda2_minus_phi <0 : # Should be caught by phi constraint
                log_term1 = -np.inf
                log_term2 = -np.inf
            else:
                log_term1 = (x - k) * np.log(val_lambda1_minus_phi) if val_lambda1_minus_phi > 1e-9 else -np.inf # Avoid log(0)
                log_term2 = (y - k) * np.log(val_lambda2_minus_phi) if val_lambda2_minus_phi > 1e-9 else -np.inf

            log_term3 = k * np.log(current_phi) if current_phi > 1e-9 else -np.inf

            current_log_sum_term = log_term1 - log_fact_xk + \
                                   log_term2 - log_fact_yk + \
                                   log_term3 - log_fact_k
            log_prob_sum_terms.append(current_log_sum_term)

        # Log-Sum-Exp trick for stability if summing probabilities directly underflows
        if not log_prob_sum_terms: return 1e-100
        max_log_term = np.nanmax(log_prob_sum_terms)
        if max_log_term == -np.inf: return 1e-100

        sum_exp_terms = np.sum(np.exp(np.array(log_prob_sum_terms) - max_log_term))
        log_sum_val = max_log_term + np.log(sum_exp_terms)

        final_log_prob = log_exp_term + log_sum_val
        return exp(final_log_prob)

    except (ValueError, OverflowError):
        return 1e-100

# --- 3. Define Negative Log-Likelihood Function ---
def neg_log_likelihood_biv_poisson(phi_param, actual_h_goals, actual_a_goals, pred_l_home, pred_l_away):
    phi = phi_param[0]
    log_likelihood = 0.0

    num_matches = len(actual_h_goals)
    for i in range(num_matches):
        h_goals_actual = actual_h_goals[i] # Assuming these are already int/float
        a_goals_actual = actual_a_goals[i]
        lambda_h_pred = pred_l_home[i]
        lambda_a_pred = pred_l_away[i]

        # Calculate probability for observed scoreline
        # biv_poisson_pmf will internally handle phi constraints for the specific lambda pair
        prob = biv_poisson_pmf(h_goals_actual, a_goals_actual, lambda_h_pred, lambda_a_pred, phi)

        if prob > 1e-12:
            log_likelihood += np.log(prob)
        else:
            log_likelihood -= 25 # Penalize very low probabilities (log(1e-12) is around -27)

    return -log_likelihood

# --- 4. Prepare Data and Optimize for the global 'phi' parameter ---
print("\nOptimizing for the covariance parameter 'phi' using the training set...")

# Ensure y_train arrays are numpy for clean masking
y_h_train_np = y_train_home_goals.to_numpy() if isinstance(y_train_home_goals, pd.Series) else np.array(y_train_home_goals)
y_a_train_np = y_train_away_goals.to_numpy() if isinstance(y_train_away_goals, pd.Series) else np.array(y_train_away_goals)

train_mask = (~np.isnan(y_h_train_np)) & (~np.isnan(y_a_train_np)) & \
             (~np.isnan(pred_home_goals_train)) & (~np.isnan(pred_away_goals_train))
y_h_train_clean = y_h_train_np[train_mask].astype(int) # Ensure integer goals
y_a_train_clean = y_a_train_np[train_mask].astype(int)
l_h_train_clean = pred_home_goals_train[train_mask]
l_a_train_clean = pred_away_goals_train[train_mask]
print(f"Number of clean training samples for phi optimization after initial NaN filter: {len(y_h_train_clean)}")
# Further filter for matches where lambdas are reasonably positive (BVP constraint)
min_lambda_for_phi_fit = 0.05 # Avoid issues with very small lambdas for phi constraint
valid_lambda_mask = (l_h_train_clean >= min_lambda_for_phi_fit) & (l_a_train_clean >= min_lambda_for_phi_fit)
y_h_train_final = y_h_train_clean[valid_lambda_mask]
y_a_train_final = y_a_train_clean[valid_lambda_mask]
l_h_train_final = l_h_train_clean[valid_lambda_mask]
l_a_train_final = l_a_train_clean[valid_lambda_mask]
print(f"Number of training samples for phi optimization after lambda filter: {len(y_h_train_final)}")
optimal_phi = 0.01  # Default/fallback phi
phi_model = None
if len(y_h_train_final) > 50:
    print("Training regression model for phi parameter...")
    
    # Create features for phi prediction
    phi_features = pd.DataFrame({
        'lambda_home': l_h_train_final,
        'lambda_away': l_a_train_final,
        'lambda_total': l_h_train_final + l_a_train_final,
        'lambda_diff': l_h_train_final - l_a_train_final,
        'lambda_min': np.minimum(l_h_train_final, l_a_train_final),
        'lambda_max': np.maximum(l_h_train_final, l_a_train_final),
        'lambda_ratio': l_h_train_final / (l_a_train_final + 1e-6),
        'lambda_product': l_h_train_final * l_a_train_final
    })
    
    # Calculate optimal phi for each match through grid search
    optimal_phis = []
    print("  Computing optimal phi values for training samples...")
    
    for i in range(len(y_h_train_final)):
        if i % 100 == 0:
            print(f"    Processing sample {i}/{len(y_h_train_final)}")
        
        h_goals, a_goals = y_h_train_final[i], y_a_train_final[i]
        lambda_h, lambda_a = l_h_train_final[i], l_a_train_final[i]
        
        # Grid search for best phi for this specific match
        phi_candidates = np.linspace(0.001, min(lambda_h, lambda_a) * 0.95, 20)
        best_phi = 0.01
        best_prob = 1e-100
        
        for phi_candidate in phi_candidates:
            prob = biv_poisson_pmf(h_goals, a_goals, lambda_h, lambda_a, phi_candidate)
            if prob > best_prob:
                best_prob = prob
                best_phi = phi_candidate
        
        optimal_phis.append(best_phi)
    
    optimal_phis = np.array(optimal_phis)
    
    # Train regression model to predict phi from features
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import mean_squared_error
    
    # Split data for phi model training
    X_phi_train, X_phi_test, y_phi_train, y_phi_test = train_test_split(
        phi_features, optimal_phis, test_size=0.2, random_state=42
    )
    
    # Train phi regression model
    phi_model = RandomForestRegressor(
        n_estimators=100, max_depth=8, min_samples_split=10,
        random_state=42, n_jobs=-1
    )
    phi_model.fit(X_phi_train, y_phi_train)
    
    # Evaluate phi model
    phi_pred_test = phi_model.predict(X_phi_test)
    phi_mse = mean_squared_error(y_phi_test, phi_pred_test)
    phi_mean = np.mean(optimal_phis)
    
    print(f"  Phi model trained - MSE: {phi_mse:.6f}, Mean phi: {phi_mean:.4f}")
    
    # Save phi model
    joblib.dump(phi_model, artifacts_dir / 'phi_model.joblib')
    shutil.copy(artifacts_dir / 'phi_model.joblib', latest_dir / 'phi_model.joblib')
    
    # For backward compatibility, also compute segmented phis as fallback
    l_total_train = l_h_train_final + l_a_train_final
    bins = [0.0, 2.3, 3.0, 99.0]
    labels = ['low_scoring', 'medium_scoring', 'high_scoring']
    segments = pd.cut(l_total_train, bins=bins, labels=labels)
    
    optimized_phis_by_segment = {}
    for segment_label in labels:
        segment_mask = (segments == segment_label)
        if segment_mask.sum() > 5:
            segment_phi = np.mean(optimal_phis[segment_mask])
            optimized_phis_by_segment[segment_label] = segment_phi
            print(f"  Segment {segment_label}: phi = {segment_phi:.4f}")
    
    optimal_phi = phi_mean  # Update global fallback
    print("Phi regression model training complete.")
else:
    print("Insufficient data for phi model training, using simple optimization...")
    # Fallback to simple segmented approach
    l_total_train = l_h_train_final + l_a_train_final
    bins = [0.0, 2.3, 3.0, 99.0]
    labels = ['low_scoring', 'medium_scoring', 'high_scoring']
    segments = pd.cut(l_total_train, bins=bins, labels=labels)

    min_of_pair_lambdas = np.minimum(l_h_train_final, l_a_train_final)
    phi_upper_bound_global = max(1e-5, float(np.min(min_of_pair_lambdas)) * 0.99)
    initial_phi_guess_global = min(0.1, phi_upper_bound_global * 0.5)
    try:
        res_global = minimize(
            neg_log_likelihood_biv_poisson,
            x0=[initial_phi_guess_global],
            args=(y_h_train_final, y_a_train_final, l_h_train_final, l_a_train_final),
            bounds=[(0, phi_upper_bound_global)],
            method='L-BFGS-B',
            options={'ftol': 1e-7, 'maxiter': 200}
        )
        if res_global.success and res_global.x[0] >= 0:
            optimal_phi = float(res_global.x[0])
    except Exception as e:
        print(f"Global phi optimization failed, using default. Reason: {e}")

    for seg in labels:
        mask = (segments == seg)
        if int(mask.sum()) < 50:
            optimized_phis_by_segment[seg] = optimal_phi
            continue
        y_h_seg = y_h_train_final[mask]
        y_a_seg = y_a_train_final[mask]
        l_h_seg = l_h_train_final[mask]
        l_a_seg = l_a_train_final[mask]
        min_pair_seg = np.minimum(l_h_seg, l_a_seg)
        phi_upper_bound_seg = max(1e-5, float(np.min(min_pair_seg)) * 0.99)
        initial_phi_guess_seg = min(optimal_phi, phi_upper_bound_seg * 0.8)
        try:
            res_seg = minimize(
                neg_log_likelihood_biv_poisson,
                x0=[initial_phi_guess_seg],
                args=(y_h_seg, y_a_seg, l_h_seg, l_a_seg),
                bounds=[(0, phi_upper_bound_seg)],
                method='L-BFGS-B'
            )
            if res_seg.success and res_seg.x[0] >= 0:
                optimized_phis_by_segment[seg] = float(res_seg.x[0])
            else:
                optimized_phis_by_segment[seg] = optimal_phi
        except Exception as e:
            print(f"Phi optimization for segment '{seg}' failed, using global. Reason: {e}")
            optimized_phis_by_segment[seg] = optimal_phi

    print(f"Dynamically optimized phi by segment: {optimized_phis_by_segment}")
    # Persist phi parameters into artifacts/latest if present
    try:
        import json, shutil
        from pathlib import Path
        bvp_payload = {"phi_global": float(optimal_phi), "phi_by_segment": optimized_phis_by_segment}
        # Update latest and timestamped bvp.json if Section 5.4 prepared them
        latest_file = Path("artifacts/latest/bvp.json")
        if latest_file.exists():
            latest_file.write_text(json.dumps(bvp_payload, indent=2))
        # Also attempt to update the most recent timestamped dir
        artifacts_root = Path("artifacts")
        candidates = sorted([p for p in artifacts_root.iterdir() if p.is_dir() and p.name != 'latest'], reverse=True)
        if candidates:
            (candidates[0]/"bvp.json").write_text(json.dumps(bvp_payload, indent=2))
        print("BVP parameters persisted to artifacts.")
    except Exception as e:
        print(f"Skipping BVP artifact persistence: {e}")


# --- 5. Generate Scoreline Probability Matrix for Test Set Matches ---
print("\nGenerating scoreline probability matrices for test set matches...")
MAX_GOALS_FOR_MATRIX = 7 # Generate matrix up to e.g., 7-7

# Get LightGBM predictions for the TEST SET (already done in Section 5, stored in df_model_input)
# Filter for the test set rows and get predictions
test_matches_df = df_model_input.loc[X_test_processed_df.index].copy()
test_matches_df['pred_home_goals'] = pd.to_numeric(test_matches_df['pred_home_goals'], errors='coerce').fillna(0.01) # from sec 5
test_matches_df['pred_away_goals'] = pd.to_numeric(test_matches_df['pred_away_goals'], errors='coerce').fillna(0.01) # from sec 5
# Ensure positive lambdas for PMF
test_matches_df['pred_home_goals'] = np.maximum(1e-6, test_matches_df['pred_home_goals'])
test_matches_df['pred_away_goals'] = np.maximum(1e-6, test_matches_df['pred_away_goals'])


scoreline_matrices = []
for index, row in test_matches_df.iterrows():
    lambda_h = row['pred_home_goals']
    lambda_a = row['pred_away_goals']

    prob_matrix = np.zeros((MAX_GOALS_FOR_MATRIX + 1, MAX_GOALS_FOR_MATRIX + 1))
    
    # Use learned phi model if available
    if phi_model is not None:
        phi_features_match = pd.DataFrame({
            'lambda_home': [lambda_h],
            'lambda_away': [lambda_a],
            'lambda_total': [lambda_h + lambda_a],
            'lambda_diff': [lambda_h - lambda_a],
            'lambda_min': [min(lambda_h, lambda_a)],
            'lambda_max': [max(lambda_h, lambda_a)],
            'lambda_ratio': [lambda_h / (lambda_a + 1e-6)],
            'lambda_product': [lambda_h * lambda_a]
        })
        predicted_phi = phi_model.predict(phi_features_match)[0]
        seg_phi = predicted_phi
    else:
        # Fallback to segment-based phi
        total_l = float(lambda_h + lambda_a)
        if 'optimized_phis_by_segment' in globals() and optimized_phis_by_segment:
            if total_l < 2.3:
                seg_phi = optimized_phis_by_segment.get('low_scoring', optimal_phi)
            elif total_l <= 3.0:
                seg_phi = optimized_phis_by_segment.get('medium_scoring', optimal_phi)
            else:
                seg_phi = optimized_phis_by_segment.get('high_scoring', optimal_phi)
        else:
            seg_phi = optimal_phi
    
    # Apply per-match constraint
    current_match_phi = max(0.0, min(float(seg_phi), float(lambda_h) - 1e-7, float(lambda_a) - 1e-7))

    for i in range(MAX_GOALS_FOR_MATRIX + 1): # Home goals
        for j in range(MAX_GOALS_FOR_MATRIX + 1): # Away goals
            prob_matrix[i, j] = biv_poisson_pmf(i, j, lambda_h, lambda_a, current_match_phi)

    matrix_sum = np.sum(prob_matrix)
    if matrix_sum > 1e-9:
        prob_matrix /= matrix_sum
    else:
        prob_matrix = np.full(((MAX_GOALS_FOR_MATRIX + 1), (MAX_GOALS_FOR_MATRIX + 1)),
                              1.0 / ((MAX_GOALS_FOR_MATRIX + 1)**2))
    scoreline_matrices.append(prob_matrix)

test_matches_df['scoreline_prob_matrix'] = scoreline_matrices
print(f"Scoreline probability matrices generated for {len(scoreline_matrices)} test matches.")

# --- Display a sample matrix and derived 1X2 probabilities (for verification) ---
if not test_matches_df.empty and 'scoreline_prob_matrix' in test_matches_df.columns:
    print("\nSample Scoreline Matrix (first test match, if available):")
    if not test_matches_df['scoreline_prob_matrix'].empty:
        print(pd.DataFrame(test_matches_df['scoreline_prob_matrix'].iloc[0]))
    else:
        print("No scoreline matrices to display.")

    model_prob_home_win_biv = []
    model_prob_draw_biv = []
    model_prob_away_win_biv = []
    for matrix in test_matches_df['scoreline_prob_matrix']:
        p_h, p_d, p_a = 0.0, 0.0, 0.0
        if isinstance(matrix, np.ndarray): # Check if matrix is valid
            for r in range(matrix.shape[0]):      # home goals (row index)
                for c in range(matrix.shape[1]):  # away goals (col index)
                    if r > c: p_h += matrix[r, c]
                    elif r == c: p_d += matrix[r, c]
                    else: p_a += matrix[r, c]
        model_prob_home_win_biv.append(p_h if isinstance(matrix, np.ndarray) else np.nan)
        model_prob_draw_biv.append(p_d if isinstance(matrix, np.ndarray) else np.nan)
        model_prob_away_win_biv.append(p_a if isinstance(matrix, np.ndarray) else np.nan)

    test_matches_df['model_prob_home_win_biv'] = model_prob_home_win_biv
    test_matches_df['model_prob_draw_biv'] = model_prob_draw_biv
    test_matches_df['model_prob_away_win_biv'] = model_prob_away_win_biv

    print("\nSample 1X2 probabilities derived from Bivariate Poisson scoreline matrices:")
    print(test_matches_df[['home_name', 'away_name', 'model_prob_home_win_biv', 'model_prob_draw_biv', 'model_prob_away_win_biv']].head())

    print("\nRe-calculating Expected Value (EV) using Bivariate Poisson probabilities...")
    test_matches_df['ev_home_win_biv'] = (test_matches_df['model_prob_home_win_biv'] * pd.to_numeric(test_matches_df['odds_ft_1'], errors='coerce')) - 1
    test_matches_df['ev_draw_biv'] = (test_matches_df['model_prob_draw_biv'] * pd.to_numeric(test_matches_df['odds_ft_x'], errors='coerce')) - 1
    test_matches_df['ev_away_win_biv'] = (test_matches_df['model_prob_away_win_biv'] * pd.to_numeric(test_matches_df['odds_ft_2'], errors='coerce')) - 1
    print("EV calculations with Bivariate Poisson probabilities complete.")
    print(test_matches_df[['ev_home_win_biv', 'ev_draw_biv', 'ev_away_win_biv']].head())
else:
    print("No test matches or scoreline matrices to process for sample display.")

print("\n--- End of Section 6: Deriving Scoreline Probabilities (Bivariate Poisson Layer) ---")
# Next: Section 6.5 (AH Probability Calculation using these scoreline_prob_matrix)
# Then: Section 7 (Backtesting using these new probabilities and EVs, especially for AH)

"""Section 6.5: Asian Handicap (AH) Probability Calculation"""

import pandas as pd
import numpy as np

print("\n--- Section 6.5 (NEW): Asian Handicap (AH) Probability Calculation ---")

# We assume 'test_matches_df' is available from Section 6 and contains
# the 'scoreline_prob_matrix' column, 'homeGoalCount', 'awayGoalCount'.
# MAX_GOALS_FOR_MATRIX was also defined in Section 6 (e.g., 7). Let's redefine for safety.
MAX_GOALS_FOR_MATRIX = 7 # Ensure this matches what was used to generate the matrices

if 'scoreline_prob_matrix' not in test_matches_df.columns:
    print("Error: 'scoreline_prob_matrix' not found in test_matches_df. Please run Section 6 first.")
    # exit() # Or handle error
else:
    print(f"Calculating Asian Handicap probabilities for {len(test_matches_df)} test matches.")

    def calculate_ah_probabilities(score_matrix, ah_line_home):
        """
        Calculates probabilities for Home team covering the AH line, Away covering, and Push.
        ah_line_home: The handicap line for the home team (e.g., -0.5, -0.75, 0, +0.25).

        Returns: (prob_home_covers, prob_away_covers, prob_push)
        """
        if not isinstance(score_matrix, np.ndarray) or \
           score_matrix.shape != (MAX_GOALS_FOR_MATRIX + 1, MAX_GOALS_FOR_MATRIX + 1) or \
           pd.isna(score_matrix).all():
            return np.nan, np.nan, np.nan # Invalid matrix

        prob_home_win_ah = 0.0  # Home team covers the handicap
        prob_away_win_ah = 0.0  # Away team covers the handicap (Home team fails to cover)
        prob_push_ah = 0.0      # Bet is a push

        for home_goals in range(MAX_GOALS_FOR_MATRIX + 1):
            for away_goals in range(MAX_GOALS_FOR_MATRIX + 1):
                prob_score = score_matrix[home_goals, away_goals]
                if pd.isna(prob_score) or prob_score == 0:
                    continue

                # Effective score for home team after handicap
                effective_home_score = home_goals + ah_line_home

                # Determine AH outcome
                if effective_home_score > away_goals: # Home wins on handicap
                    prob_home_win_ah += prob_score
                elif effective_home_score < away_goals: # Home loses on handicap (Away wins)
                    prob_away_win_ah += prob_score
                else: # It's a push on the handicap
                    prob_push_ah += prob_score

        return prob_home_win_ah, prob_away_win_ah, prob_push_ah

    # Define common AH lines to calculate probabilities for
    # For quarter lines (-0.25, -0.75), we calculate for the two constituent full/half lines
    # and then average the outcomes or split the stake.
    # For simplicity here, we'll calculate P(Win), P(Lose), P(Push) for main lines.
    # For AH -0.25: Win if team wins. Half loss if draw. Loss if team loses.
    # P(Home Win -0.25) = P(Home outright win)
    # P(Home Lose -0.25) = P(Home outright loss) + 0.5 * P(Draw)
    # P(Home Push -0.25) = 0 (no full push)
    # P(Home Half Win -0.25) = 0
    # P(Home Half Lose -0.25) = 0.5 * P(Draw)

    # Let's define a more general function for quarter ball outcomes
    def calculate_ah_outcome_probabilities_split(score_matrix, ah_line_home_team):
        """
        Calculates probabilities for Home Win, Home Loss, Push, Home Half-Win, Home Half-Loss
        for a given Asian Handicap line (including quarter lines).
        ah_line_home_team: e.g., -0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75
        """
        if not isinstance(score_matrix, np.ndarray) or \
           score_matrix.shape != (MAX_GOALS_FOR_MATRIX + 1, MAX_GOALS_FOR_MATRIX + 1) or \
           pd.isna(score_matrix).all():
            return {'win': np.nan, 'loss': np.nan, 'push': np.nan, 'half_win': np.nan, 'half_loss': np.nan}

        p_win, p_loss, p_push, p_half_win, p_half_loss = 0.0, 0.0, 0.0, 0.0, 0.0

        for h_goals in range(MAX_GOALS_FOR_MATRIX + 1):
            for a_goals in range(MAX_GOALS_FOR_MATRIX + 1):
                prob_score = score_matrix[h_goals, a_goals]
                if pd.isna(prob_score) or prob_score == 0:
                    continue

                margin = h_goals - a_goals # Home goal margin

                # Outcome relative to home_team_handicap
                # Example: Home -0.75.
                # If Home wins by 2+ (margin >= 2), e.g., 2-0. Effective margin = margin + ah_line = 2 + (-0.75) = 1.25 > 0. Win.
                # If Home wins by 1 (margin == 1), e.g., 1-0. Effective margin = 1 + (-0.75) = 0.25 > 0. Half Win.
                # If Draw (margin == 0), e.g., 0-0. Effective margin = 0 + (-0.75) = -0.75 < 0. Half Loss.
                # If Home loses (margin < 0), e.g., 0-1. Effective margin = -1 + (-0.75) = -1.75 < 0. Loss.

                effective_margin = margin + ah_line_home_team

                if effective_margin > 0.25: # Clear win (e.g., > +0.25 for lines like 0, -0.5, -0.75 etc.)
                    p_win += prob_score
                elif effective_margin == 0.25: # Half win (for lines like -0.75, +0.25)
                    p_half_win += prob_score
                elif effective_margin == 0: # Push (for lines like 0, -1.0, +1.0)
                    p_push += prob_score
                elif effective_margin == -0.25: # Half loss (for lines like -0.25, +0.75)
                    p_half_loss += prob_score
                else: # effective_margin < -0.25, Clear loss
                    p_loss += prob_score

        return {'win': p_win, 'loss': p_loss, 'push': p_push, 'half_win': p_half_win, 'half_loss': p_half_loss}

    # --- Define the AH lines you are interested in for the Home team ---
    # (Negative means home team gives handicap, positive means home team receives handicap)
    # We will calculate P(Home team covers this line)
    ah_lines_to_calculate = [-2.0, -1.75, -1.5, -1.25, -1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0]
    # You mentioned you're not keen on >2 goals, so this range is reasonable.

    # Collect all new columns in a dict to concat at once (avoids fragmentation)
    new_cols = {}
    
    for line in ah_lines_to_calculate:
        col_name_p_home_covers = f'p_home_covers_ah_{str(line).replace(".", "p")}' # e.g., p_home_covers_ah_-0p5
        # Store probabilities of different outcomes for this line
        col_win = f'p_home_win_ah_{str(line).replace(".", "p")}'
        col_loss = f'p_home_lose_ah_{str(line).replace(".", "p")}'
        col_push = f'p_home_push_ah_{str(line).replace(".", "p")}'
        col_half_win = f'p_home_hw_ah_{str(line).replace(".", "p")}'
        col_half_loss = f'p_home_hl_ah_{str(line).replace(".", "p")}'

        outcomes_list = []
        for matrix in test_matches_df['scoreline_prob_matrix']:
            outcomes = calculate_ah_outcome_probabilities_split(matrix, line)
            outcomes_list.append(outcomes)

        temp_outcomes_df = pd.DataFrame(outcomes_list, index=test_matches_df.index)

        new_cols[col_win] = temp_outcomes_df['win']
        new_cols[col_loss] = temp_outcomes_df['loss']
        new_cols[col_push] = temp_outcomes_df['push']
        new_cols[col_half_win] = temp_outcomes_df['half_win']
        new_cols[col_half_loss] = temp_outcomes_df['half_loss']

        # For EV calculation, P(Home Covers) often means P(Win) + 0.5 * P(Half-Win) - 0.5 * P(Half-Loss)
        # Or more simply, if odds are for winning the bet: P(Win) + P(Half-Win)
        # If odds are for "not losing the bet": P(Win) + P(Half-Win) + P(Push)
        # Let's define P(Home Covers) as the probability of a positive return on a "Home AH line" bet
        new_cols[col_name_p_home_covers] = temp_outcomes_df['win'] + \
                                           0.5 * temp_outcomes_df['half_win'] - \
                                           0.5 * temp_outcomes_df['half_loss']
                                           # Note: P(Push) means stake returned, EV contribution is 0 for that part.

        # Also calculate P(Away Covers AH -Line)
        # If Home is -0.75, Away is +0.75.
        # P(Away Covers +0.75) = P(Home Loses on -0.75) + 0.5 * P(Home Half-Loses on -0.75)
        col_name_p_away_covers = f'p_away_covers_ah_{str(-line).replace(".", "p")}' # e.g., p_away_covers_ah_0p75
        new_cols[col_name_p_away_covers] = temp_outcomes_df['loss'] + \
                                           0.5 * temp_outcomes_df['half_loss'] - \
                                           0.5 * temp_outcomes_df['half_win']

    # Concat all new columns at once (fixes PerformanceWarning)
    test_matches_df = pd.concat([test_matches_df, pd.DataFrame(new_cols, index=test_matches_df.index)], axis=1)


    print("Asian Handicap outcome probabilities calculated for various lines.")

    # --- Display a sample of the AH probabilities ---
    print("\n--- Sample of Test Matches with Asian Handicap Probabilities ---")
    # Select a few example AH line probability columns to display
    sample_ah_cols = [f'p_home_win_ah_{str(line).replace(".", "p")}' for line in [-0.5, 0, 0.5]]
    sample_ah_cols += [f'p_home_covers_ah_{str(line).replace(".", "p")}' for line in [-0.75, -0.25]]
    sample_ah_cols_to_display = ['home_name', 'away_name'] + [col for col in sample_ah_cols if col in test_matches_df.columns]

    if sample_ah_cols_to_display and len(sample_ah_cols_to_display) > 2:
        print(test_matches_df[sample_ah_cols_to_display].head())
    else:
        print("Sample AH probability columns not found or empty.")

print("\n--- End of Section 6.5 (NEW): Asian Handicap (AH) Probability Calculation ---")
# Next: Section 6.8 (Synthetic AH Odds if needed) OR
#       Section 7 (Backtesting, now adapted for AH bets)

"""Section 6.8: Synthetic AH Odds/Lines from Market 1X2 Odds"""

import pandas as pd
import numpy as np
from scipy.stats import poisson
from scipy.optimize import minimize

print("\n--- Section 6.8 (Revised): Synthetic AH Odds/Lines from Market 1X2 Odds ---")

# We assume 'test_matches_df' is available from Section 6.5 and contains
# 'odds_ft_1', 'odds_ft_x', 'odds_ft_2'

if 'odds_ft_1' not in test_matches_df.columns:
    print("Error: 'odds_ft_1' (and other 1X2 odds) not found in test_matches_df.")
    # exit()
else:
    print(f"Generating synthetic AH lines and odds from 1X2 market odds for {len(test_matches_df)} test matches.")

    MAX_GOALS_FOR_1X2_PROBS = 7 # Max goals for summing Poisson probabilities for 1X2

    def calculate_1x2_from_lambdas(lambda_h, lambda_a, max_goals=MAX_GOALS_FOR_1X2_PROBS):
        """Calculates P(H), P(D), P(A) from independent Poisson lambdas."""
        if pd.isna(lambda_h) or pd.isna(lambda_a) or lambda_h <= 0 or lambda_a <= 0:
            return np.nan, np.nan, np.nan

        pH_win, pDraw, pA_win = 0.0, 0.0, 0.0
        for hg in range(max_goals + 1):
            for ag in range(max_goals + 1):
                prob_score = poisson.pmf(hg, lambda_h) * poisson.pmf(ag, lambda_a)
                if hg > ag:
                    pH_win += prob_score
                elif hg == ag:
                    pDraw += prob_score
                else:
                    pA_win += prob_score

        total_prob = pH_win + pDraw + pA_win
        if total_prob > 0:
            return pH_win / total_prob, pDraw / total_prob, pA_win / total_prob
        else:
            return 1/3, 1/3, 1/3 # Fallback for tiny lambdas

    def objective_market_lambdas(lambdas, p_h_market, p_d_market, p_a_market):
        """Objective function to find lambdas that match market 1X2 probabilities."""
        lambda_h, lambda_a = lambdas
        # Penalize invalid lambdas heavily
        if lambda_h <= 1e-4 or lambda_a <= 1e-4:
            return 1000.0

        p_h_model, p_d_model, p_a_model = calculate_1x2_from_lambdas(lambda_h, lambda_a)

        if pd.isna(p_h_model): # If calculation failed
            return 1000.0

        # Sum of squared errors
        error = (p_h_model - p_h_market)**2 + \
                (p_d_model - p_d_market)**2 + \
                (p_a_model - p_a_market)**2
        return error

    market_implied_lambda_h_list = []
    market_implied_lambda_a_list = []

    print("Optimizing market-implied lambdas for each match (can take time)...")
    for index, row in test_matches_df.iterrows():
        odds_h = pd.to_numeric(row['odds_ft_1'], errors='coerce')
        odds_d = pd.to_numeric(row['odds_ft_x'], errors='coerce')
        odds_a = pd.to_numeric(row['odds_ft_2'], errors='coerce')

        if pd.isna(odds_h) or pd.isna(odds_d) or pd.isna(odds_a) or \
           odds_h <= 0 or odds_d <= 0 or odds_a <= 0:
            market_implied_lambda_h_list.append(np.nan)
            market_implied_lambda_a_list.append(np.nan)
            continue

        prob_h_raw = 1 / odds_h
        prob_d_raw = 1 / odds_d
        prob_a_raw = 1 / odds_a
        sum_probs_raw = prob_h_raw + prob_d_raw + prob_a_raw

        if sum_probs_raw == 0: # Avoid division by zero
            market_implied_lambda_h_list.append(np.nan)
            market_implied_lambda_a_list.append(np.nan)
            continue

        p_h_market_norm = prob_h_raw / sum_probs_raw
        p_d_market_norm = prob_d_raw / sum_probs_raw
        p_a_market_norm = prob_a_raw / sum_probs_raw

        # Initial guesses for lambdas (can be simple, e.g., based on avg goals or derived from probs)
        # Rough initial guess: if a team has 50% win prob, maybe they score ~1.5-1.7 goals more than concede.
        # Let's use a simpler fixed initial guess for stability.
        initial_lambda_guess = [1.5, 1.2] # Home, Away

        # Bounds for lambdas (e.g., 0.01 to 7 goals)
        lambda_bounds = [(0.01, 7.0), (0.01, 7.0)]

        res = minimize(objective_market_lambdas, initial_lambda_guess,
                       args=(p_h_market_norm, p_d_market_norm, p_a_market_norm),
                       method='L-BFGS-B', # or 'SLSQP'
                       bounds=lambda_bounds,
                       options={'ftol': 1e-7, 'maxiter': 100})

        if res.success:
            market_implied_lambda_h_list.append(res.x[0])
            market_implied_lambda_a_list.append(res.x[1])
        else:
            # print(f"Warning: Lambda optimization failed for match index {index}. Using NaN.")
            market_implied_lambda_h_list.append(np.nan)
            market_implied_lambda_a_list.append(np.nan)

    # Collect market lambdas and derived columns in a dict to avoid fragmentation
    market_cols = {
        'market_lambda_h': market_implied_lambda_h_list,
        'market_lambda_a': market_implied_lambda_a_list
    }
    test_matches_df = pd.concat([test_matches_df, pd.DataFrame(market_cols, index=test_matches_df.index)], axis=1)
    print("Market-implied lambdas calculated.")

    # Calculate market-implied goal difference
    test_matches_df['market_pred_goal_diff'] = test_matches_df['market_lambda_h'] - test_matches_df['market_lambda_a']

    # Determine the synthetic main AH line for the home team (using the function from your previous 6.8)
    def get_closest_ah_line(predicted_goal_diff):
        if pd.isna(predicted_goal_diff): return np.nan
        if predicted_goal_diff > 1.875: return -2.0
        elif predicted_goal_diff > 1.625: return -1.75
        elif predicted_goal_diff > 1.375: return -1.5
        elif predicted_goal_diff > 1.125: return -1.25
        elif predicted_goal_diff > 0.875: return -1.0
        elif predicted_goal_diff > 0.625: return -0.75
        elif predicted_goal_diff > 0.375: return -0.5
        elif predicted_goal_diff > 0.125: return -0.25
        elif predicted_goal_diff > -0.125: return 0.0
        elif predicted_goal_diff > -0.375: return 0.25
        elif predicted_goal_diff > -0.625: return 0.5
        elif predicted_goal_diff > -0.875: return 0.75
        elif predicted_goal_diff > -1.125: return 1.0
        elif predicted_goal_diff > -1.375: return 1.25
        elif predicted_goal_diff > -1.625: return 1.5
        elif predicted_goal_diff > -1.875: return 1.75
        else: return 2.0

    test_matches_df['synth_ah_line_home_market_based'] = test_matches_df['market_pred_goal_diff'].apply(get_closest_ah_line)

    # Assign synthetic odds for this main AH line
    SYNTHETIC_AH_ODDS_HOME = 1.925
    SYNTHETIC_AH_ODDS_AWAY = 1.925

    # Collect odds columns to avoid more fragmentation
    odds_cols = {
        'synth_ah_odds_home_market_based': np.where(pd.notna(test_matches_df['synth_ah_line_home_market_based']),
                                                    SYNTHETIC_AH_ODDS_HOME, np.nan),
        'synth_ah_odds_away_market_based': np.where(pd.notna(test_matches_df['synth_ah_line_home_market_based']),
                                                    SYNTHETIC_AH_ODDS_AWAY, np.nan)
    }
    test_matches_df = pd.concat([test_matches_df, pd.DataFrame(odds_cols, index=test_matches_df.index)], axis=1)

    print("Synthetic Asian Handicap lines and odds (market-based) generated.")

    # --- Display a sample ---
    print("\n--- Sample of Test Matches with Market-Based Synthetic Asian Handicap Data ---")
    synth_ah_cols_to_show_market = [
        'home_name', 'away_name', 'odds_ft_1', 'odds_ft_x', 'odds_ft_2',
        'market_lambda_h', 'market_lambda_a', 'market_pred_goal_diff',
        'synth_ah_line_home_market_based', 'synth_ah_odds_home_market_based', 'synth_ah_odds_away_market_based'
    ]
    synth_ah_cols_to_show_market = [col for col in synth_ah_cols_to_show_market if col in test_matches_df.columns]

    if not test_matches_df.empty and synth_ah_cols_to_show_market:
        print(test_matches_df[synth_ah_cols_to_show_market].head())
    else:
        print("DataFrame 'test_matches_df' is empty or key columns for synthetic AH display are missing.")

print("\n--- End of Section 6.8 (Revised): Synthetic AH Odds/Lines from Market 1X2 Odds ---")
# Next: Section 7: Backtesting for Asian Handicaps, using these market-based synthetic lines/odds
#       and the AH probabilities from Section 6.5 (which were derived from our model's scoreline matrices)
"""Section 7: Betting Strategy and Backtesting for Asian Handicaps"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

print("\n--- Section 7: Betting Strategy and Backtesting for Asian Handicaps ---")

# test_matches_df should be available from Section 6.8, containing:
# - Actual scores: 'homeGoalCount', 'awayGoalCount', 'actual_outcome'
# - Market-derived AH line: 'synth_ah_line_home_market_based'
# - Synthetic AH odds: 'synth_ah_odds_home_market_based', 'synth_ah_odds_away_market_based'
# - Model's detailed AH outcome probabilities (for various lines, from Section 6.5), e.g.,
#   'p_home_win_ah_0p0', 'p_home_hw_ah_0p0', 'p_home_push_ah_0p0',
#   'p_home_hl_ah_0p0', 'p_home_lose_ah_0p0', etc.

if 'synth_ah_line_home_market_based' not in test_matches_df.columns:
    print("Error: Essential synthetic AH line/odds columns not found in test_matches_df.")
    print("Please ensure Section 6.8 (Synthetic AH Odds/Lines) ran successfully.")
    # exit() # Or handle error
else:
    print(f"Starting Asian Handicap backtesting for {len(test_matches_df)} test matches.")

    # --- 1. Function to Calculate EV for a given AH Bet ---
    def calculate_ev_for_ah_bet(prob_win, prob_half_win, prob_push, prob_half_loss, prob_loss, odds):
        """Calculates EV for an Asian Handicap bet given outcome probabilities and odds."""
        if pd.isna(prob_win) or pd.isna(prob_half_win) or pd.isna(prob_push) or \
           pd.isna(prob_half_loss) or pd.isna(prob_loss) or pd.isna(odds) or odds <= 0:
            return np.nan

        # Profit for each outcome (assuming 1 unit stake)
        profit_win = odds - 1
        profit_half_win = (odds - 1) / 2
        profit_push = 0
        profit_half_loss = -0.5
        profit_loss = -1.0

        ev = (prob_win * profit_win) + \
             (prob_half_win * profit_half_win) + \
             (prob_push * profit_push) + \
             (prob_half_loss * profit_half_loss) + \
             (prob_loss * profit_loss)
        return ev

    # --- 2. Add EV Columns to test_matches_df for the synthetic main line ---
    print("\nCalculating EV for market-derived main AH lines...")

    ev_home_ah_list = []
    ev_away_ah_list = []

    for index, row in test_matches_df.iterrows():
        home_line = row['synth_ah_line_home_market_based']

        if pd.isna(home_line):
            ev_home_ah_list.append(np.nan)
            ev_away_ah_list.append(np.nan)
            continue

        line_str = str(home_line).replace(".", "p") # e.g., -0.5 -> -0p5; 0.0 -> 0p0

        # Probabilities for betting on Home + home_line
        p_hw = row.get(f'p_home_win_ah_{line_str}', np.nan)
        p_hhw = row.get(f'p_home_hw_ah_{line_str}', np.nan)
        p_hpush = row.get(f'p_home_push_ah_{line_str}', np.nan)
        p_hhl = row.get(f'p_home_hl_ah_{line_str}', np.nan)
        p_hl = row.get(f'p_home_lose_ah_{line_str}', np.nan)
        odds_h = row['synth_ah_odds_home_market_based']
        ev_h = calculate_ev_for_ah_bet(p_hw, p_hhw, p_hpush, p_hhl, p_hl, odds_h)
        ev_home_ah_list.append(ev_h)

        # Probabilities for betting on Away + (-home_line)
        # P(Away Win on AH -L_M) = P(Home Loss on AH L_M)
        # P(Away Half-Win on AH -L_M) = P(Home Half-Loss on AH L_M) etc.
        p_aw = p_hl # Home Loss for line L_M is Away Win for line -L_M
        p_ahw = p_hhl# Home Half-Loss for line L_M is Away Half-Win for line -L_M
        p_apush = p_hpush # Push is symmetric
        p_ahl = p_hhw # Home Half-Win for line L_M is Away Half-Loss for line -L_M
        p_al = p_hw  # Home Win for line L_M is Away Loss for line -L_M
        odds_a = row['synth_ah_odds_away_market_based']
        ev_a = calculate_ev_for_ah_bet(p_aw, p_ahw, p_apush, p_ahl, p_al, odds_a)
        ev_away_ah_list.append(ev_a)

    test_matches_df['ev_synth_home_ah'] = ev_home_ah_list
    test_matches_df['ev_synth_away_ah'] = ev_away_ah_list
    print("EV calculations for synthetic main AH lines complete.")


    # --- 3. Define AH Betting Strategy Function ---
    def get_ah_bet_decision_main_line(row, ev_threshold=0.05):
        """
        Determines AH bet based on EV for the synthetically determined main line.
        Returns: ('bet_type', line_for_home, odds)
        'bet_type' can be 'bet_home_main_ah', 'bet_away_main_ah', 'no_bet'.
        'line_for_home' is the handicap applied to the home team.
        """
        ev_h = row['ev_synth_home_ah']
        ev_a = row['ev_synth_away_ah']
        home_line = row['synth_ah_line_home_market_based'] # Line for home team

        # Ensure data is valid for decision
        if pd.isna(ev_h) and pd.isna(ev_a) or pd.isna(home_line):
            return 'no_bet', np.nan, np.nan

        bet_home = False
        bet_away = False

        if pd.notna(ev_h) and ev_h > ev_threshold:
            bet_home = True
        if pd.notna(ev_a) and ev_a > ev_threshold:
            bet_away = True

        if bet_home and bet_away:
            if ev_h > ev_a: # Prioritize higher EV
                return 'bet_home_main_ah', home_line, row['synth_ah_odds_home_market_based']
            else:
                return 'bet_away_main_ah', -home_line, row['synth_ah_odds_away_market_based'] # Bet on away with opposite line
        elif bet_home:
            return 'bet_home_main_ah', home_line, row['synth_ah_odds_home_market_based']
        elif bet_away:
            return 'bet_away_main_ah', -home_line, row['synth_ah_odds_away_market_based']
        else:
            return 'no_bet', np.nan, np.nan

    # --- 4. Function to Resolve AH Bet Outcome and Calculate Profit ---
    def resolve_ah_bet_profit(home_goals, away_goals, line_betted_on_team, side_betted, odds, stake=1.0):
        """
        Resolves an AH bet and calculates profit.
        line_betted_on_team: The handicap line OF THE TEAM YOU BET ON (e.g., -0.75 if you bet Home -0.75).
        side_betted: 'home' or 'away'.
        """
        if pd.isna(home_goals) or pd.isna(away_goals) or pd.isna(line_betted_on_team) or pd.isna(odds):
            return 0.0 # No bet or invalid data

        margin = home_goals - away_goals # Home margin

        if side_betted == 'home':
            effective_score_for_bet = margin + line_betted_on_team # e.g., margin -0.75 if line was -0.75
        elif side_betted == 'away':
            effective_score_for_bet = (-margin) + line_betted_on_team # e.g., (-margin) +0.75 if line was +0.75
        else:
            return 0.0

        # Determine profit
        if effective_score_for_bet > 0.25: # Win
            return (odds * stake) - stake
        elif effective_score_for_bet == 0.25: # Half Win
            return ((odds * stake) - stake) / 2
        elif effective_score_for_bet == 0: # Push
            return 0.0
        elif effective_score_for_bet == -0.25: # Half Loss
            return -stake / 2
        else: # Loss (effective_score_for_bet < -0.25)
            return -stake

    # --- 5. Simulate Betting and Calculate Returns ---
    def simulate_ah_betting(df, ev_threshold=0.05, stake_per_bet=1.0):
        df_copy = df.copy()

        decisions = df_copy.apply(lambda row: get_ah_bet_decision_main_line(row, ev_threshold), axis=1)
        df_copy['bet_type_ah'] = [d[0] for d in decisions]
        df_copy['line_betted_on'] = [d[1] for d in decisions] # This is the line for the team betted ON
        df_copy['odds_betted_on'] = [d[2] for d in decisions]

        df_copy['profit_loss_ah'] = 0.0
        for index, row in df_copy.iterrows():
            if row['bet_type_ah'] == 'no_bet':
                continue

            side = 'home' if row['bet_type_ah'] == 'bet_home_main_ah' else 'away'
            # The line_betted_on is already correct for the team we bet on.
            # e.g., if home_line was -0.75 and we bet away, line_betted_on is +0.75
            df_copy.loc[index, 'profit_loss_ah'] = resolve_ah_bet_profit(
                row['homeGoalCount'], row['awayGoalCount'],
                row['line_betted_on'],
                side,
                row['odds_betted_on'],
                stake_per_bet
            )
        return df_copy

    # --- 6. Backtest with a default threshold and analyze results ---
    print("\nRunning initial AH backtest...")
    EV_THRESHOLD_DEFAULT_AH = 0.05
    STAKE_AH = 1.0

    backtest_results_ah_df = simulate_ah_betting(test_matches_df, EV_THRESHOLD_DEFAULT_AH, STAKE_AH)
    bets_placed_ah_df = backtest_results_ah_df[backtest_results_ah_df['bet_type_ah'] != 'no_bet'].copy() # Use .copy()

    if not bets_placed_ah_df.empty:
        num_bets_ah = len(bets_placed_ah_df)
        total_profit_loss_ah = bets_placed_ah_df['profit_loss_ah'].sum()
        total_wagered_ah = num_bets_ah * STAKE_AH
        roi_ah = (total_profit_loss_ah / total_wagered_ah) * 100 if total_wagered_ah > 0 else 0

        # Win rate here means bets that resulted in positive profit
        positive_profit_bets = (bets_placed_ah_df['profit_loss_ah'] > 0).sum()
        non_losing_bets = (bets_placed_ah_df['profit_loss_ah'] >= 0).sum() # Includes pushes, half-wins
        win_rate_positive_profit = positive_profit_bets / num_bets_ah * 100 if num_bets_ah > 0 else 0

        print(f"\n--- AH Backtest Results (EV Threshold = {EV_THRESHOLD_DEFAULT_AH:.2f}, Stake = {STAKE_AH}) ---")
        print(f"Total Matches in Test Set: {len(test_matches_df)}")
        print(f"Number of AH Bets Placed: {num_bets_ah}")
        print(f"Total Wagered (on resolved bets): {total_wagered_ah:.2f}")
        print(f"Total Profit/Loss: {total_profit_loss_ah:.2f} units")
        print(f"Return on Investment (ROI): {roi_ah:.2f}%")
        print(f"Win Rate (bets with positive profit): {win_rate_positive_profit:.2f}%")
        print(f"Non-Losing Bet Rate (pushes or better): {non_losing_bets / num_bets_ah * 100 if num_bets_ah > 0 else 0:.2f}%")

        bets_placed_ah_df.loc[:, 'cumulative_profit_ah'] = bets_placed_ah_df['profit_loss_ah'].cumsum()
        plt.figure(figsize=(12, 6))
        bets_placed_ah_df['cumulative_profit_ah'].plot(kind='line')
        plt.title(f'AH Cumulative Profit Over Time (EV Threshold = {EV_THRESHOLD_DEFAULT_AH:.2f})')
        plt.xlabel('Bet Number (Chronological in Test Set)')
        plt.ylabel('Cumulative Profit (units)')
        plt.grid(True)
        plt.show()
    else:
        print(f"No AH bets were placed with EV Threshold = {EV_THRESHOLD_DEFAULT_AH:.2f}.")

    # --- 7. Optimize EV Threshold for AH Betting ---
    print("\nOptimizing EV Threshold for AH Betting...")
    ev_thresholds_to_test_ah = np.arange(0.0, 0.51, 0.01)
    results_by_threshold_ah = []

    for th in ev_thresholds_to_test_ah:
        sim_df_ah = simulate_ah_betting(test_matches_df, th, STAKE_AH)
        bets_df_ah = sim_df_ah[sim_df_ah['bet_type_ah'] != 'no_bet']
        if not bets_df_ah.empty:
            n_bets = len(bets_df_ah)
            p_l = bets_df_ah['profit_loss_ah'].sum()
            wagered = n_bets * STAKE_AH
            current_roi = (p_l / wagered) * 100 if wagered > 0 else 0
            results_by_threshold_ah.append({'threshold': th, 'num_bets': n_bets, 'profit_loss': p_l, 'roi': current_roi})
        else:
            results_by_threshold_ah.append({'threshold': th, 'num_bets': 0, 'profit_loss': 0, 'roi': 0})

    threshold_df_ah = pd.DataFrame(results_by_threshold_ah)

    if not threshold_df_ah.empty and threshold_df_ah['num_bets'].sum() > 0 :
        best_roi_row_ah = threshold_df_ah.loc[threshold_df_ah['roi'].idxmax()]
        print("\n--- AH EV Threshold Optimization Results ---")
        print(f"Best ROI for AH: {best_roi_row_ah['roi']:.2f}% at EV Threshold = {best_roi_row_ah['threshold']:.2f}")
        print(f"  Number of Bets: {best_roi_row_ah['num_bets']}")
        print(f"  Profit/Loss: {best_roi_row_ah['profit_loss']:.2f} units")

        fig, ax1 = plt.subplots(figsize=(12, 6))
        ax1.plot(threshold_df_ah['threshold'], threshold_df_ah['roi'], marker='o', linestyle='-', color='tab:blue', label='ROI (%)')
        ax1.set_xlabel('EV Threshold')
        ax1.set_ylabel('Return on Investment (ROI %)', color='tab:blue')
        ax1.tick_params(axis='y', labelcolor='tab:blue')
        ax1.grid(True, axis='x')
        plt.axvline(best_roi_row_ah['threshold'], color='r', linestyle='--', label=f"Best Threshold for ROI ({best_roi_row_ah['threshold']:.2f})")

        ax2 = ax1.twinx()
        ax2.plot(threshold_df_ah['threshold'], threshold_df_ah['num_bets'], marker='x', linestyle=':', color='tab:green', label='Number of Bets')
        ax2.set_ylabel('Number of Bets', color='tab:green')
        ax2.tick_params(axis='y', labelcolor='tab:green')

        fig.tight_layout()
        plt.title('AH ROI & Number of Bets vs. EV Threshold')
        # Combine legends
        lines, labels = ax1.get_legend_handles_labels()
        lines2, labels2 = ax2.get_legend_handles_labels()
        ax2.legend(lines + lines2, labels + labels2, loc='best')
        plt.show()
    else:
        print("No results from AH threshold optimization (likely no bets placed at any threshold).")

print("\n--- End of Section 7: Betting Strategy and Backtesting for Asian Handicaps ---")

"""Section 7.1: Granular Backtesting Analysis for Asian Handicaps

> Add blockquote


"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt # In case you want to plot specific segments later
import seaborn as sns # For aesthetics if plotting

print("\n--- Section 7.1 (Extended): Granular Backtesting Analysis (Combined Segments) ---")

# We assume 'bets_placed_ah_df' is available from the initial run of Section 7
# and contains 'league_tier', 'competition_type', 'line_betted_on', 'profit_loss_ah'.

if 'bets_placed_ah_df' not in locals() or bets_placed_ah_df.empty:
    print("Error: 'bets_placed_ah_df' is not defined or empty. Please run Section 7 (initial backtest) first.")
    # exit()
elif not all(col in bets_placed_ah_df.columns for col in ['league_tier', 'competition_type', 'line_betted_on', 'profit_loss_ah']):
    print("Error: 'bets_placed_ah_df' is missing one or more required columns for granular analysis.")
    # exit()
else:
    print(f"Further analyzing {len(bets_placed_ah_df)} placed AH bets with combined segments...")
    STAKE_AH = 1.0 # Assuming a constant stake used in Section 7

    def calculate_segment_kpis(df_segment, segment_col_name="Segment"): # Keep include_groups=False if using older pandas
        if df_segment.empty:
            return pd.Series({
                'Num Bets': 0, 'Total P/L': 0, 'Total Wagered': 0,
                'ROI (%)': 0, 'Win Rate (+P/L %)': 0, 'Non-Losing Rate (%)': 0
            })
        num_bets = len(df_segment)
        total_profit_loss = df_segment['profit_loss_ah'].sum()
        total_wagered = num_bets * STAKE_AH
        roi = (total_profit_loss / total_wagered) * 100 if total_wagered > 0 else 0
        positive_profit_bets = (df_segment['profit_loss_ah'] > 0).sum()
        win_rate_positive_profit = positive_profit_bets / num_bets * 100 if num_bets > 0 else 0
        non_losing_bets = (df_segment['profit_loss_ah'] >= 0).sum()
        non_losing_rate = non_losing_bets / num_bets * 100 if num_bets > 0 else 0
        return pd.Series({
            'Num Bets': num_bets, 'Total P/L': round(total_profit_loss, 2),
            'Total Wagered': round(total_wagered, 2), 'ROI (%)': round(roi, 2),
            'Win Rate (+P/L %)': round(win_rate_positive_profit, 2),
            'Non-Losing Rate (%)': round(non_losing_rate, 2)
        })

    # --- Previous Analyses (re-run for context if needed, or assume done) ---
    # print("\n--- Analysis by League Tier (Recap) ---")
    # tier_analysis = bets_placed_ah_df.groupby('league_tier', observed=False).apply(calculate_segment_kpis, include_groups=False).sort_values(by='ROI (%)', ascending=False)
    # print(tier_analysis)

    # print("\n--- Analysis by Competition Type (Recap) ---")
    # type_analysis = bets_placed_ah_df.groupby('competition_type', observed=False).apply(calculate_segment_kpis, include_groups=False).sort_values(by='ROI (%)', ascending=False)
    # print(type_analysis)

    # print("\n--- Analysis by Asian Handicap Line Bet On (Recap) ---")
    # line_analysis = bets_placed_ah_df.groupby('line_betted_on').apply(calculate_segment_kpis, include_groups=False).sort_values(by='ROI (%)', ascending=False)
    # print(line_analysis.head(10)) # Display top 10 by ROI


    # --- Combined Segment Analysis ---

    # 1. Performance of each AH Line BY League Tier
    print("\n\n--- Combined Analysis: AH Line Performance by League Tier ---")
    if 'league_tier' in bets_placed_ah_df.columns and 'line_betted_on' in bets_placed_ah_df.columns:
        line_by_tier_analysis = bets_placed_ah_df.groupby(['league_tier', 'line_betted_on'], observed=False).apply(
            calculate_segment_kpis, include_groups=False
        )
        # Sort for better readability, e.g., by tier then by ROI or line
        line_by_tier_analysis = line_by_tier_analysis.sort_index(level=0).sort_values(by=['league_tier', 'ROI (%)'], ascending=[True, False])

        # To make it more readable, unstack or print per tier
        for tier, group_df in line_by_tier_analysis.groupby(level=0):
            print(f"\nLeague Tier: {tier}")
            # Filter out segments with very few bets for cleaner output if desired
            # print(group_df.droplevel(0)[group_df.droplevel(0)['Num Bets'] >= 5]) # Example: show if >= 5 bets
            print(group_df.droplevel(0))
    else:
        print("Warning: 'league_tier' or 'line_betted_on' column missing for combined analysis.")

    # 2. Performance of each AH Line BY Competition Type
    print("\n\n--- Combined Analysis: AH Line Performance by Competition Type ---")
    if 'competition_type' in bets_placed_ah_df.columns and 'line_betted_on' in bets_placed_ah_df.columns:
        line_by_comp_type_analysis = bets_placed_ah_df.groupby(['competition_type', 'line_betted_on'], observed=False).apply(
            calculate_segment_kpis, include_groups=False
        )
        line_by_comp_type_analysis = line_by_comp_type_analysis.sort_index(level=0).sort_values(by=['competition_type', 'ROI (%)'], ascending=[True, False])

        for comp_type, group_df in line_by_comp_type_analysis.groupby(level=0):
            print(f"\nCompetition Type: {comp_type}")
            # print(group_df.droplevel(0)[group_df.droplevel(0)['Num Bets'] >= 5])
            print(group_df.droplevel(0))
    else:
        print("Warning: 'competition_type' or 'line_betted_on' column missing for combined analysis.")

    # 3. (Optional) Performance by League Tier AND Competition Type
    print("\n\n--- Combined Analysis: League Tier by Competition Type ---")
    if 'league_tier' in bets_placed_ah_df.columns and 'competition_type' in bets_placed_ah_df.columns:
        tier_by_comp_type_analysis = bets_placed_ah_df.groupby(['league_tier', 'competition_type'], observed=False).apply(
            calculate_segment_kpis, include_groups=False
        )
        print(tier_by_comp_type_analysis.sort_values(by='ROI (%)', ascending=False))
    else:
        print("Warning: 'league_tier' or 'competition_type' column missing for combined analysis.")


print("\n--- End of Section 7.1 (Extended): Granular Backtesting Analysis ---")

"""Section 7.1.1: Visualizing Granular Performance."""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

print("\n--- Section 7.1.1 (NEW): Visualizing Granular Performance ---")

# We assume the analysis DataFrames from Section 7.1 are available:
# - line_by_tier_analysis
# - line_by_comp_type_analysis
# - bets_placed_ah_df (for generating aggregated segments)

# Set plot style for better aesthetics
sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (14, 8) # Set default figure size

if 'line_by_tier_analysis' not in locals() or 'line_by_comp_type_analysis' not in locals():
    print("Error: Analysis DataFrames from Section 7.1 not found. Please run Section 7.1 first.")
else:
    # --- Visualization 1: Grouped Bar Chart - ROI by Line, Grouped by League Tier ---
    print("\n--- Plot 1: ROI by Asian Handicap Line, Grouped by League Tier ---")

    # Prepare data for plotting by resetting the index
    plot_data_tier = line_by_tier_analysis.reset_index()

    # Filter for segments with a reasonable number of bets for a cleaner plot
    MIN_BETS_FOR_VISUAL = 15
    plot_data_tier_filtered = plot_data_tier[plot_data_tier['Num Bets'] >= MIN_BETS_FOR_VISUAL]

    plt.figure() # Create a new figure
    ax = sns.barplot(
        data=plot_data_tier_filtered,
        x='line_betted_on',
        y='ROI (%)',
        hue='league_tier',
        palette='viridis' # Use a distinct color palette
    )
    ax.axhline(0, color='black', linewidth=0.8, linestyle='--') # Add a zero line
    plt.title('ROI (%) by AH Line and League Tier (Min. 15 Bets per Segment)', fontsize=16)
    plt.xlabel('Asian Handicap Line Bet On', fontsize=12)
    plt.ylabel('Return on Investment (ROI %)', fontsize=12)
    plt.legend(title='League Tier')
    plt.show()

    # --- Visualization 2: ROI Heatmap - League Tier vs. AH Line ---
    print("\n--- Plot 2: Heatmap of ROI (%) - League Tier vs. Asian Handicap Line ---")

    try:
        # Pivot the data to create a matrix: Tiers on Y-axis, Lines on X-axis, ROI as values
        heatmap_data_roi = line_by_tier_analysis['ROI (%)'].unstack(level='line_betted_on')
        # Also create a matrix for annotations (Number of Bets)
        heatmap_data_bets = line_by_tier_analysis['Num Bets'].unstack(level='line_betted_on').fillna(0).astype(int)

        plt.figure()
        sns.heatmap(
            heatmap_data_roi,
            annot=heatmap_data_bets, # Annotate with the number of bets
            fmt='d', # Format annotations as integers
            cmap='coolwarm', # Use a diverging colormap (blue=cold/bad, red=hot/good)
            linewidths=.5,
            center=0 # Center the colormap on zero ROI
        )
        plt.title('ROI (%) Heatmap by League Tier and AH Line (Number of Bets shown in cells)', fontsize=16)
        plt.xlabel('Asian Handicap Line Bet On', fontsize=12)
        plt.ylabel('League Tier', fontsize=12)
        plt.show()
    except Exception as e:
        print(f"Could not generate heatmap, likely due to data structure issues: {e}")


    # --- Visualization 3: Aggregated Strategic Segment Analysis ---
    print("\n--- Plot 3: ROI by Aggregated Strategic Segments ---")

    if 'bets_placed_ah_df' in locals() and not bets_placed_ah_df.empty:
        # Create higher-level categories based on the line
        def get_bet_position(line):
            if pd.isna(line): return 'Unknown'
            if line < 0: return 'Favorite (Betting on "-")'
            if line > 0: return 'Underdog (Betting on "+")'
            return 'Pick-em (AH 0)'

        def get_line_magnitude(line):
            if pd.isna(line): return 'Unknown'
            abs_line = abs(line)
            if abs_line < 1.0: return 'Small Line (< 1.0)'
            if abs_line >= 1.0: return 'Large Line (>= 1.0)'
            return 'Other'

        # Create a copy for this analysis to avoid modifying the original
        strategic_df = bets_placed_ah_df.copy()
        strategic_df['position'] = strategic_df['line_betted_on'].apply(get_bet_position)
        strategic_df['line_magnitude'] = strategic_df['line_betted_on'].apply(get_line_magnitude)

        # Group by League Tier and our new strategic categories
        strategic_analysis = strategic_df.groupby(
            ['league_tier', 'position', 'line_magnitude'], observed=False
        ).apply(calculate_segment_kpis, include_groups=False)

        print("\n--- Performance by Aggregated Strategic Segments ---")
        print(strategic_analysis.sort_values(by='ROI (%)', ascending=False))

        # Visualize this aggregated data
        strategic_plot_data = strategic_analysis.reset_index()
        strategic_plot_data_filtered = strategic_plot_data[strategic_plot_data['Num Bets'] >= MIN_BETS_FOR_VISUAL]

        plt.figure(figsize=(16, 10))
        sns.catplot(
            data=strategic_plot_data_filtered,
            x='ROI (%)',
            y='position',
            hue='line_magnitude',
            col='league_tier', # Create separate columns for each tier
            kind='bar',
            orient='h',
            palette='Set2'
        )
        plt.suptitle('ROI (%) by Aggregated Strategy (Position & Line Size) across League Tiers', y=1.03, fontsize=16)
        plt.show()
    else:
        print("Warning: 'bets_placed_ah_df' not available for strategic segment analysis.")

print("\n--- End of Section 7.1.1: Visualizing Granular Performance ---")

"""Section 7.2 (NEW): Automated Policy Generation & Refined AH Backtest"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

print("\n--- Section 7.2 (NEW): Automated Policy Generation & Refined AH Backtest ---")

# Ensure necessary DataFrames are available from previous sections
if 'test_matches_df' not in locals() or test_matches_df.empty:
    print("Error: 'test_matches_df' from Section 6.8 is not defined or empty.")
    # exit()
elif 'line_by_tier_analysis' not in locals() or \
     'line_by_comp_type_analysis' not in locals() or \
     'tier_by_comp_type_analysis' not in locals(): # Add this one too
    print("Error: Granular analysis DataFrames from Section 7.1 (e.g., 'line_by_tier_analysis') are not available.")
    print("Please run Section 7.1 (Extended Granular Analysis) first.")
    # exit()
elif not all(col in test_matches_df.columns for col in ['ev_synth_home_ah', 'ev_synth_away_ah',
                                                        'league_tier', 'competition_type',
                                                        'synth_ah_line_home_market_based',
                                                        'synth_ah_odds_home_market_based',
                                                        'synth_ah_odds_away_market_based',
                                                        'homeGoalCount', 'awayGoalCount']):
    print("Error: 'test_matches_df' is missing one or more required columns for refined backtesting.")
    # exit()
else:
    STAKE_AH = 1.0
    print(f"Starting refined AH backtest for {len(test_matches_df)} matches.")

    # --- 1. Define Meta-Rules for Automated Policy Generation ---
    print("\nDefining meta-rules for automated policy generation...")
    META_RULES = {
        'MIN_BETS_FOR_RELIABLE_RULE': 20,  # Min bets in a segment from 7.1 to create a specific rule
        'ROI_THRESHOLD_VERY_GOOD': 15.0,   # ROI (%) to qualify for a lower EV threshold
        'ROI_THRESHOLD_ACCEPTABLE': 5.0, # ROI (%) to qualify for a moderate EV threshold
        'ROI_THRESHOLD_POOR': 2.0,       # ROI (%) below which we might avoid or use high EV

        'EV_FOR_VERY_GOOD_ROI': 0.05,    # Lower EV for very good segments
        'EV_FOR_ACCEPTABLE_ROI': 0.10,   # Moderate EV for acceptable segments
        'EV_FOR_MODERATE_ROI': 0.15,     # For segments with just okay ROI or few bets
        'DEFAULT_EV_THRESHOLD': 0.20,      # General fallback if no specific rule applies
        'ACTION_FOR_POOR_ROI': {'allow_bet': False, 'min_ev': 0.50} # Effectively 'no_bet'
    }

    # --- 2. Function to Generate Betting Policy Programmatically ---
    def generate_automated_betting_policy(
        line_by_tier_df,
        line_by_comp_type_df,
        tier_by_comp_type_df, # Added this
        meta_rules
    ):
        policy = {'default': {'min_ev': meta_rules['DEFAULT_EV_THRESHOLD'], 'allow_bet': True}}

        # Process rules from AH Line Performance by League Tier
        if line_by_tier_df is not None:
            for (tier, line), data_row in line_by_tier_df.iterrows():
                key = (tier, None, line) # Rule for (tier, any_comp_type, line)
                if data_row['Num Bets'] >= meta_rules['MIN_BETS_FOR_RELIABLE_RULE']:
                    if data_row['ROI (%)'] >= meta_rules['ROI_THRESHOLD_VERY_GOOD']:
                        policy[key] = {'min_ev': meta_rules['EV_FOR_VERY_GOOD_ROI'], 'allow_bet': True}
                    elif data_row['ROI (%)'] >= meta_rules['ROI_THRESHOLD_ACCEPTABLE']:
                        policy[key] = {'min_ev': meta_rules['EV_FOR_ACCEPTABLE_ROI'], 'allow_bet': True}
                    elif data_row['ROI (%)'] < meta_rules['ROI_THRESHOLD_POOR']:
                        policy[key] = meta_rules['ACTION_FOR_POOR_ROI'].copy()
                    else: # Moderate ROI
                        policy[key] = {'min_ev': meta_rules['EV_FOR_MODERATE_ROI'], 'allow_bet': True}

        # Process rules from AH Line Performance by Competition Type
        if line_by_comp_type_df is not None:
            for (comp_type, line), data_row in line_by_comp_type_df.iterrows():
                key = (None, comp_type, line) # Rule for (any_tier, comp_type, line)
                # Only add/override if this segment also has enough bets
                if data_row['Num Bets'] >= meta_rules['MIN_BETS_FOR_RELIABLE_RULE']:
                    new_rule = {}
                    if data_row['ROI (%)'] >= meta_rules['ROI_THRESHOLD_VERY_GOOD']:
                        new_rule = {'min_ev': meta_rules['EV_FOR_VERY_GOOD_ROI'], 'allow_bet': True}
                    elif data_row['ROI (%)'] >= meta_rules['ROI_THRESHOLD_ACCEPTABLE']:
                        new_rule = {'min_ev': meta_rules['EV_FOR_ACCEPTABLE_ROI'], 'allow_bet': True}
                    elif data_row['ROI (%)'] < meta_rules['ROI_THRESHOLD_POOR']:
                        new_rule = meta_rules['ACTION_FOR_POOR_ROI'].copy()
                    else:
                        new_rule = {'min_ev': meta_rules['EV_FOR_MODERATE_ROI'], 'allow_bet': True}

                    # If a rule for this (None, comp_type, line) doesn't exist, or if new rule is stricter, apply it
                    if key not in policy or (new_rule.get('allow_bet', True) == False and policy[key].get('allow_bet',True) == True) or \
                       (new_rule.get('min_ev',0) > policy[key].get('min_ev',meta_rules['DEFAULT_EV_THRESHOLD'])):
                        policy[key] = new_rule

        # Process rules from League Tier by Competition Type
        if tier_by_comp_type_df is not None:
            for (tier, comp_type), data_row in tier_by_comp_type_df.iterrows():
                key = (tier, comp_type, None) # Rule for (tier, comp_type, any_line)
                if data_row['Num Bets'] >= meta_rules['MIN_BETS_FOR_RELIABLE_RULE']:
                    new_rule = {}
                    if data_row['ROI (%)'] >= meta_rules['ROI_THRESHOLD_VERY_GOOD']:
                        new_rule = {'min_ev': meta_rules['EV_FOR_VERY_GOOD_ROI'], 'allow_bet': True}
                    elif data_row['ROI (%)'] >= meta_rules['ROI_THRESHOLD_ACCEPTABLE']:
                        new_rule = {'min_ev': meta_rules['EV_FOR_ACCEPTABLE_ROI'], 'allow_bet': True}
                    elif data_row['ROI (%)'] < meta_rules['ROI_THRESHOLD_POOR']:
                        new_rule = meta_rules['ACTION_FOR_POOR_ROI'].copy()
                    else:
                        new_rule = {'min_ev': meta_rules['EV_FOR_MODERATE_ROI'], 'allow_bet': True}
                    policy[key] = new_rule # More general rules can be overridden by more specific ones later in lookup

        return policy

    AUTOMATED_BETTING_POLICY = generate_automated_betting_policy(
        line_by_tier_analysis,
        line_by_comp_type_analysis,
        tier_by_comp_type_analysis, # Pass the third analysis DataFrame
        META_RULES
    )
    print("\nAutomated Betting Policy Generated.")
    # For brevity, not printing the whole policy. You can inspect it if needed.
    # print("Sample Policy Rules:", {k: v for i, (k, v) in enumerate(AUTOMATED_BETTING_POLICY.items()) if i % (len(AUTOMATED_BETTING_POLICY)//10 +1) == 0})


    # --- 3. Refined AH Bet Decision Function (uses the generated policy) ---
    def get_refined_ah_bet_decision(row, policy):
        current_tier = row['league_tier']
        current_comp_type = row['competition_type']
        home_line_market = row['synth_ah_line_home_market_based'] # This is the line for Home team

        ev_h = row['ev_synth_home_ah'] # EV for betting Home at home_line_market
        ev_a = row['ev_synth_away_ah'] # EV for betting Away at -home_line_market

        if pd.isna(home_line_market) or (pd.isna(ev_h) and pd.isna(ev_a)):
            return 'no_bet', np.nan, np.nan, np.nan

        potential_bets = []
        if pd.notna(ev_h):
            potential_bets.append({'side': 'home', 'ev': ev_h,
                                   'line': home_line_market,
                                   'odds': row['synth_ah_odds_home_market_based']})
        if pd.notna(ev_a):
            potential_bets.append({'side': 'away', 'ev': ev_a,
                                   'line': -home_line_market, # Line for away team
                                   'odds': row['synth_ah_odds_away_market_based']})

        if not potential_bets:
            return 'no_bet', np.nan, np.nan, np.nan

        # Filter by policy and then choose highest EV among allowed bets
        allowed_value_bets = []
        for bet_option in potential_bets:
            line_for_policy_lookup = bet_option['line'] # This is the line OF THE TEAM BEING BET ON

            # Rule lookup with precedence
            rule = None
            policy_keys = [
                (current_tier, current_comp_type, line_for_policy_lookup),
                (current_tier, None, line_for_policy_lookup),
                (None, current_comp_type, line_for_policy_lookup),
                (current_tier, current_comp_type, None),
                (current_tier, None, None),
                (None, current_comp_type, None),
                (None, None, line_for_policy_lookup),
                'default'
            ]
            for key in policy_keys:
                if key in policy:
                    rule = policy[key]
                    break
            if rule is None:
                rule = {}  # Default empty

            min_ev_for_segment = rule['min_ev']
            allow_bet_for_segment = rule.get('allow_bet', True)

            if allow_bet_for_segment and bet_option['ev'] > min_ev_for_segment:
                allowed_value_bets.append(bet_option)

        if not allowed_value_bets:
            return 'no_bet', np.nan, np.nan, np.nan

        # Choose the bet with the highest EV from the allowed value bets
        best_bet = max(allowed_value_bets, key=lambda x: x['ev'])

        bet_type_str = f"bet_{best_bet['side']}_refined_ah"
        return bet_type_str, best_bet['line'], best_bet['odds'], best_bet['ev']

    # --- 4. Simulate Betting with AUTOMATED Refined Strategy ---
    # (resolve_ah_bet_profit function is the same)
    def resolve_ah_bet_profit(home_goals, away_goals, line_betted_on_team, side_betted, odds, stake=1.0):
        if pd.isna(home_goals) or pd.isna(away_goals) or pd.isna(line_betted_on_team) or pd.isna(odds) or odds <=0: return 0.0
        margin = home_goals - away_goals
        if side_betted == 'home': effective_score_for_bet = margin + line_betted_on_team
        elif side_betted == 'away': effective_score_for_bet = (-margin) + line_betted_on_team
        else: return 0.0
        if effective_score_for_bet > 0.25: return (odds * stake) - stake
        elif effective_score_for_bet == 0.25: return ((odds * stake) - stake) / 2
        elif effective_score_for_bet == 0: return 0.0
        elif effective_score_for_bet == -0.25: return -stake / 2
        else: return -stake

    print("\nRunning REFINED AH backtest with AUTOMATED Segmented Policy...")
    # Use a fresh copy of test_matches_df for this simulation
    refined_backtest_df = test_matches_df.copy()

    refined_decisions = refined_backtest_df.apply(
        lambda row: get_refined_ah_bet_decision(row, AUTOMATED_BETTING_POLICY), axis=1
    )
    refined_backtest_df['bet_type_refined_ah'] = [d[0] for d in refined_decisions]
    refined_backtest_df['line_betted_on_refined'] = [d[1] for d in refined_decisions]
    refined_backtest_df['odds_betted_on_refined'] = [d[2] for d in refined_decisions]
    refined_backtest_df['ev_for_bet_refined'] = [d[3] for d in refined_decisions]

    # Kelly staking configuration
    KELLY_FRACTION = 0.20
    MAX_STAKE_PERCENT = 0.05
    INITIAL_BANKROLL = 100.0
    current_bankroll = INITIAL_BANKROLL

    refined_backtest_df['stake_ah'] = 0.0
    refined_backtest_df['profit_loss_refined_ah'] = 0.0

    for index, row in refined_backtest_df.iterrows():
        if row['bet_type_refined_ah'] == 'no_bet' or pd.isna(row['ev_for_bet_refined']) or pd.isna(row['odds_betted_on_refined']) or row['odds_betted_on_refined'] <= 1:
            continue
        ev = row['ev_for_bet_refined']
        stake_percent = max(0.0, min(ev * KELLY_FRACTION, MAX_STAKE_PERCENT))
        stake_amount = current_bankroll * stake_percent
        if stake_amount <= 0.01:
            continue
        refined_backtest_df.loc[index, 'stake_ah'] = stake_amount
        side = 'home' if row['bet_type_refined_ah'] == 'bet_home_refined_ah' else 'away'
        profit = resolve_ah_bet_profit(
            row['homeGoalCount'], row['awayGoalCount'],
            row['line_betted_on_refined'], side,
            row['odds_betted_on_refined'], stake_amount
        )
        refined_backtest_df.loc[index, 'profit_loss_refined_ah'] = profit
        current_bankroll += profit

    refined_bets_placed_df = refined_backtest_df[refined_backtest_df['stake_ah'] > 0].copy()
    if not refined_bets_placed_df.empty:
        num_bets_refined = len(refined_bets_placed_df)
        total_profit_loss_refined = refined_bets_placed_df['profit_loss_refined_ah'].sum()
        total_wagered_refined = refined_bets_placed_df['stake_ah'].sum()
        roi_refined = (total_profit_loss_refined / total_wagered_refined) * 100 if total_wagered_refined > 0 else 0
        positive_profit_bets_refined = (refined_bets_placed_df['profit_loss_refined_ah'] > 0).sum()
        win_rate_positive_profit_refined = positive_profit_bets_refined / num_bets_refined * 100 if num_bets_refined > 0 else 0
        non_losing_bets_refined = (refined_bets_placed_df['profit_loss_refined_ah'] >= 0).sum()
        non_losing_rate_refined = non_losing_bets_refined / num_bets_refined * 100 if num_bets_refined > 0 else 0

        print(f"\n--- AUTOMATED REFINED AH Backtest Results (Segmented Policy, Stake = {STAKE_AH}) ---")
        print(f"Number of AH Bets Placed: {num_bets_refined}")
        print(f"Total Wagered: {total_wagered_refined:.2f}")
        print(f"Total Profit/Loss: {total_profit_loss_refined:.2f} units")
        print(f"Return on Investment (ROI): {roi_refined:.2f}%")
        print(f"Win Rate (bets with positive profit): {win_rate_positive_profit_refined:.2f}%")
        print(f"Non-Losing Bet Rate: {non_losing_rate_refined:.2f}%")

        # Sort bets by datetime before plotting cumulative profit for chronological view
        # Assuming 'datetime_gmt8' exists in refined_bets_placed_df (merged from test_matches_df)
        if 'datetime_gmt8' in refined_bets_placed_df.columns:
            refined_bets_placed_df = refined_bets_placed_df.sort_values(by='datetime_gmt8')

        refined_bets_placed_df.loc[:, 'cumulative_profit_refined_ah'] = refined_bets_placed_df['profit_loss_refined_ah'].cumsum()
        plt.figure(figsize=(12, 6))
        refined_bets_placed_df['cumulative_profit_refined_ah'].plot(kind='line')
        plt.title(f'AUTOMATED REFINED AH Cumulative Profit (Segmented Policy)')
        plt.xlabel('Bet Number (Chronological in Test Set, if sorted)')
        plt.ylabel('Cumulative Profit (units)')
        plt.grid(True)
        plt.show()

        # Optional: write detailed bet records to Postgres if DATABASE_URL set
        import os
        db_url = os.environ.get('DATABASE_URL')
        if db_url:
            try:
                import psycopg2
                conn = psycopg2.connect(db_url)
                cur = conn.cursor()
                cur.execute("""
                CREATE TABLE IF NOT EXISTS bets(
                    bet_id bigserial PRIMARY KEY,
                    run_id text,
                    dt_gmt8 timestamptz,
                    league text,
                    home text,
                    away text,
                    tier int,
                    comp_type text,
                    side text,
                    line numeric,
                    odds numeric,
                    ev numeric,
                    stake numeric,
                    pl numeric,
                    cum_bankroll numeric,
                    status text DEFAULT 'open',
                    settled_at timestamptz,
                    fixture_id text,
                    home_score int,
                    away_score int,
                    line_betted_on_refined numeric,
                    bet_type_refined_ah text,
                    odds_betted_on_refined numeric
                );
                
                -- Add missing columns to existing tables (safe if columns already exist)
                ALTER TABLE bets ADD COLUMN IF NOT EXISTS status text DEFAULT 'open';
                ALTER TABLE bets ADD COLUMN IF NOT EXISTS settled_at timestamptz;
                ALTER TABLE bets ADD COLUMN IF NOT EXISTS fixture_id text;
                ALTER TABLE bets ADD COLUMN IF NOT EXISTS home_score int;
                ALTER TABLE bets ADD COLUMN IF NOT EXISTS away_score int;
                ALTER TABLE bets ADD COLUMN IF NOT EXISTS line_betted_on_refined numeric;
                ALTER TABLE bets ADD COLUMN IF NOT EXISTS bet_type_refined_ah text;
                ALTER TABLE bets ADD COLUMN IF NOT EXISTS odds_betted_on_refined numeric;
                """)
                insert_sql = """
                INSERT INTO bets(run_id, dt_gmt8, league, home, away, tier, comp_type, side, line, odds, ev, stake, pl, cum_bankroll, line_betted_on_refined, bet_type_refined_ah, odds_betted_on_refined)
                VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
                """
                # prepare cumulative bankroll
                running = 100.0
                for _, r in refined_bets_placed_df.sort_values(by='datetime_gmt8', na_position='last').iterrows():
                    running += float(r.get('profit_loss_refined_ah', 0) or 0)
                    cur.execute(
                        insert_sql,
                        (
                            RUN_ID,
                            r.get('datetime_gmt8'), r.get('league'), r.get('home_name'), r.get('away_name'),
                            int(r.get('league_tier')) if pd.notna(r.get('league_tier')) else None,
                            r.get('competition_type'),
                            'home' if r.get('bet_type_refined_ah') == 'bet_home_refined_ah' else 'away',
                            r.get('line_betted_on_refined'), r.get('odds_betted_on_refined'), r.get('ev_for_bet_refined'),
                            r.get('stake_ah'), r.get('profit_loss_refined_ah'), running,
                            r.get('line_betted_on_refined'), r.get('bet_type_refined_ah'), r.get('odds_betted_on_refined')
                        )
                    )
                conn.commit(); cur.close(); conn.close()
                print("Bet records inserted to Postgres.")
                logging.info("Bet records inserted to Postgres successfully.")
            except Exception as e:
                print(f"Postgres bets insert skipped/failed: {e}")
                logging.error(f"Postgres insert failed: {e}")
    else:
        print("No bets were placed with the automated refined segmented policy.")

print("\n--- End of Section 7.2 (NEW): Automated Policy Generation & Refined AH Backtest ---")

"""Section 8: Generating Future Match Recommendations"""

# ==============================================================================
# SECTION 8 (FINAL & COMPLETE): GENERATING FUTURE MATCH RECOMMENDATIONS
# ==============================================================================

# --- Ensure all prerequisite libraries are imported ---
import pandas as pd
import numpy as np
from datetime import datetime, timedelta, timezone
import pytz
from scipy.optimize import minimize
from math import lgamma, exp, pow
from scipy.stats import poisson

# Optional integrations disabled here to avoid IDE import warnings
gspread = None
auth = None
google_auth_default = None
GoogleAuthRequest = None
cellFormat = None
textFormat = None
gspread_color = None
format_cell_range = None

print("\n--- Section 8 (Final & Complete): Generating Future Match Recommendations & Outputting to Google Sheet ---")

# ==============================================================================
#  HELPER FUNCTION DEFINITIONS
# ==============================================================================
# (Defining these here makes this section self-contained and robust)

def biv_poisson_pmf(x, y, lambda1, lambda2, phi, max_k_sum=20):
    """Calculates the Bivariate Poisson Probability Mass Function P(X=x, Y=y)."""
    x, y = int(x), int(y)
    if pd.isna(lambda1) or pd.isna(lambda2) or pd.isna(phi) or lambda1 <= 0 or lambda2 <= 0: return 1e-100
    current_phi = max(0, min(phi, lambda1 - 1e-7, lambda2 - 1e-7))
    try:
        if (lambda1 + lambda2 - current_phi) < 0: return 1e-100
        log_exp_term = -(lambda1 + lambda2 - current_phi)
        log_prob_sum_terms = []
        for k in range(min(x, y, max_k_sum) + 1):
            log_fact_xk, log_fact_yk, log_fact_k = lgamma(x-k+1), lgamma(y-k+1), lgamma(k+1)
            val_l1_minus_phi, val_l2_minus_phi = lambda1 - current_phi, lambda2 - current_phi
            log_term1 = (x-k) * np.log(val_l1_minus_phi) if val_l1_minus_phi > 1e-9 else -np.inf
            log_term2 = (y-k) * np.log(val_l2_minus_phi) if val_l2_minus_phi > 1e-9 else -np.inf
            log_term3 = k * np.log(current_phi) if current_phi > 1e-9 else -np.inf
            current_log_sum_term = log_term1-log_fact_xk + log_term2-log_fact_yk + log_term3-log_fact_k
            log_prob_sum_terms.append(current_log_sum_term)
        max_log_term = np.nanmax(log_prob_sum_terms) if log_prob_sum_terms else -np.inf
        if max_log_term == -np.inf: return 1e-100
        sum_exp_terms = np.sum(np.exp(np.array(log_prob_sum_terms) - max_log_term))
        return exp(log_exp_term + max_log_term + np.log(sum_exp_terms))
    except (ValueError, OverflowError): return 1e-100

def calculate_ah_outcome_probabilities_split(score_matrix, ah_line_home_team):
    """Calculates probabilities for Win, Loss, Push, Half-Win, Half-Loss for a given AH line."""
    if not isinstance(score_matrix, np.ndarray) or pd.isna(score_matrix).all(): return {'win':np.nan, 'loss':np.nan, 'push':np.nan, 'half_win':np.nan, 'half_loss':np.nan}
    p_win, p_loss, p_push, p_half_win, p_half_loss = 0.0, 0.0, 0.0, 0.0, 0.0
    num_goals = score_matrix.shape[0] - 1
    for h_goals in range(num_goals + 1):
        for a_goals in range(num_goals + 1):
            prob_score = score_matrix[h_goals, a_goals]
            if pd.isna(prob_score) or prob_score == 0: continue
            effective_margin = (h_goals - a_goals) + ah_line_home_team
            if effective_margin > 0.25: p_win += prob_score
            elif effective_margin == 0.25: p_half_win += prob_score
            elif effective_margin == 0: p_push += prob_score
            elif effective_margin == -0.25: p_half_loss += prob_score
            else: p_loss += prob_score
    return {'win': p_win, 'loss': p_loss, 'push': p_push, 'half_win': p_half_win, 'half_loss': p_half_loss}

def calculate_1x2_from_lambdas(lambda_h, lambda_a, max_goals=7):
    """Calculates P(H), P(D), P(A) from independent Poisson lambdas."""
    if pd.isna(lambda_h) or pd.isna(lambda_a) or lambda_h<=0 or lambda_a<=0: return np.nan, np.nan, np.nan
    pH, pD, pA = 0.0, 0.0, 0.0
    for hg in range(max_goals+1):
        for ag in range(max_goals+1):
            prob = poisson.pmf(hg, lambda_h) * poisson.pmf(ag, lambda_a)
            if hg > ag: pH += prob
            elif hg == ag: pD += prob
            else: pA += prob
    total = pH + pD + pA
    return (pH/total, pD/total, pA/total) if total > 0 else (1/3, 1/3, 1/3)

def objective_market_lambdas(lambdas, p_h_market, p_d_market, p_a_market):
    """Objective function to find lambdas that match market 1X2 probabilities."""
    lambda_h, lambda_a = lambdas
    if lambda_h <= 1e-4 or lambda_a <= 1e-4: return 1000.0
    p_h_model, p_d_model, p_a_model = calculate_1x2_from_lambdas(lambda_h, lambda_a)
    if pd.isna(p_h_model): return 1000.0
    return (p_h_model - p_h_market)**2 + (p_d_model - p_d_market)**2 + (p_a_model - p_a_market)**2

def get_closest_ah_line(pred_goal_diff):
    """Maps a predicted goal difference to the closest standard quarter AH line."""
    if pd.isna(pred_goal_diff): return np.nan
    lines = np.array([-2.0,-1.75,-1.5,-1.25,-1.0,-0.75,-0.5,-0.25,0.0,0.25,0.5,0.75,1.0,1.25,1.5,1.75,2.0])
    return lines[np.abs(lines + pred_goal_diff).argmin()]

def calculate_ev_for_ah_bet(p_w, p_hw, p_p, p_hl, p_l, odds):
    """Calculates EV for an Asian Handicap bet."""
    if any(pd.isna(p) for p in [p_w, p_hw, p_p, p_hl, p_l]) or pd.isna(odds) or odds <= 0: return np.nan
    profit_win, profit_hw, profit_p, profit_hl, profit_l = (odds-1), (odds-1)/2, 0, -0.5, -1.0
    return (p_w * profit_win) + (p_hw * profit_hw) + (p_p * profit_p) + (p_hl * profit_hl) + (p_l * profit_l)

def get_refined_ah_bet_decision(row, policy):
    """Applies a segmented betting policy to decide on an AH bet."""
    current_tier, current_comp_type = row['league_tier'], row['competition_type']
    home_line_market = row['synth_ah_line_home_market_based']
    ev_h, ev_a = row['ev_synth_home_ah'], row['ev_synth_away_ah']
    if pd.isna(home_line_market) or (pd.isna(ev_h) and pd.isna(ev_a)): return 'no_bet', np.nan, np.nan, np.nan
    potential_bets = []
    if pd.notna(ev_h): potential_bets.append({'side':'home', 'ev':ev_h, 'line':home_line_market, 'odds':row['synth_ah_odds_home_market_based']})
    if pd.notna(ev_a): potential_bets.append({'side':'away', 'ev':ev_a, 'line':-home_line_market, 'odds':row['synth_ah_odds_away_market_based']})
    if not potential_bets: return 'no_bet', np.nan, np.nan, np.nan
    allowed_value_bets = []
    for bet in potential_bets:
        policy_line_key = bet['line']
        rule = None
        policy_keys = [
            (current_tier, current_comp_type, policy_line_key),
            (current_tier, None, policy_line_key),
            (None, current_comp_type, policy_line_key),
            (current_tier, current_comp_type, None),
            (current_tier, None, None),
            (None, current_comp_type, None),
            (None, None, policy_line_key),
            'default'
        ]
        for key in policy_keys:
            if key in policy:
                rule = policy[key]
                break
        if rule is None:
            rule = {}  # Default empty

        if rule.get('allow_bet', True) and bet['ev'] > rule.get('min_ev', 0.20):
            allowed_value_bets.append(bet)
    if not allowed_value_bets: return 'no_bet', np.nan, np.nan, np.nan
    best_bet = max(allowed_value_bets, key=lambda x: x['ev'])
    return f"bet_{best_bet['side']}_refined_ah", best_bet['line'], best_bet['odds'], best_bet['ev']

def write_to_google_sheet(dataframe, base_sheet_name, worksheet_name_to_write, use_service_account=False, service_account_file=None):
    """Writes recommendations to a Google Sheet and returns success status and URL."""
    try:
        if gspread is None:
            raise ImportError("gspread is not available in this environment")
        print(f"\nAttempting to write to: '{base_sheet_name}' -> '{worksheet_name_to_write}'")
        if use_service_account:
            if service_account_file is None: raise ValueError("Service account file must be provided.")
            from google.oauth2.service_account import Credentials
            creds = Credentials.from_service_account_file(service_account_file, scopes=['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive.file'])
            gc = gspread.authorize(creds)
        else: # Colab user auth
            if auth is None or google_auth_default is None or GoogleAuthRequest is None:
                raise EnvironmentError("Google Colab auth is unavailable in this environment")
            auth.authenticate_user()
            creds, _ = google_auth_default(scopes=['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive.file'])
            if getattr(creds, 'expired', False) and getattr(creds, 'refresh_token', None):
                creds.refresh(GoogleAuthRequest())
            gc = gspread.authorize(creds)

        spreadsheet = gc.open(base_sheet_name)
        try:
            worksheet = spreadsheet.worksheet(worksheet_name_to_write)
            print(f"Clearing existing worksheet: '{worksheet_name_to_write}'")
            worksheet.clear()
        except gspread.exceptions.WorksheetNotFound:
            worksheet = spreadsheet.add_worksheet(title=worksheet_name_to_write, rows="100", cols=max(20, dataframe.shape[1] + 2))
            print(f"Created new worksheet: '{worksheet_name_to_write}'")

        df_for_gsheet = dataframe.astype(object).where(pd.notnull(dataframe), "")
        worksheet.update([df_for_gsheet.columns.values.tolist()] + df_for_gsheet.values.tolist(), value_input_option='USER_ENTERED')
        print(f"Data successfully written to worksheet: '{worksheet_name_to_write}'")
        return True, worksheet.spreadsheet.url
    except Exception as e:
        print(f"Error writing to Google Sheet: {e}")
        logging.error(f"Google Sheet write failed: {e}")
        return False, None

def format_google_sheet(spreadsheet_name, worksheet_name, use_service_account=False, service_account_file=None, cols_for_3dp=None):
    """Applies beautiful formatting to the specified worksheet."""
    if cols_for_3dp is None: cols_for_3dp = []
    print(f"Attempting to format worksheet: '{worksheet_name}'...")
    try:
        if gspread is None or cellFormat is None or textFormat is None or gspread_color is None or format_cell_range is None:
            raise ImportError("gspread formatting libraries are not available; skipping formatting")
        if use_service_account:
            if service_account_file is None: raise ValueError("Service account file must be provided.")
            from google.oauth2.service_account import Credentials
            creds = Credentials.from_service_account_file(service_account_file, scopes=['https://www.googleapis.com/auth/spreadsheets'])
            gc = gspread.authorize(creds)
        else: # Colab user auth
            if auth is None or google_auth_default is None or GoogleAuthRequest is None:
                raise EnvironmentError("Google Colab auth is unavailable in this environment")
            auth.authenticate_user()
            creds, _ = google_auth_default()
            if getattr(creds, 'expired', False) and getattr(creds, 'refresh_token', None):
                creds.refresh(GoogleAuthRequest())
            gc = gspread.authorize(creds)

        spreadsheet = gc.open(spreadsheet_name)
        worksheet = spreadsheet.worksheet(worksheet_name)

        all_values = worksheet.get_all_values()
        if not all_values: return

        num_rows, num_cols = len(all_values), len(all_values[0]) if all_values else 0
        if num_cols == 0: return

        default_font_format = cellFormat(textFormat=textFormat(fontFamily="Roboto", fontSize=10))
        header_format = cellFormat(backgroundColor=gspread_color(0/255, 77/255, 77/255),
                                   textFormat=textFormat(fontFamily="Roboto", fontSize=11, bold=True, foregroundColor=gspread_color(1, 1, 1)),
                                   horizontalAlignment='CENTER', verticalAlignment='MIDDLE')

        end_cell_a1 = gspread.utils.rowcol_to_a1(num_rows, num_cols)
        format_cell_range(worksheet, f'A1:{end_cell_a1}', default_font_format)
        format_cell_range(worksheet, '1:1', header_format)

        headers = all_values[0]
        for col_index, header_name in enumerate(headers):
            col_letter = gspread.utils.col_num_to_letter(col_index + 1)
            data_range = f'{col_letter}2:{col_letter}{num_rows}'
            current_format = None
            if header_name in cols_for_3dp: current_format = cellFormat(numberFormat={'type': 'NUMBER', 'pattern': '0.000'})
            elif any(k in header_name.lower() for k in ['odds', 'ev', 'line_betted']): current_format = cellFormat(numberFormat={'type': 'NUMBER', 'pattern': '0.00'})
            elif any(k in header_name.lower() for k in ['tier', 'matches_last', 'goalcount']): current_format = cellFormat(numberFormat={'type': 'NUMBER', 'pattern': '0'})
            elif 'datetime_gmt8' in header_name.lower(): current_format = cellFormat(numberFormat={'type':'DATE_TIME', 'pattern':'yyyy-mm-dd hh:mm'})
            if current_format and num_rows > 1: format_cell_range(worksheet, data_range, current_format)

        batch_update_requests = [{"updateSheetProperties": {"properties": {"sheetId": worksheet.id, "gridProperties": {"frozenRowCount": 1}}, "fields": "gridProperties.frozenRowCount"}}]
        for i in range(num_cols):
            max_length = max(len(str(row[i])) for row in all_values if len(row) > i) if all_values else 10
            pixel_width = max(80, min(450, (max_length + 4) * 7))
            batch_update_requests.append({"updateDimensionProperties": {"range": {"sheetId": worksheet.id, "dimension": "COLUMNS", "startIndex": i, "endIndex": i + 1}, "properties": {"pixelSize": pixel_width}, "fields": "pixelSize"}})
        if batch_update_requests: spreadsheet.batch_update({"requests": batch_update_requests})

        print(f"Worksheet '{worksheet_name}' beautifully formatted.")
    except Exception as e: print(f"Skipping formatting: {e}")

# ==============================================================================
#  SECTION 9: Daily Settlement Helper (Post-run P&L updates)
# ==============================================================================
def _normalize_team_name(name: str) -> str:
    try:
        return str(name or "").strip().lower()
    except Exception:
        return ""
def settle_open_bets(footystats_api_key: str, db_url: str, hours_buffer: int = 2) -> None:
    """Settle open bets in the Postgres `bets` table using FootyStats final scores.

    Requirements (DB columns, with fallbacks handled where possible):
      - bet_id (primary key)
      - dt_gmt8 (timestamp, fixture datetime in GMT+8)
      - league, home, away (strings)
      - line_betted_on_refined or line (number)
      - odds_betted_on_refined or odds (number)
      - bet_type_refined_ah (string) or side (string: 'home'|'away')
      - stake (number, default 1.0 if null)
      - status ('open'|'settled'), pl (float), settled_at (timestamp)

    If FootyStats key is missing or a match cannot be matched, the bet is skipped.
    """
    import os
    import psycopg2
    import pandas as pd
    from datetime import timedelta

    if not db_url:
        print("Settlement skipped: DATABASE_URL not provided.")
        return
    if not footystats_api_key:
        print("Settlement skipped: FOOTYSTATS_API_KEY not provided.")
        return

    try:
        conn = psycopg2.connect(db_url)
        cur = conn.cursor()
        # Fetch open bets older than buffer window
        cur.execute(
            """
            SELECT 
              CAST(bet_id AS TEXT) AS bet_key,
              dt_gmt8, league, home, away,
              COALESCE(line_betted_on_refined, line) AS line_val,
              COALESCE(odds_betted_on_refined, odds) AS odds_val,
              COALESCE(stake, 1.0) AS stake_val,
              COALESCE(bet_type_refined_ah, side) AS side_val
            FROM bets
            WHERE (status IS NULL OR status = 'open')
              AND dt_gmt8 < NOW() - INTERVAL '%s hours'
            ORDER BY dt_gmt8 ASC
            """,
            (hours_buffer,)
        )
        rows = cur.fetchall()
        if not rows:
            print("No open bets to settle.")
            cur.close(); conn.close()
            return

        # Group by league to minimize API calls
        import numpy as _np
        import pandas as _pd
        open_df = _pd.DataFrame(rows, columns=[
            'bet_key','dt_gmt8','league','home','away','line_val','odds_val','stake_val','side_val'
        ])

        # Build a cache of recent matches per league using existing FootyStats fetcher
        league_to_matches = {}
        unique_leagues = sorted([l for l in open_df['league'].dropna().unique()])

        for league_name in unique_leagues:
            try:
                season_ids = get_season_ids_for_league(footystats_api_key, league_name, past_seasons=1)
                league_matches = []
                for s_id in season_ids:
                    m = get_league_match_data(footystats_api_key, s_id, league_name)
                    if m is not None and not m.empty:
                        league_matches.append(m)
                league_df = pd.concat(league_matches, ignore_index=True) if league_matches else pd.DataFrame()
                # Normalize names and timestamps for matching
                if not league_df.empty:
                    for col in ['home_name','away_name','homeTeam','awayTeam','home','away']:
                        if col in league_df.columns:
                            league_df[col+'_norm'] = league_df[col].astype(str).str.strip().str.lower()
                    # unify goal columns
                    if 'homeGoalCount' not in league_df.columns:
                        if 'home_goals' in league_df.columns:
                            league_df['homeGoalCount'] = pd.to_numeric(league_df['home_goals'], errors='coerce')
                    if 'awayGoalCount' not in league_df.columns:
                        if 'away_goals' in league_df.columns:
                            league_df['awayGoalCount'] = pd.to_numeric(league_df['away_goals'], errors='coerce')
                    # unify datetime - ensure timezone-naive
                    dt_col = None
                    for c in ['datetime_gmt8','date_unix','date']:
                        if c in league_df.columns:
                            dt_col = c; break
                    if dt_col is not None:
                        try:
                            league_df['dt'] = pd.to_datetime(league_df[dt_col], errors='coerce', utc=True).tz_localize(None)
                        except Exception:
                            league_df['dt'] = pd.NaT
                league_to_matches[league_name] = league_df
            except Exception as e:
                print(f"Settlement warning: failed to fetch league '{league_name}': {e}")
                league_to_matches[league_name] = pd.DataFrame()

        settled = 0
        for _, r in open_df.iterrows():
            bet_id = r['bet_key']
            league = r['league']
            home = _normalize_team_name(r['home'])
            away = _normalize_team_name(r['away'])
            side_raw = str(r['side_val'] or '').lower()
            side = 'home' if 'home' in side_raw else ('away' if 'away' in side_raw else None)
            line = r['line_val']
            odds = r['odds_val']
            stake = r['stake_val']
            dt_bet = pd.to_datetime(r['dt_gmt8'], errors='coerce', utc=True).tz_localize(None)

            if bet_id is None or league not in league_to_matches or side is None:
                continue

            league_df = league_to_matches.get(league, pd.DataFrame())
            if league_df is None or league_df.empty:
                continue

            # Find closest match by date and team names (best-effort)
            candidates = league_df.copy()
            # Choose available normalized name columns
            home_cols = [c for c in candidates.columns if c.endswith('_norm') and c.startswith('home')]
            away_cols = [c for c in candidates.columns if c.endswith('_norm') and c.startswith('away')]
            ok = False
            match_row = None
            for hc in home_cols:
                for ac in away_cols:
                    mask = (candidates[hc] == home) & (candidates[ac] == away)
                    if mask.any():
                        sub = candidates.loc[mask].copy()
                        if 'dt' in sub.columns and pd.notna(dt_bet):
                            sub['abs_dt_diff'] = (sub['dt'] - dt_bet).abs()
                            sub = sub.sort_values('abs_dt_diff')
                        match_row = sub.iloc[0]
                        ok = True
                        break
                if ok:
                    break
            if not ok or match_row is None:
                continue

            try:
                hg = float(match_row.get('homeGoalCount', _np.nan))
                ag = float(match_row.get('awayGoalCount', _np.nan))
                if not _np.isfinite(hg) or not _np.isfinite(ag):
                    continue
                profit = resolve_ah_bet_profit(int(hg), int(ag), float(line), side, float(odds), float(stake))
                cur.execute(
                    """
                    UPDATE bets
                    SET pl = %s, status = 'settled', settled_at = NOW()
                    WHERE CAST(bet_id AS TEXT) = %s
                    """,
                    (profit, str(bet_id))
                )
                settled += 1
            except Exception as e:
                print(f"Settlement warning: bet {bet_id} update failed: {e}")

        conn.commit()
        cur.close(); conn.close()
        print(f"Settled {settled} bets.")
    except Exception as e:
        print(f"Settlement error: {e}")

# ==============================================================================
#  MAIN LOGIC FOR SECTION 8
# ==============================================================================

# --- 0. Configuration ---
DAYS_FOR_RECOMMENDATIONS = 7
GOOGLE_SHEET_NAME = 'GBM DC EV Model'
WRITE_TO_GSHEET = True
USE_SERVICE_ACCOUNT_AUTH = False
SERVICE_ACCOUNT_FILE = '/content/your_service_account_credentials.json'

# --- Safety Check ---
# ... (Condensed for brevity, assuming prerequisite variables are loaded) ...

if 'df_to_predict_future' not in locals() or df_to_predict_future.empty :
    print("No future matches available to process. Please ensure Section 4 has run correctly.")
else:
    # --- 1. Filter for Near-Term Future Matches ---
    print(f"\nFiltering for matches in the next {DAYS_FOR_RECOMMENDATIONS} days...")
    df_predict_period_input = df_to_predict_future.copy()
    if 'datetime_gmt8' not in df_predict_period_input.columns or not pd.api.types.is_datetime64_any_dtype(df_predict_period_input['datetime_gmt8']):
        print("Error: 'datetime_gmt8' column is missing or not in datetime format. Stopping recommendation generation.")
        df_predict_period_filtered = pd.DataFrame()
    else:
        now_utc = datetime.now(timezone.utc)
        gmt_plus_8_tz = pytz.timezone('Asia/Singapore')
        now_gmt8_aware = now_utc.astimezone(gmt_plus_8_tz)
        now_gmt8_for_comparison = now_gmt8_aware.replace(tzinfo=None)
        print(f"Current reference time for filtering (GMT+8, naive): {now_gmt8_for_comparison}")
        recommendation_period_end_date = now_gmt8_for_comparison + timedelta(days=DAYS_FOR_RECOMMENDATIONS)
        df_predict_period_filtered = df_predict_period_input[
            (df_predict_period_input['datetime_gmt8'] > now_gmt8_for_comparison) &
            (df_predict_period_input['datetime_gmt8'] <= recommendation_period_end_date)
        ].copy()

    # --- 2-7. Full Prediction and Decision Pipeline ---
    if df_predict_period_filtered.empty:
        print(f"No future matches found within the next {DAYS_FOR_RECOMMENDATIONS} days.")
    else:
        print(f"Processing {len(df_predict_period_filtered)} future matches for the upcoming period...")

        X_future_to_predict_final = X_future_processed_df.loc[df_predict_period_filtered.index]
        recommendations_df_in_progress = df_predict_period_filtered.copy()

        # Step 2: Predict Mean Goals (with tier-specific models)
        print("  Predicting mean goals for upcoming matches...")
        
        future_tiers = recommendations_df_in_progress['league_tier'].fillna(5)
        pred_home_future = np.zeros(len(X_future_to_predict_final))
        pred_away_future = np.zeros(len(X_future_to_predict_final))
        
        for i, tier in enumerate(future_tiers):
            tier_int = int(tier) if not pd.isna(tier) else 5
            
            if tier_int in tier_models_home and tier_int in tier_models_away:
                # Use tier-specific model and calibrator if available
                pred_home_raw = tier_models_home[tier_int].predict(X_future_to_predict_final.iloc[[i]])[0]
                pred_away_raw = tier_models_away[tier_int].predict(X_future_to_predict_final.iloc[[i]])[0]
                
                # Apply tier-specific calibration if available
                if tier_int in tier_calibrators_home and tier_int in tier_calibrators_away:
                    pred_home_future[i] = tier_calibrators_home[tier_int].predict([[pred_home_raw]])[0]
                    pred_away_future[i] = tier_calibrators_away[tier_int].predict([[pred_away_raw]])[0]
                else:
                    pred_home_future[i] = pred_home_raw
                    pred_away_future[i] = pred_away_raw
            else:
                # Use fallback model with general calibration
                pred_home_raw = final_model_home_goals.predict(X_future_to_predict_final.iloc[[i]])[0]
                pred_away_raw = final_model_away_goals.predict(X_future_to_predict_final.iloc[[i]])[0]
                
                # Apply general calibration if available
                if 'calib_home' in locals() and 'calib_away' in locals():
                    pred_home_future[i] = calib_home.predict([[pred_home_raw]])[0]
                    pred_away_future[i] = calib_away.predict([[pred_away_raw]])[0]
                else:
                    pred_home_future[i] = pred_home_raw
                    pred_away_future[i] = pred_away_raw
        
        recommendations_df_in_progress['pred_home_goals'] = pred_home_future
        recommendations_df_in_progress['pred_away_goals'] = pred_away_future
        recommendations_df_in_progress.loc[recommendations_df_in_progress['pred_home_goals'] < 0, 'pred_home_goals'] = 1e-6
        recommendations_df_in_progress.loc[recommendations_df_in_progress['pred_away_goals'] < 0, 'pred_away_goals'] = 1e-6

        # Step 2.1: Generate SHAP explanations for recommendations
        print("  Generating SHAP feature explanations...")
        try:
            import shap
            
            # Create SHAP explainer for home goals model
            explainer_home = shap.TreeExplainer(final_model_home_goals)
            explainer_away = shap.TreeExplainer(final_model_away_goals)
            
            # Calculate SHAP values for future matches
            shap_values_home = explainer_home.shap_values(X_future_to_predict_final)
            shap_values_away = explainer_away.shap_values(X_future_to_predict_final)
            
            # Get feature names
            feature_names = X_future_to_predict_final.columns.tolist()
            
            # For each recommendation, get top 5 most influential features
            shap_explanations = []
            for idx in range(len(X_future_to_predict_final)):
                # Home model top features
                home_shap = shap_values_home[idx]
                home_top_idx = np.argsort(np.abs(home_shap))[-5:][::-1]
                home_top_features = [(feature_names[i], home_shap[i]) for i in home_top_idx]
                
                # Away model top features
                away_shap = shap_values_away[idx]
                away_top_idx = np.argsort(np.abs(away_shap))[-5:][::-1]
                away_top_features = [(feature_names[i], away_shap[i]) for i in away_top_idx]
                
                # Combine and format
                explanation = {
                    'home_top_features': home_top_features,
                    'away_top_features': away_top_features,
                    'home_explanation': '; '.join([f"{feat}: {val:.3f}" for feat, val in home_top_features[:3]]),
                    'away_explanation': '; '.join([f"{feat}: {val:.3f}" for feat, val in away_top_features[:3]])
                }
                shap_explanations.append(explanation)
            
            # Add explanations to dataframe
            recommendations_df_in_progress['shap_home_explanation'] = [exp['home_explanation'] for exp in shap_explanations]
            recommendations_df_in_progress['shap_away_explanation'] = [exp['away_explanation'] for exp in shap_explanations]
            
            print(f"  Generated SHAP explanations for {len(shap_explanations)} matches.")
            
        except ImportError:
            print("  SHAP not available - skipping feature explanations")
            recommendations_df_in_progress['shap_home_explanation'] = "SHAP not available"
            recommendations_df_in_progress['shap_away_explanation'] = "SHAP not available"
        except Exception as e:
            print(f"  SHAP explanation generation failed: {e}")
            recommendations_df_in_progress['shap_home_explanation'] = "Error generating explanations"
            recommendations_df_in_progress['shap_away_explanation'] = "Error generating explanations"

        # --- 3. Derive Scoreline Probabilities (Bivariate Poisson) ---
        print("  Deriving scoreline probabilities...")
        future_scoreline_matrices = []
        for index, row in recommendations_df_in_progress.iterrows():
            lambda_h = row['pred_home_goals']
            lambda_a = row['pred_away_goals']

            prob_matrix = np.zeros((MAX_GOALS_FOR_MATRIX + 1, MAX_GOALS_FOR_MATRIX + 1))
            
            # Use learned phi model if available
            if phi_model is not None:
                phi_features_match = pd.DataFrame({
                    'lambda_home': [lambda_h],
                    'lambda_away': [lambda_a],
                    'lambda_total': [lambda_h + lambda_a],
                    'lambda_diff': [lambda_h - lambda_a],
                    'lambda_min': [min(lambda_h, lambda_a)],
                    'lambda_max': [max(lambda_h, lambda_a)],
                    'lambda_ratio': [lambda_h / (lambda_a + 1e-6)],
                    'lambda_product': [lambda_h * lambda_a]
                })
                predicted_phi = phi_model.predict(phi_features_match)[0]
                seg_phi = predicted_phi
            else:
                # Fallback to segment-based phi
                total_l = float(lambda_h + lambda_a)
                if 'optimized_phis_by_segment' in globals() and optimized_phis_by_segment:
                    if total_l < 2.3:
                        seg_phi = optimized_phis_by_segment.get('low_scoring', optimal_phi)
                    elif total_l <= 3.0:
                        seg_phi = optimized_phis_by_segment.get('medium_scoring', optimal_phi)
                    else:
                        seg_phi = optimized_phis_by_segment.get('high_scoring', optimal_phi)
                else:
                    seg_phi = optimal_phi
            
            current_match_phi = max(0.0, min(float(seg_phi), float(lambda_h) - 1e-7, float(lambda_a) - 1e-7))

            # Use nested loops to calculate probability for each scoreline
            for i in range(MAX_GOALS_FOR_MATRIX + 1): # i represents home_goals (a single number)
                for j in range(MAX_GOALS_FOR_MATRIX + 1): # j represents away_goals (a single number)
                    prob_matrix[i, j] = biv_poisson_pmf(i, j, lambda_h, lambda_a, current_match_phi)

            # Normalize the matrix so its elements sum to 1
            matrix_sum = np.sum(prob_matrix)
            if matrix_sum > 1e-9:
                prob_matrix /= matrix_sum
            else: # Fallback if all probabilities are tiny
                prob_matrix = np.full(((MAX_GOALS_FOR_MATRIX + 1), (MAX_GOALS_FOR_MATRIX + 1)), 1.0 / ((MAX_GOALS_FOR_MATRIX + 1)**2))

            future_scoreline_matrices.append(prob_matrix)

        recommendations_df_in_progress['scoreline_prob_matrix'] = future_scoreline_matrices

        # Step 4: Calculate AH Probabilities
        print("  Calculating AH outcome probabilities...")
        ah_lines_to_calculate = [-2.0, -1.75, -1.5, -1.25, -1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0]
        new_ah_prob_cols = {}
        for line in ah_lines_to_calculate:
            line_str = str(line).replace(".", "p").replace("-", "neg")
            outcomes_list = [calculate_ah_outcome_probabilities_split(matrix, line) for matrix in recommendations_df_in_progress['scoreline_prob_matrix']]
            temp_outcomes_df = pd.DataFrame(outcomes_list, index=recommendations_df_in_progress.index)
            for outcome_type_short, outcome_type_long in {'win':'win', 'hw':'half_win', 'push':'push', 'hl':'half_loss', 'lose':'loss'}.items():
                new_ah_prob_cols[f'p_home_{outcome_type_short}_ah_{line_str}'] = temp_outcomes_df[outcome_type_long]
        for col_name, col_data in new_ah_prob_cols.items(): recommendations_df_in_progress[col_name] = col_data

        # --- 5. Generate Synthetic AH Line & Odds (from 1X2 market odds) ---
        print("  Generating synthetic AH lines/odds for upcoming matches...")
        market_lh_list_fut, market_la_list_fut = [], []

        # Ensure 'odds_ft_1', 'odds_ft_x', 'odds_ft_2' are present
        if all(c in recommendations_df_in_progress.columns for c in ['odds_ft_1', 'odds_ft_x', 'odds_ft_2']):
            for index, row_fut in recommendations_df_in_progress.iterrows():
                odds_h = pd.to_numeric(row_fut['odds_ft_1'], errors='coerce')
                odds_d = pd.to_numeric(row_fut['odds_ft_x'], errors='coerce')
                odds_a = pd.to_numeric(row_fut['odds_ft_2'], errors='coerce')

                # If odds are invalid, append NaN and continue to the next match
                if pd.isna(odds_h) or pd.isna(odds_d) or pd.isna(odds_a) or odds_h<=0 or odds_d<=0 or odds_a<=0:
                    market_lh_list_fut.append(np.nan)
                    market_la_list_fut.append(np.nan)
                    continue

                p_h_raw=1/odds_h; p_d_raw=1/odds_d; p_a_raw=1/odds_a; sum_p = p_h_raw+p_d_raw+p_a_raw

                if sum_p==0: # Unlikely, but a safeguard
                    market_lh_list_fut.append(np.nan)
                    market_la_list_fut.append(np.nan)
                    continue

                p_h_m=p_h_raw/sum_p; p_d_m=p_d_raw/sum_p; p_a_m=p_a_raw/sum_p

                res = minimize(objective_market_lambdas, [1.5,1.2], args=(p_h_m,p_d_m,p_a_m),
                              method='L-BFGS-B', bounds=[(0.01,7),(0.01,7)],
                              options={'ftol':1e-7,'maxiter':100})

                if res.success:
                    market_lh_list_fut.append(res.x[0])
                    market_la_list_fut.append(res.x[1])
                else: # If optimization fails, append NaN
                    market_lh_list_fut.append(np.nan)
                    market_la_list_fut.append(np.nan)

            # Now assign the lists which have the same length as the DataFrame
            recommendations_df_in_progress['market_lambda_h'] = market_lh_list_fut
            recommendations_df_in_progress['market_lambda_a'] = market_la_list_fut
        else:
            print("    Warning: 1X2 odds not found for future matches. Using model's own lambdas for AH line setting.")
            recommendations_df_in_progress['market_lambda_h'] = recommendations_df_in_progress['pred_home_goals']
            recommendations_df_in_progress['market_lambda_a'] = recommendations_df_in_progress['pred_away_goals']

        # The rest of the section follows...
        recommendations_df_in_progress['market_pred_goal_diff'] = recommendations_df_in_progress['market_lambda_h'] - recommendations_df_in_progress['market_lambda_a']
        recommendations_df_in_progress['synth_ah_line_home_market_based'] = recommendations_df_in_progress['market_pred_goal_diff'].apply(get_closest_ah_line)
        recommendations_df_in_progress['synth_ah_odds_home_market_based'] = np.where(pd.notna(recommendations_df_in_progress['synth_ah_line_home_market_based']), SYNTHETIC_AH_ODDS_HOME, np.nan)
        recommendations_df_in_progress['synth_ah_odds_away_market_based'] = np.where(pd.notna(recommendations_df_in_progress['synth_ah_line_home_market_based']), SYNTHETIC_AH_ODDS_AWAY, np.nan)

        # Step 6: Calculate EV
        print("  Calculating EV for main synthetic AH line...")
        ev_h_list_fut, ev_a_list_fut = [], []
        for idx, row_fut in recommendations_df_in_progress.iterrows():
            home_line = row_fut['synth_ah_line_home_market_based']
            if pd.isna(home_line): ev_h_list_fut.append(np.nan); ev_a_list_fut.append(np.nan); continue
            line_str = str(home_line).replace(".", "p").replace("-", "neg")
            p_hw=row_fut.get(f'p_home_win_ah_{line_str}',0); p_hhw=row_fut.get(f'p_home_hw_ah_{line_str}',0); p_hpush=row_fut.get(f'p_home_push_ah_{line_str}',0); p_hhl=row_fut.get(f'p_home_hl_ah_{line_str}',0); p_hl=row_fut.get(f'p_home_lose_ah_{line_str}',0)
            ev_h = calculate_ev_for_ah_bet(p_hw,p_hhw,p_hpush,p_hhl,p_hl, row_fut['synth_ah_odds_home_market_based'])
            ev_a = calculate_ev_for_ah_bet(p_hl,p_hhl,p_hpush,p_hhw,p_hw, row_fut['synth_ah_odds_away_market_based'])
            ev_h_list_fut.append(ev_h); ev_a_list_fut.append(ev_a)
        recommendations_df_in_progress['ev_synth_home_ah'] = ev_h_list_fut
        recommendations_df_in_progress['ev_synth_away_ah'] = ev_a_list_fut

        # Step 7: Make Betting Decisions
        print("  Applying refined betting policy...")
        if 'AUTOMATED_BETTING_POLICY' in globals():
            refined_future_decisions = recommendations_df_in_progress.apply(lambda row: get_refined_ah_bet_decision(row, AUTOMATED_BETTING_POLICY), axis=1)
            decisions_df = pd.DataFrame(refined_future_decisions.to_list(), columns=['bet_type_refined_ah', 'line_betted_on_refined', 'odds_betted_on_refined', 'ev_for_bet_refined'], index=recommendations_df_in_progress.index)
            for col in decisions_df.columns: recommendations_df_in_progress[col] = decisions_df[col]
            final_recommendations_df = recommendations_df_in_progress[recommendations_df_in_progress['bet_type_refined_ah'] != 'no_bet'].copy()
            logging.info(f"Policy applied. Bets before filter: {len(recommendations_df_in_progress)}, after: {len(final_recommendations_df)}")  # NEW: Log counts
        else: 
            final_recommendations_df = pd.DataFrame() 
            logging.warning("AUTOMATED_BETTING_POLICY missing - no recommendations generated")
        print(f"Generated {len(final_recommendations_df)} betting recommendations.")
        # Step 8: Output Recommendations
        if not final_recommendations_df.empty:
            # Add new columns and sort
            def create_recommendation_text(row):
                line_val = row['line_betted_on_refined']; line_text = f"+{line_val}" if line_val > 0 else str(line_val)
                if 'home' in row['bet_type_refined_ah']: return f"{row['home_name']} {line_text}"
                elif 'away' in row['bet_type_refined_ah']: return f"{row['away_name']} {line_text}"
                return ""
            final_recommendations_df['Recommendation'] = final_recommendations_df.apply(create_recommendation_text, axis=1)

            # New: Generate King's Call
            import os
            import requests
            import time
            import json
            import re
            from pathlib import Path
            import logging

            xai_api_key = os.environ.get('XAI_API_KEY')
            # --- King's Call: Grok integration with debug trail ---
            if xai_api_key:
                # System prompt for betting analysis
                SYSTEM_PROMPT = """
                You are 'The King', a sharp, data-driven betting analyst known for balanced insights and subtle wit. Your analysis is called the "King's Call".

                Your task is to critically analyze a betting recommendation using live search for real-time data and respond ONLY with a JSON object with the following structure:
                {
                "agreement": "Agree", "Disagree", or "Neutral",
                "insight": "Your King's Call. A single, punchy sentence, 80-140 chars. Start with 'Agree:' or 'Disagree:'. Focus on key statistical factors, form trends, and tactical considerations. Use subtle wit but avoid over-reliance on injury narratives.",
                "reasoning": "Your detailed analysis (30-50 words) explaining why you agree/disagree. Balance statistical evidence, recent form, tactical matchups, and situational factors. Avoid repetitive injury-focused narratives unless truly decisive.",
                "sources": ["A list of 1-3 key sources used."]
                }

                Focus on: statistical trends, recent form, tactical matchups, motivation factors, and situational context. Only mention injuries when they're genuinely game-changing, not as a default narrative.

                Do NOT add any text outside of this JSON structure.
                """

                # Relaxed validation function for insights (helper for get_grok_response)
                def validate_insight(response: dict) -> bool:
                    insight = response.get('insight', '')
                    reasoning = response.get('reasoning', '')
                    agreement = response.get('agreement', '')
                    
                    # Basic validation - much more lenient
                    if not insight or len(insight) < 50:
                        logging.warning(f"Validation failed: Insight too short ({len(insight)} chars).")
                        return False
                    
                    if len(insight) > 200:
                        logging.info(f"Insight long ({len(insight)} chars) but acceptable, will truncate if needed.")
                    
                    if not reasoning or len(reasoning.split()) < 10:
                        logging.warning(f"Validation failed: Reasoning too short ({len(reasoning.split())} words).")
                        return False
                    
                    if agreement not in ['Agree', 'Disagree', 'Neutral']:
                        logging.warning(f"Validation failed: Invalid agreement value ({agreement}).")
                        return False
                    
                    # Don't require specific format - just check if it's meaningful
                    if len(insight.strip()) < 50:
                        logging.warning("Validation failed: Insight appears empty or too short.")
                        return False
                        
                    return True

                # Function to get Grok response with live search and structured output
                def get_grok_response(prompt: str, model="grok-4-fast-reasoning", enable_retry=False):
                    url = "https://api.x.ai/v1/chat/completions"
                    headers = {"Authorization": f"Bearer {xai_api_key}", "Content-Type": "application/json"}
                    messages = [
                        {"role": "system", "content": SYSTEM_PROMPT},
                        {"role": "user", "content": prompt}
                    ]
                    data = {
                        "model": model,
                        "messages": messages,
                        "max_tokens": 1500,  # Reduced for more focused output
                        "temperature": 0.7,  # Slightly less creative for more reliability
                        "search_parameters": {"mode": "on"}  # Enable live search
                    }
                    max_retries = 3
                    base_delay = 2  # Base delay for exponential backoff
                    
                    for attempt in range(max_retries):
                        try:
                            # Add exponential backoff delay
                            if attempt > 0:
                                delay = base_delay * (2 ** (attempt - 1))
                                logging.info(f"Retrying after {delay}s delay (attempt {attempt + 1})")
                                time.sleep(delay)
                            
                            response = requests.post(url, headers=headers, json=data, timeout=45)  # Shorter timeout
                            if response.status_code == 429:  # Rate limit
                                logging.warning(f"Rate limited (attempt {attempt + 1}). Status: {response.status_code}")
                                if attempt < max_retries - 1:  # Don't sleep on last attempt
                                    time.sleep(10)  # Wait 10s for rate limit
                                    continue
                                else:
                                    return {
                                        "agreement": "Neutral",
                                        "insight": "Rate limited—try again later.",
                                        "reasoning": "API rate limit exceeded.",
                                        "sources": [],
                                        "raw_response": {}
                                    }
                            elif response.status_code != 200:
                                logging.error(f"API response code: {response.status_code}, text: {response.text}")
                                if attempt < max_retries - 1:  # Retry on other errors too
                                    continue
                                else:
                                    return {
                                        "agreement": "Neutral",
                                        "insight": "API error—service unavailable.",
                                        "reasoning": f"API call failed with status {response.status_code}.",
                                        "sources": [],
                                        "raw_response": response.json() if response.content else {}
                                    }
                            raw_response = response.json()
                            logging.info(f"Full raw response: {json.dumps(raw_response, indent=2)}")
                            raw_content = raw_response['choices'][0]['message']['content'].strip()
                            # Save raw response to file for diagnostics
                            Path('artifacts/raw_responses').mkdir(parents=True, exist_ok=True)
                            with open(f'artifacts/raw_responses/response_{int(time.time())}_{model}.json', 'w', encoding='utf-8') as f:
                                json.dump(raw_response, f, indent=2)
                            if not raw_content:
                                logging.warning("Empty content from Grok—using default.")
                                return {
                                    "agreement": "Neutral",
                                    "insight": "Unable to fetch insight—rely on EV!",
                                    "reasoning": "Empty response from Grok.",
                                    "sources": [],
                                    "raw_response": raw_response
                                }
                            try:
                                content = json.loads(raw_content)
                                agreement = content.get('agreement', 'Neutral')
                                insight = content.get('insight', 'Unable to parse insight.')
                                reasoning = content.get('reasoning', 'No reasoning provided.')
                                sources = content.get('sources', [])
                                
                                # Truncate if too long but don't be too strict
                                if len(insight) > 180:
                                    logging.info(f"Insight long ({len(insight)} chars)—truncating to 180 chars.")
                                    insight = insight[:177] + "..."
                                
                                # Use relaxed validation
                                validation_result = validate_insight({"insight": insight, "reasoning": reasoning, "agreement": agreement})
                                
                                if validation_result:
                                    logging.info("Insight validated successfully.")
                                    return {
                                        "agreement": agreement,
                                        "insight": insight,
                                        "reasoning": reasoning,
                                        "sources": sources,
                                        "raw_response": raw_response
                                    }
                                else:
                                    # Even if validation fails, use the response if it's somewhat reasonable
                                    if len(insight) > 30 and agreement in ['Agree', 'Disagree', 'Neutral']:
                                        logging.warning("Using response despite validation failure—seems reasonable.")
                                        return {
                                            "agreement": agreement,
                                            "insight": insight,
                                            "reasoning": reasoning,
                                            "sources": sources,
                                            "raw_response": raw_response
                                        }
                                    
                                    # Only retry if validation completely failed and we have retries left
                                    if enable_retry and attempt < max_retries - 1:
                                        logging.warning("Response failed validation—retrying with adjusted prompt.")
                                        messages.append({"role": "assistant", "content": raw_content})
                                        messages.append({"role": "user", "content": "Please provide a clearer, more concise response. Ensure the insight is meaningful and the reasoning explains your position."})
                                        data["messages"] = messages
                                        data["max_tokens"] = 1200
                                        data["search_parameters"] = {"mode": "off"}  # Disable search on retry
                                        continue
                                    
                                    # Return what we have, even if not perfect
                                return {
                                    "agreement": agreement,
                                        "insight": insight if len(insight) > 10 else "Analysis inconclusive—rely on EV.",
                                        "reasoning": reasoning if len(reasoning) > 10 else "Unable to provide detailed reasoning.",
                                    "sources": sources,
                                    "raw_response": raw_response
                                }
                            except json.JSONDecodeError:
                                logging.warning("JSON parse failed—using fallback.")
                                match = re.search(r'\{.*"insight":\s*"([^"]+)"', raw_content, re.DOTALL)
                                if match:
                                    return {
                                        "agreement": "Neutral",
                                        "insight": match.group(1).strip()[:140],
                                        "reasoning": "Fallback: JSON parsing failed.",
                                        "sources": [],
                                        "raw_response": raw_response
                                    }
                                return {
                                    "agreement": "Neutral",
                                    "insight": "Unable to parse response.",
                                    "reasoning": "Fallback: JSON parsing failed.",
                                    "sources": [],
                                    "raw_response": raw_response
                                }
                        except requests.exceptions.ReadTimeout as e:
                            logging.warning("Timeout hit—retrying without search.")
                            data["search_parameters"] = {"mode": "off"}
                            continue
                        except requests.exceptions.HTTPError as e:
                            logging.error(f"HTTP error: {e} - Status: {e.response.status_code if e.response else 'Unknown'}")
                            raw_response = e.response.json() if e.response and e.response.content else {}
                            if e.response and e.response.status_code == 429:
                                logging.warning("Rate limit hit—sleeping 60s.")
                                time.sleep(60)
                                continue
                            elif e.response and e.response.status_code == 404:
                                logging.error("Model not found—trying grok-3.")
                                data["model"] = "grok-3"
                                continue
                            return {
                                "agreement": "Neutral",
                                "insight": "API error—check log.",
                                "reasoning": f"HTTP error: {e}",
                                "sources": [],
                                "raw_response": raw_response
                            }
                        except Exception as e:
                            logging.error(f"Grok API error: {e}")
                            return {
                                "agreement": "Neutral",
                                "insight": "Unable to fetch insight—rely on EV!",
                                "reasoning": f"API call failed: {e}",
                                "sources": [],
                                "raw_response": {}
                            }
                        logging.info(f"Retry {attempt+1}/{max_retries}.")
                    return {
                        "agreement": "Neutral",
                        "insight": "Unable to fetch insight—rely on EV!",
                        "reasoning": "API call failed after retries.",
                        "sources": [],
                        "raw_response": {}
                    }


                # Initialize King's Call columns using correct database column names
                final_recommendations_df['kings_call_insight'] = ''
                final_recommendations_df['kings_call_agreement'] = ''
                final_recommendations_df['kings_call_reasoning'] = ''
                final_recommendations_df['kings_call_sources'] = ''
                
                debug_rows = []
                total_recommendations = len(final_recommendations_df)
                
                # Filter for Tier 1 games only to optimize API usage
                tier1_recommendations = final_recommendations_df[final_recommendations_df['league_tier'] == 1].copy()
                
                # Further filter to today's games with buffer to save API costs
                from datetime import datetime, timezone, timedelta
                now_gmt8 = datetime.now(timezone(timedelta(hours=8)))
                
                # Create a more inclusive time window for "today's games"
                # Start from 6 hours ago to catch games that started recently
                # End at tomorrow 6 AM to catch late night games
                today_start = now_gmt8.replace(hour=0, minute=0, second=0, microsecond=0) - timedelta(hours=6)
                today_end = now_gmt8.replace(hour=0, minute=0, second=0, microsecond=0) + timedelta(days=1, hours=6)
                
                # Filter using datetime range instead of date equality
                today_recommendations = tier1_recommendations[
                    (pd.to_datetime(tier1_recommendations['datetime_gmt8']) >= today_start.replace(tzinfo=None)) &
                    (pd.to_datetime(tier1_recommendations['datetime_gmt8']) <= today_end.replace(tzinfo=None))
                ].copy()
                
                total_tier1 = len(tier1_recommendations)
                total_today = len(today_recommendations)
                total_all = len(final_recommendations_df)
                
                print(f"Generating King's Call for {total_today} Tier 1 games in today's window (6hrs ago to 6hrs into tomorrow) (out of {total_tier1} Tier 1 total, {total_all} overall)...")
                print(f"Time window: {today_start.strftime('%Y-%m-%d %H:%M')} to {today_end.strftime('%Y-%m-%d %H:%M')} GMT+8")
                
                for i, (idx, row) in enumerate(today_recommendations.iterrows()):
                    print(f"Processing {i+1}/{total_today}: {row['home_name']} vs {row['away_name']} ({row['league']})")
                    
                    prompt = (
                        f"Analyze betting recommendation: {row['Recommendation']} @ {row['odds_betted_on_refined']:.2f} odds, EV {row['ev_for_bet_refined']:.2f}. "
                        f"Match: {row['home_name']} vs {row['away_name']} ({row['league']}) on {row['datetime_gmt8']}. "
                        f"Consider: recent form, injuries, team motivation, manager situations. "
                        f"Provide structured analysis with agreement/disagreement."
                    )
                    
                    # Use the advanced get_grok_response function
                    result = get_grok_response(prompt, model="grok-4-fast-reasoning", enable_retry=True)
                    
                    # Add delay between API calls to avoid rate limiting
                    if i < total_today - 1:  # Don't delay after last call
                        time.sleep(3)  # 3 second delay between calls
                    
                    # Store all King's Call data using correct database column names
                    final_recommendations_df.at[idx, 'kings_call_insight'] = result.get('insight', 'Unable to fetch insight—rely on EV!')
                    final_recommendations_df.at[idx, 'kings_call_agreement'] = result.get('agreement', 'Neutral')
                    final_recommendations_df.at[idx, 'kings_call_reasoning'] = result.get('reasoning', 'No reasoning available')
                    final_recommendations_df.at[idx, 'kings_call_sources'] = ', '.join(result.get('sources', []))
                    
                    debug_rows.append({
                        'datetime_gmt8': row.get('datetime_gmt8'),
                        'league': row.get('league'),
                        'home': row.get('home_name'),
                        'away': row.get('away_name'),
                        'recommendation': row.get('Recommendation'),
                        'odds': row.get('odds_betted_on_refined'),
                        'ev': row.get('ev_for_bet_refined'),
                        'prompt_used': prompt,
                        'model': 'grok-4-fast-reasoning',
                        'agreement': result.get('agreement', 'Neutral'),
                        'insight': result.get('insight', 'Unable to fetch insight'),
                        'reasoning': result.get('reasoning', 'No reasoning available'),
                        'sources': ', '.join(result.get('sources', [])),
                        'parsed_tweet': result.get('insight', 'Unable to fetch insight')
                    })

                # Write debug CSV for inspection (artifacts and site)
                try:
                    from pathlib import Path
                    import csv as _csv
                    Path('artifacts/latest').mkdir(parents=True, exist_ok=True)
                    Path('site').mkdir(parents=True, exist_ok=True)
                    for out_path in ['artifacts/latest/kings_call_debug.csv', 'site/kings_call_debug.csv']:
                        with open(out_path, 'w', newline='', encoding='utf-8') as f:
                            w = _csv.DictWriter(f, fieldnames=[
                                'datetime_gmt8','league','home','away','recommendation','odds','ev','prompt_used','model','agreement','insight','reasoning','sources','parsed_tweet'
                            ])
                            w.writeheader()
                            for r in debug_rows:
                                w.writerow(r)
                except Exception as _e:
                    print(f"Debug write failed: {_e}")
                    logging.error(f"Debug write failed: {_e}")

            if 'kings_call' not in final_recommendations_df.columns:
                final_recommendations_df['kings_call'] = "King's insight: Solid bet based on ML analysis—watch this space!"
            final_recommendations_df['kings_call'] = final_recommendations_df['kings_call'].fillna("King's insight: Solid bet based on ML analysis—watch this space!")

            # Ensure parlay_wins.csv exists in site/
            try:
                import os, csv
                os.makedirs('site', exist_ok=True)
                parlay_csv = 'site/parlay_wins.csv'
                if 'parlay_wins' in globals():
                    with open(parlay_csv, 'w', newline='', encoding='utf-8') as f:
                        w = csv.writer(f)
                        w.writerow(['window_start','window_end','leg_count','total_odds','stake','payout','profit','legs'])
                        for row in parlay_wins:  # if available from earlier step
                            w.writerow(row)
                else:
                    # Sample data for testing
                    sample_parlays = [
                        ['2024-08-16 12:00', '2024-08-16 18:00', 3, 5.5, 100, 550, 450, 'TeamA vs TeamB | Rec1@1.5 || TeamC vs TeamD | Rec2@2.0 || TeamE vs TeamF | Rec3@1.8']
                    ]
                    with open(parlay_csv, 'w', newline='', encoding='utf-8') as f:
                        w = csv.writer(f)
                        w.writerow(['window_start','window_end','leg_count','total_odds','stake','payout','profit','legs'])
                        for row in sample_parlays:
                            w.writerow(row)
                    print("Wrote sample parlay_wins.csv for testing")
            except Exception as _:
                pass

            if 'df_for_training_and_testing' in globals():
                historical_team_ids = set(df_for_training_and_testing['homeID'].unique()) | set(df_for_training_and_testing['awayID'].unique())
                def get_confidence_level(row):
                    if row['homeID'] in historical_team_ids and row['awayID'] in historical_team_ids: return "High"
                    elif row['homeID'] in historical_team_ids or row['awayID'] in historical_team_ids: return "Medium"
                    else: return "Very Low"
                final_recommendations_df['confidence_level'] = final_recommendations_df.apply(get_confidence_level, axis=1)
                final_recommendations_df['confidence_sort'] = final_recommendations_df['confidence_level'].map({'High': 1, 'Medium': 2, 'Very Low': 3})
                sort_keys = ['confidence_sort', 'datetime_gmt8', 'league_tier', 'ev_for_bet_refined']
                sort_ascending = [True, True, True, False]
            else:
                sort_keys = ['datetime_gmt8', 'ev_for_bet_refined']; sort_ascending = [True, False]
            final_recommendations_df = final_recommendations_df.sort_values(by=sort_keys, ascending=sort_ascending).drop(columns=['confidence_sort'], errors='ignore')

            cols_to_output = [
                'datetime_gmt8', 'league', 'home_name', 'away_name', 'Recommendation', 'confidence_level',
                'line_betted_on_refined', 'odds_betted_on_refined', 'ev_for_bet_refined',
                'pred_home_goals', 'pred_away_goals', 'synth_ah_line_home_market_based',
                'competition_type', 'league_tier', 'shap_home_explanation', 'shap_away_explanation',
                'kings_call'
            ]
            cols_to_output_existing = [col for col in cols_to_output if col in final_recommendations_df.columns]
            df_to_write = final_recommendations_df[cols_to_output_existing].copy()

            print("\n--- Recommended Bets for Upcoming Period (Sorted) ---")
            try:
                # Handle Unicode characters in team names safely
                pd.set_option('display.unicode.east_asian_width', True)
                pd.set_option('display.unicode.ambiguous_as_wide', True)
                print(df_to_write.to_string(index=False))
            except UnicodeEncodeError:
                print("Recommendations generated successfully (Unicode display suppressed for compatibility)")
                print(f"Total recommendations: {len(df_to_write)}")
                for col in ['home_name', 'away_name', 'league', 'Recommendation']:
                    if col in df_to_write.columns:
                        print(f"{col} samples: {df_to_write[col].head(3).tolist()}")

            # Optional: write to Postgres/Supabase if DATABASE_URL is provided
            import os
            db_url = os.environ.get('DATABASE_URL')
            if db_url:
                try:
                    import psycopg2
                    conn = psycopg2.connect(db_url)
                    cur = conn.cursor()
                    # Ensure minimal tables exist (idempotent)
                    cur.execute("""
                    CREATE TABLE IF NOT EXISTS runs(
                        run_id text PRIMARY KEY,
                        started_at timestamptz,
                        finished_at timestamptz,
                        train_rows int,
                        test_rows int,
                        poisson_home_loss numeric,
                        poisson_away_loss numeric
                    );
                    CREATE TABLE IF NOT EXISTS recommendations(
                        run_id text,
                        dt_gmt8 timestamptz,
                        league text,
                        home text,
                        away text,
                        rec_text text,
                        line numeric,
                        odds numeric,
                        ev numeric,
                        confidence text,
                        kings_call_insight text,
                        kings_call_agreement text,
                        kings_call_reasoning text,
                        kings_call_sources text,
                        UNIQUE (run_id, dt_gmt8, home, away, line)
                    );
                    """)
                    # Insert run row (basic timing only here)
                    cur.execute(
                        "INSERT INTO runs(run_id, started_at, finished_at, train_rows, test_rows) VALUES(%s, now(), now(), %s, %s) ON CONFLICT (run_id) DO NOTHING",
                        (RUN_ID, len(df_for_training_and_testing) if 'df_for_training_and_testing' in globals() else None,
                         len(test_matches_df) if 'test_matches_df' in globals() else None)
                    )
                    # Insert recommendations with deduplication safeguard
                    insert_sql = """
                    INSERT INTO recommendations(run_id, dt_gmt8, league, home, away, rec_text, line, odds, ev, confidence, kings_call_insight, kings_call_agreement, kings_call_reasoning, kings_call_sources)
                    VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
                    ON CONFLICT (run_id, dt_gmt8, home, away, line) 
                    DO UPDATE SET 
                        rec_text = EXCLUDED.rec_text,
                        odds = EXCLUDED.odds,
                        ev = EXCLUDED.ev,
                        confidence = EXCLUDED.confidence,
                        kings_call_insight = EXCLUDED.kings_call_insight,
                        kings_call_agreement = EXCLUDED.kings_call_agreement,
                        kings_call_reasoning = EXCLUDED.kings_call_reasoning,
                        kings_call_sources = EXCLUDED.kings_call_sources
                    """
                    
                    # First, clean up old recommendations for this run to avoid stale data
                    cur.execute("DELETE FROM recommendations WHERE run_id = %s", (RUN_ID,))
                    
                    for _, r in df_to_write.iterrows():
                        cur.execute(
                            insert_sql,
                            (
                                RUN_ID,
                                r.get('datetime_gmt8'), r.get('league'), r.get('home_name'), r.get('away_name'),
                                r.get('Recommendation'), r.get('line_betted_on_refined'), r.get('odds_betted_on_refined'),
                                r.get('ev_for_bet_refined'), r.get('confidence_level'),
                                r.get('kings_call', ''), r.get('kings_call_agreement', ''), 
                                r.get('kings_call_reasoning', ''), r.get('kings_call_sources', '')
                            )
                        )
                    conn.commit(); cur.close(); conn.close()
                    print("Recommendations inserted to Postgres.")
                    logging.info("Recommendations inserted to Postgres successfully.")
                except Exception as e:
                    print(f"Postgres insert skipped/failed: {e}")
                    logging.error(f"Postgres insert failed: {e}")

            # Additional exports (CSV and HTML)
            try:
                import os
                from datetime import datetime as _dt
                os.makedirs('artifacts/latest', exist_ok=True)
                csv_path = f"artifacts/latest/recommendations_{_dt.now():%Y%m%d_%H%M%S}.csv"
                df_to_write.to_csv(csv_path, index=False, encoding='utf-8')
                print(f"Saved recommendations to CSV: {csv_path}")

                html_path = f"artifacts/latest/report_{_dt.now():%Y%m%d_%H%M%S}.html"
                with open(html_path, 'w', encoding='utf-8') as f:
                    f.write('<html><head><meta charset="utf-8"><title>Recommendations</title></head><body>')
                    f.write(f"<h2>Generated: {_dt.now():%Y-%m-%d %H:%M:%S}</h2>")
                    f.write(df_to_write.to_html(index=False))
                    f.write('</body></html>')
                print(f"Saved HTML report: {html_path}")
            except Exception as e:
                print(f"Export error (CSV/HTML): {e}")

            if WRITE_TO_GSHEET:
                if 'datetime_gmt8' in df_to_write.columns:
                    df_to_write['datetime_gmt8'] = pd.to_datetime(df_to_write['datetime_gmt8']).dt.strftime('%Y-%m-%d %H:%M')
                current_worksheet_name = f"Recs_{datetime.now().strftime('%Y-%m-%d')}"
                write_success, spreadsheet_url = write_to_google_sheet(df_to_write, base_sheet_name=GOOGLE_SHEET_NAME, worksheet_name_to_write=current_worksheet_name, use_service_account=USE_SERVICE_ACCOUNT_AUTH, service_account_file=SERVICE_ACCOUNT_FILE if USE_SERVICE_ACCOUNT_AUTH else None)
                if write_success:
                    format_google_sheet(GOOGLE_SHEET_NAME, current_worksheet_name, use_service_account=USE_SERVICE_ACCOUNT_AUTH, service_account_file=SERVICE_ACCOUNT_FILE if USE_SERVICE_ACCOUNT_AUTH else None, cols_for_3dp=['ev_for_bet_refined', 'pred_home_goals', 'pred_away_goals'])
                    if spreadsheet_url: print(f"Access the formatted sheet at: {spreadsheet_url}")

            # NEW: Copy to site/latest_recommendations.csv for the website and handle empty DF
            import shutil
            site_csv = 'site/latest_recommendations.csv'
            os.makedirs('site', exist_ok=True)
            if not df_to_write.empty:
                shutil.copy(csv_path, site_csv)
                logging.info(f"Copied recommendations to {site_csv} (rows: {len(df_to_write)})")
            else:
                logging.warning("No recommendations to copy - DF is empty")
                with open(site_csv, 'w') as f:
                    f.write('')  # Write empty file to avoid site errors
            print(f"Copied to site CSV: {site_csv}")
        else:
            print("No betting recommendations generated based on the policy for the upcoming period.")

print("\n--- End of Section 8: Generating Future Match Recommendations ---")

"""Section 8.5: Export Unified Games Schedule for Frontend"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os

print("\n--- Section 8.5: Export Unified Games Schedule for Frontend ---")

# League metadata with flags and short names
LEAGUE_METADATA = {
    'England Premier League': {'flag': '🏴󠁧󠁢󠁥󠁮󠁧󠁿', 'short': 'EPL', 'color': '#38003c'},
    'Spain La Liga': {'flag': '🇪🇸', 'short': 'La Liga', 'color': '#ee8900'},
    'Italy Serie A': {'flag': '🇮🇹', 'short': 'Serie A', 'color': '#024494'},
    'Germany Bundesliga': {'flag': '🇩🇪', 'short': 'Bundesliga', 'color': '#d20515'},
    'France Ligue 1': {'flag': '🇫🇷', 'short': 'Ligue 1', 'color': '#dae025'},
    'Europe UEFA Champions League': {'flag': '🏆', 'short': 'UCL', 'color': '#00336a'},
    'Europe UEFA Europa League': {'flag': '🥈', 'short': 'UEL', 'color': '#f68900'},
    'England Championship': {'flag': '🏴󠁧󠁢󠁥󠁮󠁧󠁿', 'short': 'Championship', 'color': '#004225'},
    'Netherlands Eredivisie': {'flag': '🇳🇱', 'short': 'Eredivisie', 'color': '#ff6200'},
    'Portugal Liga NOS': {'flag': '🇵🇹', 'short': 'Liga NOS', 'color': '#046a38'},
    'Belgium Pro League': {'flag': '🇧🇪', 'short': 'Pro League', 'color': '#000000'},
    'Brazil Serie A': {'flag': '🇧🇷', 'short': 'Brasileirão', 'color': '#009739'},
    'Argentina Primera División': {'flag': '🇦🇷', 'short': 'Primera', 'color': '#74acdf'},
    'Japan J1 League': {'flag': '🇯🇵', 'short': 'J1 League', 'color': '#e60012'},
    'South Korea K League 1': {'flag': '🇰🇷', 'short': 'K League', 'color': '#cd212a'},
    'USA MLS': {'flag': '🇺🇸', 'short': 'MLS', 'color': '#005da6'},
    'Australia A-League': {'flag': '🇦🇺', 'short': 'A-League', 'color': '#00843d'},
    'Turkey Süper Lig': {'flag': '🇹🇷', 'short': 'Süper Lig', 'color': '#e30613'},
    'Saudi Arabia Professional League': {'flag': '🇸🇦', 'short': 'Saudi Pro', 'color': '#006c35'},
    'China Chinese Super League': {'flag': '🇨🇳', 'short': 'CSL', 'color': '#de2910'},
    'Denmark Superliga': {'flag': '🇩🇰', 'short': 'Superliga', 'color': '#c8102e'},
    'Austria Bundesliga': {'flag': '🇦🇹', 'short': 'Bundesliga', 'color': '#ed2939'},
    'Scotland Premiership': {'flag': '🏴󠁧󠁢󠁳󠁣󠁴󠁿', 'short': 'Premiership', 'color': '#005eb8'},
    'Malaysia Super League': {'flag': '🇲🇾', 'short': 'Super League', 'color': '#cc0001'},
    'Israel Israeli Premier League': {'flag': '🇮🇱', 'short': 'Premier', 'color': '#0038b8'},
    'Thailand League 1': {'flag': '🇹🇭', 'short': 'Thai L1', 'color': '#a51931'}
}

def determine_signal_type(rec_data):
    """Determine signal icon based on recommendation data"""
    if not rec_data:
        return {'primary': '', 'secondary': ''}
    
    ev = rec_data.get('ev_for_bet_refined', 0) or rec_data.get('ev', 0)
    confidence = rec_data.get('confidence_level', '') or rec_data.get('confidence', '')
    has_kings_call = bool((rec_data.get('kings_call', '') or rec_data.get('kings_call_insight', '')).strip())
    
    # Avoid placeholder King's Calls
    if has_kings_call and 'Unable to fetch insight' in str(rec_data.get('kings_call', '')):
        has_kings_call = False
    
    # Primary signal hierarchy
    if has_kings_call and ev > 0.15:
        primary = 'kings-call'  # 👑
    elif ev > 0.20:
        primary = 'high-ev'     # 📈
    elif confidence == 'High' and ev > 0.10:
        primary = 'hot-pick'    # 🔥
    elif ev > 0.05:
        primary = 'value-bet'   # 💎
    else:
        primary = ''
    
    # Secondary signal (subtle indicator for moderate value)
    secondary = 'value' if primary and ev > 0.08 else ''
    
    return {'primary': primary, 'secondary': secondary}
def export_unified_games_schedule():
    """Export unified schedule leveraging existing all_data_unified"""
    try:
        if 'all_data_unified' not in globals() or all_data_unified.empty:
            print("Warning: all_data_unified not available, skipping unified schedule export")
            return
            
        # Use existing data - no new API calls needed!
        schedule_data = all_data_unified.copy()
        
        # Filter for relevant timeframe (past 24h + future 7 days)
        now_gmt8 = pd.Timestamp.now(tz='Asia/Singapore').tz_localize(None)
        recent_cutoff = now_gmt8 - pd.Timedelta(hours=24)
        future_cutoff = now_gmt8 + pd.Timedelta(days=7)
        
        schedule_filtered = schedule_data[
            (schedule_data['datetime_gmt8'] >= recent_cutoff) &
            (schedule_data['datetime_gmt8'] <= future_cutoff)
        ].copy()
        
        print(f"Filtered to {len(schedule_filtered)} games in relevant timeframe")
        
        # Link recommendations using existing final_recommendations_df
        unified_schedule = []
        recommendations_dict = {}
        
        # Create lookup dictionary from recommendations
        if 'final_recommendations_df' in globals() and not final_recommendations_df.empty:
            for _, rec in final_recommendations_df.iterrows():
                key = f"{rec['home_name']}_{rec['away_name']}"
                recommendations_dict[key] = rec.to_dict()
            print(f"Loaded {len(recommendations_dict)} recommendations for linking")
        
        for _, game in schedule_filtered.iterrows():
            # Find matching recommendation
            game_key = f"{game['home_name']}_{game['away_name']}"
            rec_match = recommendations_dict.get(game_key)
            
            # Determine signals
            signals = determine_signal_type(rec_match)
            
            # Get league metadata
            league_meta = LEAGUE_METADATA.get(game['league'], {})
            
            # Calculate authoritative AH lines for ALL games (not just recommendations)
            ah_line_home = None
            ah_line_away = None
            ah_odds_home = 1.925  # Default synthetic odds
            ah_odds_away = 1.925
            
            # Priority 1: Use synthetic AH from backend model if available
            if rec_match and 'synth_ah_line_home_market_based' in rec_match:
                ah_line_home = rec_match.get('synth_ah_line_home_market_based')
                if pd.notna(ah_line_home):
                    ah_line_away = -ah_line_home
                    ah_odds_home = rec_match.get('synth_ah_odds_home_market_based', 1.925)
                    ah_odds_away = rec_match.get('synth_ah_odds_away_market_based', 1.925)
            
            # Priority 2: Calculate from 1X2 odds if synthetic not available
            if ah_line_home is None and all(pd.notna(game.get(col)) and game.get(col) > 0 
                                          for col in ['odds_ft_1', 'odds_ft_x', 'odds_ft_2']):
                try:
                    # Convert to implied probabilities
                    prob_h = 1 / game['odds_ft_1']
                    prob_d = 1 / game['odds_ft_x'] 
                    prob_a = 1 / game['odds_ft_2']
                    total_prob = prob_h + prob_d + prob_a
                    
                    # Normalize
                    norm_prob_h = prob_h / total_prob
                    norm_prob_a = prob_a / total_prob
                    
                    # Estimate goal difference using same logic as backend
                    goal_diff = (norm_prob_h - norm_prob_a) * 2.5
                    
                    # Map to closest quarter line (same as backend get_closest_ah_line)
                    if goal_diff > 1.875: ah_line_home = -2.0
                    elif goal_diff > 1.625: ah_line_home = -1.75
                    elif goal_diff > 1.375: ah_line_home = -1.5
                    elif goal_diff > 1.125: ah_line_home = -1.25
                    elif goal_diff > 0.875: ah_line_home = -1.0
                    elif goal_diff > 0.625: ah_line_home = -0.75
                    elif goal_diff > 0.375: ah_line_home = -0.5
                    elif goal_diff > 0.125: ah_line_home = -0.25
                    elif goal_diff > -0.125: ah_line_home = 0.0
                    elif goal_diff > -0.375: ah_line_home = 0.25
                    elif goal_diff > -0.625: ah_line_home = 0.5
                    elif goal_diff > -0.875: ah_line_home = 0.75
                    elif goal_diff > -1.125: ah_line_home = 1.0
                    elif goal_diff > -1.375: ah_line_home = 1.25
                    elif goal_diff > -1.625: ah_line_home = 1.5
                    elif goal_diff > -1.875: ah_line_home = 1.75
                    else: ah_line_home = 2.0
                    
                    ah_line_away = -ah_line_home
                except Exception as e:
                    print(f"Warning: AH calculation failed for {game['home_name']} vs {game['away_name']}: {e}")
                    ah_line_home = 0.0
                    ah_line_away = 0.0
            
            # Priority 3: Fallback to neutral lines
            if ah_line_home is None:
                ah_line_home = 0.0
                ah_line_away = 0.0
            
            # CRITICAL: Include actual scores for parlay evaluation
            home_score = game.get('homeGoalCount')
            away_score = game.get('awayGoalCount')

            # Debug: Check scores for completed games
            if game.get('status') == 'complete':
                if home_score is None or away_score is None:
                    print(f"⚠️ Missing scores for completed game: {game.get('home_name')} vs {game.get('away_name')} (homeGoalCount={home_score}, awayGoalCount={away_score})")
                else:
                    print(f"✅ Found scores for {game.get('home_name')} vs {game.get('away_name')}: {home_score}-{away_score}")
            
            unified_schedule.append({
                'datetime_gmt8': game['datetime_gmt8'],
                'league': game['league'],
                'league_short': league_meta.get('short', game['league']),
                'league_flag': league_meta.get('flag', '⚽'),
                'league_color': league_meta.get('color', '#666666'),
                'home_name': game['home_name'],
                'away_name': game['away_name'],
                'odds_1': game.get('odds_ft_1', ''),
                'odds_x': game.get('odds_ft_x', ''), 
                'odds_2': game.get('odds_ft_2', ''),
                'league_tier': game['league_tier'],
                'competition_type': game['competition_type'],
                'is_future': game['is_future'],
                'status': game.get('status', ''),
                
                # Authoritative Asian Handicap data
                'ah_line_home': ah_line_home,
                'ah_line_away': ah_line_away,
                'ah_odds_home': ah_odds_home,
                'ah_odds_away': ah_odds_away,

                'home_score': home_score if home_score is not None else '',
                'away_score': away_score if away_score is not None else '',
                
                # Recommendation data
                'has_recommendation': rec_match is not None,
                'rec_text': rec_match.get('Recommendation', '') if rec_match else '',
                'line': rec_match.get('line_betted_on_refined', 0) if rec_match else 0,
                'rec_odds': rec_match.get('odds_betted_on_refined', 0) if rec_match else 0,
                'ev': rec_match.get('ev_for_bet_refined', 0) if rec_match else 0,
                'confidence': rec_match.get('confidence_level', '') if rec_match else '',
                'kings_call': rec_match.get('kings_call_insight', '') if rec_match else '',
                'kings_call_agreement': rec_match.get('kings_call_agreement', '') if rec_match else '',
                
                # Signal data
                'primary_signal': signals['primary'],
                'secondary_signal': signals['secondary']
            })
        
        # Export to site directory
        df_unified = pd.DataFrame(unified_schedule)
        os.makedirs('site', exist_ok=True)
        df_unified.to_csv('site/unified_games.csv', index=False, encoding='utf-8')
        print(f"✅ Exported {len(df_unified)} games to site/unified_games.csv")
        
        # Also copy to artifacts for backup
        os.makedirs('artifacts/latest', exist_ok=True)
        df_unified.to_csv('artifacts/latest/unified_games.csv', index=False, encoding='utf-8')
        
        # Log summary stats
        signal_counts = df_unified['primary_signal'].value_counts()
        rec_count = df_unified['has_recommendation'].sum()
        future_count = df_unified['is_future'].sum()
        
        print(f"Schedule summary:")
        print(f"  - Total games: {len(df_unified)}")
        print(f"  - With recommendations: {rec_count}")
        print(f"  - Future games: {future_count}")
        print(f"  - Signal distribution: {dict(signal_counts)}")
        
        logging.info(f"Unified schedule exported: {len(df_unified)} games, {rec_count} with recommendations")
        
    except Exception as e:
        print(f"Error exporting unified schedule: {e}")
        logging.error(f"Unified schedule export failed: {e}")

# Execute the export only when run directly, not when imported
if __name__ == "__main__":
    export_unified_games_schedule()